import{a as P,n as hn,b as ro,t as f,c as D,e as Bn,d as X,r as E,s as cn,f as Fe,g as Ts,h as Wn,i as Ds,j as xs,k as pe,l as oo,m as dn,o as B,p as _e,q as ao,u as z,v as rt,w as se,x as ct,y as lo,z as uo,A as ho,B as co,C as po,D as w,E as ut,S as Ae,F as Ls,G as Es,H as Os,I as Un,J as fo,K as mo,L as Ne,M as go,N as Ct,O as _,P as ms,Q as yo,R as ke,T as Vn,U as nt,V as Dt,W as bo,X as pn,Y as wo,Z as Io,_ as Ao,$ as Se,a0 as jn,a1 as Ge,a2 as ne,a3 as tt,a4 as Y,a5 as ge,a6 as $s,a7 as No,a8 as ko,a9 as gt,aa as Ye,ab as Kt,ac as Be,ad as Rs,ae as So,af as Ms,ag as Xt,ah as zo,ai as ie,aj as vo,ak as Co,al as To,am as fn,an as Do,ao as xo,ap as Lo,aq as Eo,ar as Oo,as as Pn,at as Hn,au as qn,av as $o,aw as Ro,ax as Mo,ay as Fo,az as _o,aA as Bo,aB as jt,aC as Wo,aD as Uo,aE as Vo,aF as jo,aG as Pt,aH as re,aI as gs,aJ as ys,aK as Kn,aL as mn,aM as gn,aN as bs,aO as Po,aP as Ho,aQ as qo,aR as Jn,aS as Fs,aT as Ko,aU as Jo,aV as Zo,aW as Go,aX as Yo,aY as Xo,aZ as Qo,a_ as ta,a$ as ea,b0 as sa,b1 as yn,b2 as na}from"./tfjs-core-05bdc049.js";/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */class It extends Error{constructor(t){super(t),Object.setPrototypeOf(this,It.prototype)}}class ht extends Error{constructor(t){super(t),Object.setPrototypeOf(this,ht.prototype)}}class c extends Error{constructor(t){super(t),Object.setPrototypeOf(this,c.prototype)}}class L extends Error{constructor(t){super(t),Object.setPrototypeOf(this,L.prototype)}}class _s extends Error{constructor(t){super(t),Object.setPrototypeOf(this,_s.prototype)}}/**
 * @license
 * Copyright 2022 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */class Zn{constructor(t){this.maxEntries=t||100,this.cache=new Map}get(t){let e;return this.cache.has(t)&&(e=this.cache.get(t),this.cache.delete(t),this.cache.set(t,e)),e}put(t,e){if(this.cache.has(t))this.cache.delete(t);else if(this.cache.size>=this.maxEntries){const s=this.cache.keys().next().value;this.cache.delete(s)}this.cache.set(t,e)}getMaxEntries(){return this.maxEntries}setMaxEntries(t){if(t<0)throw new Error(`The maxEntries of LRU caches must be at least 0, but got ${t}.`);if(this.maxEntries>t)for(let e=0;e<this.maxEntries-t;e++){const s=this.cache.keys().next().value;this.cache.delete(s)}this.maxEntries=t}}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function Jt(n,t){if(Array.isArray(n)){let e=[];for(let s=0;s<t;s++)e=e.concat(n);return e}else{const e=new Array(t);return e.fill(n),e}}function At(n,t){if(!n)throw new _s(t)}function bn(n,t){let e=0;for(const s of n)s===t&&e++;return e}function et(n){return n.length===1?n[0]:n}function W(n){return Array.isArray(n)?n:[n]}function Tt(n){const e=n.replace(/(.)([A-Z][a-z0-9]+)/g,"$1_$2").replace(/([a-z])([A-Z])/g,"$1_$2").toLowerCase();return e[0]!=="_"?e:"private"+e}function Vt(n){return n.length<=1||n.indexOf("_")===-1?n:n.replace(/[_]+(\w|$)/g,(t,e)=>e.toUpperCase())}let at={};function Bs(n){if(n==null)return null;const t={};return t.className=n.getClassName(),t.config=n.getConfig(),t}function ws(n){if(!(n==null||typeof n!="object"))if(Array.isArray(n))n.forEach(t=>ws(t));else{const t=Object.keys(n);for(const e of t){const s=n[e];s!=null&&typeof s=="object"&&(!Array.isArray(s)&&s.type==="ndarray"&&typeof s.value=="number"?n[e]=s.value:ws(s))}}}function ze(n,t={},e={},s="object",i=!1){if(typeof n=="string"){const r=n;let o;if(r in e)o=e[r];else if(r in at)o=at[r];else if(o=t[r],o==null)throw new c(`Unknown ${s}: ${n}. This may be due to one of the following reasons:
1. The ${s} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.
2. The custom ${s} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);return o}else{const r=n;if(r.className==null||r.config==null)throw new c(`${s}: Improper config format: ${JSON.stringify(r)}.
'className' and 'config' must set.`);const o=r.className;let a,l;if(o in e?[a,l]=e[o]:o in at?[a,l]=at.className:o in t&&([a,l]=t[o]),a==null)throw new c(`Unknown ${s}: ${o}. This may be due to one of the following reasons:
1. The ${s} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.
2. The custom ${s} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);if(l!=null){const u={};for(const I of Object.keys(at))u[I]=at[I];for(const I of Object.keys(e))u[I]=e[I];const h=r.config;h.customObjects=u;const d=Object.assign({},at);for(const I of Object.keys(e))at[I]=e[I];ws(r.config);const p=l(a,r.config,e,i);return at=Object.assign({},d),p}else{const u=Object.assign({},at);for(const d of Object.keys(e))at[d]=e[d];const h=new a(r.config);return at=Object.assign({},u),h}}}function ia(n,t){return n<t?-1:n>t?1:0}function Oe(n,t){return-1*ia(n,t)}function $t(n){if(n==null)return n;const t=[];for(const e of n)t.indexOf(e)===-1&&t.push(e);return t}function ra(n){if(n==null)throw new c(`Invalid value in obj: ${JSON.stringify(n)}`);for(const t in n)if(n.hasOwnProperty(t))return!1;return!0}function Zt(n,t,e){if(e!=null&&n.indexOf(e)<0)throw new c(`${e} is not a valid ${t}.  Valid values are ${n} or null/undefined.`)}function Ws(n,t,e=0,s=1/0){return At(e>=0),At(s>=e),Array.isArray(n)&&n.length>=e&&n.length<=s&&n.every(i=>typeof i===t)}function G(n,t){Array.isArray(n)?(P(n.length>0,()=>`${t} is unexpectedly an empty array.`),n.forEach((e,s)=>G(e,`element ${s+1} of ${t}`))):P(Number.isInteger(n)&&n>0,()=>`Expected ${t} to be a positive integer, but got ${Gn(n)}.`)}function Gn(n){return n===null?"null":Array.isArray(n)?"["+n.map(t=>Gn(t)).join(",")+"]":typeof n=="string"?`"${n}"`:`${n}`}function oa(n,t,e){let s=e!=null?e():hn(),i;return(...o)=>{const a=e!=null?e():hn();return a-s<t||(s=a,i=n(...o)),i}}function Yn(n){return n==="relu"?"relu":n==="linear"?"linear":n==="elu"?"elu":null}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */let aa=0;function Xn(){return aa++}const $e={};function Xe(n=""){return n in $e||($e[n]=0),$e[n]+=1,n+$e[n].toString()}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */const la=["channelsFirst","channelsLast"],ua=["nearest","bilinear"],ha=["valid","same","causal"],ca=["max","avg"],da=["sum","mul","concat","ave"];/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */const Qt=new Map;function H(n){Zt(la,"DataFormat",n)}function pa(n){Zt(ua,"InterpolationFormat",n)}function ot(n){Zt(ha,"PaddingMode",n)}function Qn(n){Zt(ca,"PoolMode",n)}const me=[],wn="/";function Ht(n,t){me.push(n);try{const e=t();return me.pop(),e}catch(e){throw me.pop(),e}}function fa(){return me.length===0?"":me.join(wn)+wn}function ti(n){if(!si(n))throw new Error("Not a valid tensor name: '"+n+"'");return fa()+n}function ei(n){if(!si(n))throw new Error("Not a valid tensor name: '"+n+"'");Qt.has(n)||Qt.set(n,0);const t=Qt.get(n);if(Qt.set(n,Qt.get(n)+1),t>0){const e=`${n}_${t}`;return Qt.set(e,1),e}else return n}const ma=new RegExp(/^[A-Za-z0-9][-A-Za-z0-9\._\/]*$/);function si(n){return!!n.match(ma)}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function ga(n){return n===parseInt(n.toString(),10)}function Rt(n,t,e){t==null&&(t=0),e==null&&(e=n.length);let s=1;for(let i=t;i<e;++i)s*=n[i];return s}function oe(n){if(n.length===0)return Number.NaN;let t=Number.POSITIVE_INFINITY;for(let e=0;e<n.length;e++){const s=n[e];s<t&&(t=s)}return t}function Mt(n){if(n.length===0)return Number.NaN;let t=Number.NEGATIVE_INFINITY;for(let e=0;e<n.length;e++){const s=n[e];s>t&&(t=s)}return t}function yt(n,t){if(t<n)throw new c(`end (${t}) < begin (${n}) is forbidden.`);const e=[];for(let s=n;s<t;++s)e.push(s);return e}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */let us;function q(){return us==null&&(us=ro().epsilon()),us}function bt(){return"channelsLast"}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function St(n,t){return X(n,t)}function ve(n,t=-1){const e=n.shape.slice();return t<0&&(t=e.length+t+1),e.splice(t,0,1),E(n,e)}function ya(n,t){return f(()=>{if(n.shape.length!==2)throw new c(`repeat() expects a rank-2 tensor, but received a rank-${n.shape.length} tensor.`);const e=ve(n,1);return Is(e,[1,t,1])})}function ba(n){const t=[Rt(n.shape)];return E(n,t)}function wa(n){if(n.rank<=1)throw new c(`batchFlatten requires a minimum rank of 2. Got rank: ${n.rank}.`);const t=[n.shape[0],Rt(n.shape,1)];return E(n,t)}function qt(n,t,e){return f(()=>{switch(n.rank){case 1:return Ds(n,t,e);case 2:return Wn(n,[t,0],[e,n.shape[1]]);case 3:return Ts(n,[t,0,0],[e,n.shape[1],n.shape[2]]);case 4:return Fe(n,[t,0,0,0],[e,n.shape[1],n.shape[2],n.shape[3]]);case 5:return cn(n,[t,0,0,0,0],[e,n.shape[1],n.shape[2],n.shape[3],n.shape[4]]);case 6:return cn(n,[t,0,0,0,0,0],[e,n.shape[1],n.shape[2],n.shape[3],n.shape[4],n.shape[5]]);default:throw new c(`sliceAlongFirstAxis() received an unsupported tensor rank: ${n.rank}`)}})}function hs(n,t,e){return f(()=>{switch(n.rank){case 1:return Ds(n,t,e);case 2:return Wn(n,[0,t],[n.shape[0],e]);case 3:return Ts(n,[0,0,t],[n.shape[0],n.shape[1],e]);case 4:return Fe(n,[0,0,0,t],[n.shape[0],n.shape[1],n.shape[2],e]);default:throw new c(`sliceAlongLastAxis() received an unsupported tensor rank: ${n.rank}`)}})}function Re(n,t,e,s){return f(()=>{switch(n.rank){case 1:return Ds(n,t,e);case 2:switch(s){case 1:return qt(n,t,e);case 2:return hs(n,t,e);default:throw new c(`The axis is not within the rank of the tensor ${s}`)}case 3:switch(s){case 1:return qt(n,t,e);case 2:return Ts(n,[0,t,0],[n.shape[0],e,n.shape[2]]);case 3:return hs(n,t,e);default:throw new c(`The axis is not within the rank of the tensor ${s}`)}case 4:switch(s){case 1:return qt(n,t,e);case 2:return Fe(n,[0,t,0,0],[n.shape[0],e,n.shape[2],n.shape[3]]);case 3:return Fe(n,[0,0,t,0],[n.shape[0],n.shape[1],e,n.shape[3]]);case 4:return hs(n,t,e);default:throw new c(`The axis is not within the rank of the tensor ${s}`)}default:throw new c(`sliceAlongLastAxis() received an unsupported tensor rank: ${n.rank}`)}})}function Us(n,t=-1){let e;return t<0&&(e=n[0].rank,e!==0?t=e:t=0),t===n[0].rank&&(t=-1),xs(n,t)}function In(n,t){switch(n.rank){case 1:return co([n,t]);case 2:return ho([n,t],0);case 3:return uo([n,t],0);case 4:return lo([n,t],0);default:throw new c(`concatAlongFirstAxis() received an unsupported tensor rank: ${n.rank}`)}}function Is(n,t){if(Array.isArray(t)||(t=[t]),n.rank!==t.length)throw new c(`The length of input n (${t.length}) does not match the number of dimensions in input x (${n.rank})`);return pe(n,t)}function Qe(n,t=0,e=1,s,i){return oo(n,t,e,s,i)}function zt(n,t,e,s){if(n.rank<2||t.rank<2)throw new L(`dot requires both inputs to be rank >= 2 but got x shape = ${n.shape} and y shape = ${t.shape}`);if(t.rank>=3){const i=n.shape.slice(-1)[0],r=t.shape.slice(-2)[0];if(i!==r)throw new L(`If rank y >= 3, then the second last dim of y must equal the last dim of x but got x shape = ${n.shape} and  y shape = ${t.shape}`)}if(n.rank===2&&t.rank===2)return dn({a:n,b:t,transposeA:!1,transposeB:!1,bias:s?As(n.rank,s,bt()):null,activation:e});{const i=n.shape.slice(),r=i.pop();n=E(n,[-1,r]);const o=t.shape.slice(),a=o.pop(),l=o.pop(),u=[...o,a],h=Array.from({length:t.rank},(b,g)=>g===0?t.rank-2:g<=t.rank-2?g-1:g);t=E(B(t,h),[l,-1]);const d=[...i,...u];return E(dn({a:n,b:t,transposeA:!1,transposeB:!1,bias:s?As(n.rank,s,bt()):null,activation:e}),d)}}function ni(n,t,e){return f(()=>(Array.isArray(t)?t=_e(t,"int32"):t=X(t,"int32"),ao(n,t,e)))}function Ce(n){return z(n,n)}function As(n,t,e){const s=t.shape;if(t.rank!==1&&t.rank!==n)throw new c(`Unexpected bias dimensions: ${t.rank}; expected it to be 1 or ${n}`);if(n===5){if(e==="channelsFirst")return s.length===1?E(t,[1,s[0],1,1,1]):E(t,[1,s[3],s[0],s[1],s[2]]);if(e==="channelsLast")return s.length===1?E(t,[1,1,1,1,s[0]]):E(t,[1].concat(s))}else if(n===4){if(e==="channelsFirst")return s.length===1?E(t,[1,s[0],1,1]):E(t,[1,s[2],s[0],s[1]]);if(e==="channelsLast")return s.length===1?E(t,[1,1,1,s[0]]):E(t,[1].concat(s))}else if(n===3){if(e==="channelsFirst")return s.length===1?E(t,[1,s[0],1]):E(t,[1,s[1],s[0]]);if(e==="channelsLast")return s.length===1?E(t,[1,1,s[0]]):E(t,[1].concat(s))}else if(n<3)return t;throw new c(`Unsupported input rank by biasAdd: ${t.rank}`)}function wt(n,t,e){return f(()=>(e==null&&(e=bt()),H(e),D(n,As(n.rank,t,e))))}function Ia(n,t=1){if(t!==1)throw new L(`Support for alpha values other than 1 (${t}) is not implemented yet.`);return Bn(n)}function Aa(n){return f(()=>rt(n,D(se(n),1)))}function ii(n,t,e,s){return f(()=>po(n,t,e,s))}function Na(n){return f(()=>{const t=D(.5,z(.2,n));return ct(t,0,1)})}function Te(n,t,e=!1){return e?n():t()}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */const ka=["fanIn","fanOut","fanAvg"],Sa=["normal","uniform","truncatedNormal"];/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function za(n){Zt(ka,"FanMode",n)}function va(n){Zt(Sa,"Distribution",n)}class dt extends Ae{fromConfigUsesCustomObjects(){return!1}getConfig(){return{}}}class ri extends dt{apply(t,e){return ut(t,e)}}ri.className="Zeros";w(ri);class Vs extends dt{apply(t,e){return Ls(t,e)}}Vs.className="Ones";w(Vs);class oi extends dt{constructor(t){if(super(),typeof t!="object")throw new c(`Expected argument of type ConstantConfig but got ${t}`);if(t.value===void 0)throw new c(`config must have value set but got ${t}`);this.value=t.value}apply(t,e){return f(()=>z(Es(this.value),Ls(t,e)))}getConfig(){return{value:this.value}}}oi.className="Constant";w(oi);class ai extends dt{constructor(t){super(),this.DEFAULT_MINVAL=-.05,this.DEFAULT_MAXVAL=.05,this.minval=t.minval||this.DEFAULT_MINVAL,this.maxval=t.maxval||this.DEFAULT_MAXVAL,this.seed=t.seed}apply(t,e){return Os(t,this.minval,this.maxval,e,this.seed)}getConfig(){return{minval:this.minval,maxval:this.maxval,seed:this.seed}}}ai.className="RandomUniform";w(ai);class li extends dt{constructor(t){super(),this.DEFAULT_MEAN=0,this.DEFAULT_STDDEV=.05,this.mean=t.mean||this.DEFAULT_MEAN,this.stddev=t.stddev||this.DEFAULT_STDDEV,this.seed=t.seed}apply(t,e){if(e=e||"float32",e!=="float32"&&e!=="int32")throw new L(`randomNormal does not support dType ${e}.`);return Qe(t,this.mean,this.stddev,e,this.seed)}getConfig(){return{mean:this.mean,stddev:this.stddev,seed:this.seed}}}li.className="RandomNormal";w(li);class ui extends dt{constructor(t){super(),this.DEFAULT_MEAN=0,this.DEFAULT_STDDEV=.05,this.mean=t.mean||this.DEFAULT_MEAN,this.stddev=t.stddev||this.DEFAULT_STDDEV,this.seed=t.seed}apply(t,e){if(e=e||"float32",e!=="float32"&&e!=="int32")throw new L(`truncatedNormal does not support dType ${e}.`);return Un(t,this.mean,this.stddev,e,this.seed)}getConfig(){return{mean:this.mean,stddev:this.stddev,seed:this.seed}}}ui.className="TruncatedNormal";w(ui);class hi extends dt{constructor(t){super(),this.gain=t.gain!=null?t.gain:1}apply(t,e){return f(()=>{if(t.length!==2||t[0]!==t[1])throw new c("Identity matrix initializer can only be used for 2D square matrices.");return z(this.gain,fo(t[0]))})}getConfig(){return{gain:this.gain}}}hi.className="Identity";w(hi);function Ca(n,t="channelsLast"){let e,s;if(H(t),n.length===2)e=n[0],s=n[1];else if([3,4,5].indexOf(n.length)!==-1){if(t==="channelsFirst"){const i=Rt(n,2);e=n[1]*i,s=n[0]*i}else if(t==="channelsLast"){const i=Rt(n,0,n.length-2);e=n[n.length-2]*i,s=n[n.length-1]*i}}else{const i=Rt(n);e=Math.sqrt(i),s=Math.sqrt(i)}return[e,s]}class it extends dt{constructor(t){if(super(),t.scale<0)throw new c(`scale must be a positive float. Got: ${t.scale}`);this.scale=t.scale==null?1:t.scale,this.mode=t.mode==null?"fanIn":t.mode,za(this.mode),this.distribution=t.distribution==null?"normal":t.distribution,va(this.distribution),this.seed=t.seed}apply(t,e){const s=Ca(t),i=s[0],r=s[1];let o=this.scale;if(this.mode==="fanIn"?o/=Math.max(1,i):this.mode==="fanOut"?o/=Math.max(1,r):o/=Math.max(1,(i+r)/2),this.distribution==="normal"){const a=Math.sqrt(o);if(e=e||"float32",e!=="float32"&&e!=="int32")throw new L(`${this.getClassName()} does not support dType ${e}.`);return Un(t,0,a,e,this.seed)}else{const a=Math.sqrt(3*o);return Os(t,-a,a,e,this.seed)}}getConfig(){return{scale:this.scale,mode:this.mode,distribution:this.distribution,seed:this.seed}}}it.className="VarianceScaling";w(it);class js extends it{constructor(t){super({scale:1,mode:"fanAvg",distribution:"uniform",seed:t==null?null:t.seed})}getClassName(){return it.className}}js.className="GlorotUniform";w(js);class Ps extends it{constructor(t){super({scale:1,mode:"fanAvg",distribution:"normal",seed:t==null?null:t.seed})}getClassName(){return it.className}}Ps.className="GlorotNormal";w(Ps);class Hs extends it{constructor(t){super({scale:2,mode:"fanIn",distribution:"normal",seed:t==null?null:t.seed})}getClassName(){return it.className}}Hs.className="HeNormal";w(Hs);class qs extends it{constructor(t){super({scale:2,mode:"fanIn",distribution:"uniform",seed:t==null?null:t.seed})}getClassName(){return it.className}}qs.className="HeUniform";w(qs);class Ks extends it{constructor(t){super({scale:1,mode:"fanIn",distribution:"normal",seed:t==null?null:t.seed})}getClassName(){return it.className}}Ks.className="LeCunNormal";w(Ks);class Js extends it{constructor(t){super({scale:1,mode:"fanIn",distribution:"uniform",seed:t==null?null:t.seed})}getClassName(){return it.className}}Js.className="LeCunUniform";w(Js);class ci extends dt{constructor(t){if(super(),this.DEFAULT_GAIN=1,this.gain=t.gain==null?this.DEFAULT_GAIN:t.gain,this.seed=t.seed,this.seed!=null)throw new L("Random seed is not implemented for Orthogonal Initializer yet.")}apply(t,e){return f(()=>{if(t.length<2)throw new L("Shape must be at least 2D.");t[0]*t[1]>2e3&&console.warn(`Orthogonal initializer is being called on a matrix with more than 2000 (${t[0]*t[1]}) elements: Slowness may result.`);const s=t[0]>t[1]?[t[1],t[0]]:t,i=Qe(s,0,1,"float32");let r=mo.gramSchmidt(i);return t[0]>t[1]&&(r=B(r)),z(this.gain,r)})}getConfig(){return{gain:this.gain,seed:this.seed}}}ci.className="Orthogonal";w(ci);const An={constant:"Constant",glorotNormal:"GlorotNormal",glorotUniform:"GlorotUniform",heNormal:"HeNormal",heUniform:"HeUniform",identity:"Identity",leCunNormal:"LeCunNormal",leCunUniform:"LeCunUniform",ones:"Ones",orthogonal:"Orthogonal",randomNormal:"RandomNormal",randomUniform:"RandomUniform",truncatedNormal:"TruncatedNormal",varianceScaling:"VarianceScaling",zeros:"Zeros"};function Nn(n,t={}){return ze(n,Ne.getMap().classNameMap,t,"initializer")}function j(n){return Bs(n)}function U(n){if(typeof n=="string"){const t=n in An?An[n]:n;if(t==="GlorotNormal")return new Ps;if(t==="GlorotUniform")return new js;if(t==="HeNormal")return new Hs;if(t==="HeUniform")return new qs;if(t==="LeCunNormal")return new Ks;if(t==="LeCunUniform")return new Js;{const e={};return e.className=t,e.config={},Nn(e)}}else return n instanceof dt?n:Nn(n)}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function Ns(n){return Array.isArray(n)&&Array.isArray(n[0])}function We(n){return n.length===0?[]:Array.isArray(n[0])?n:[n]}function C(n){let t;if(Array.isArray(n)){if(n.length!==1)throw new c(`Expected Tensor length to be 1; got ${n.length}`);t=n[0]}else t=n;return t}function R(n){if(Array.isArray(n)&&Array.isArray(n[0])){if(n.length===1)return n=n,n[0];throw new c(`Expected exactly 1 Shape; got ${n.length}`)}else return n}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function Ue(n){let t=0;for(const e of n)e.shape.length===0?t+=1:t+=e.shape.reduce((s,i)=>s*i);return t}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */const kn="Variable";class Ta{constructor(t,e="float32",s=kn,i=!0,r=null){this.dtype=e??"float32",this.shape=t.shape,this.id=Xn(),s=s??kn,this.originalName=ti(s),this.name=ei(this.originalName),this.trainable_=i,this.constraint=r,this.val=go(t,this.trainable_,this.name,this.dtype)}read(){return this.assertNotDisposed(),this.val}write(t){return this.assertNotDisposed(),Da(this.val,t),this.val.id!==t.id&&(this.val.assign(t),this.constraint!=null&&this.val.assign(this.constraint.apply(this.val))),this}dispose(){this.assertNotDisposed(),this.val.dispose()}assertNotDisposed(){if(this.val.isDisposed)throw new Error(`LayersVariable ${this.name} is already disposed.`)}get trainable(){return this.trainable_}set trainable(t){this.trainable_=t,this.val.trainable=t}}function Da(n,t){if(n.shape.toString()!==t.shape.toString())throw new Error("Shape mismatch: "+JSON.stringify(n.shape)+" vs. "+JSON.stringify(t.shape))}function ks(n){return n.map(t=>t.read())}function Zs(n){n.forEach(t=>{t[0].write(t[1])})}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */class K{constructor(t){this.dtype=t.dtype,this.shape=t.shape,t.shape!=null?this.ndim=t.shape.length:this.ndim=t.ndim,this.maxNDim=t.maxNDim,this.minNDim=t.minNDim,this.axes=t.axes||{}}}class kt{constructor(t,e,s,i,r,o,a){this.dtype=t,this.shape=e,this.sourceLayer=s,this.inputs=i,this.callArgs=r,this.outputTensorIndex=a,this.id=Xn(),o!=null&&(this.originalName=ti(o),this.name=ei(this.originalName)),this.rank=e.length}}let xa=0;class ts{constructor(t,e){this.callArgs=e,this.id=xa++,this.outboundLayer=t.outboundLayer,this.inboundLayers=t.inboundLayers,this.nodeIndices=t.nodeIndices,this.tensorIndices=t.tensorIndices,this.inputTensors=t.inputTensors,this.outputTensors=t.outputTensors,this.inputMasks=t.inputMasks,this.outputMasks=t.outputMasks,this.inputShapes=t.inputShapes,this.outputShapes=t.outputShapes;for(const s of t.inboundLayers)s?.outboundNodes.push(this);t.outboundLayer.inboundNodes.push(this)}getConfig(){const t=[];for(const e of this.inboundLayers)e!=null?t.push(e.name):t.push(null);return{outboundLayer:this.outboundLayer?this.outboundLayer.name:null,inboundLayers:t,nodeIndices:this.nodeIndices,tensorIndices:this.tensorIndices}}}let La=0;class O extends Ae{constructor(t={}){super(),this._callHook=null,this._addedWeightNames=[],this._stateful=!1,this.id=La++,this.activityRegularizer=null,this.inputSpec=null,this.supportsMasking=!1,this._trainableWeights=[],this._nonTrainableWeights=[],this._losses=[],this._updates=[],this._built=!1,this.inboundNodes=[],this.outboundNodes=[];let e=t.name;if(!e){const s=this.getClassName();e=Tt(s)+"_"+Xe(s)}if(this.name=e,this.trainable_=t.trainable==null?!0:t.trainable,t.inputShape!=null||t.batchInputShape!=null){let s;if(t.batchInputShape!=null)s=t.batchInputShape;else if(t.inputShape!=null){let r=null;t.batchSize!=null&&(r=t.batchSize),s=[r].concat(t.inputShape)}this.batchInputShape=s;let i=t.dtype;i==null&&(i=t.inputDType),i==null&&(i="float32"),this.dtype=i}t.weights!=null?this.initialWeights=t.weights:this.initialWeights=null,this._refCount=null,this.fastWeightInitDuringBuild=!1}static nodeKey(t,e){return t.name+"_ib-"+e.toString()}getNodeAtIndex(t,e){if(this.inboundNodes.length===0)throw new ht(`The layer has never been called and thus has no defined ${e}.`);if(this.inboundNodes.length<=t)throw new c(`Asked to get ${e} at node ${t}, but the layer has only ${this.inboundNodes.length} inbound nodes.`);return this.inboundNodes[t]}getInputAt(t){return et(this.getNodeAtIndex(t,"input").inputTensors)}getOutputAt(t){return et(this.getNodeAtIndex(t,"output").outputTensors)}get input(){if(this.inboundNodes.length>1)throw new It(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer input" is ill-defined. Use \`getInputAt(nodeIndex)\` instead.`);if(this.inboundNodes.length===0)throw new It(`Layer ${this.name} is not connected, no input to return.`);return et(this.getNodeAtIndex(0,"input").inputTensors)}get output(){if(this.inboundNodes.length===0)throw new It(`Layer ${this.name} has no inbound nodes.`);if(this.inboundNodes.length>1)throw new It(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer output" is ill-defined. Use \`getOutputAt(nodeIndex)\` instead.`);return et(this.getNodeAtIndex(0,"output").outputTensors)}get losses(){return this._losses}calculateLosses(){return this.losses.map(t=>t())}get updates(){return this._updates}get built(){return this._built}set built(t){this._built=t}get trainable(){return this.trainable_}set trainable(t){this._trainableWeights.forEach(e=>e.trainable=t),this.trainable_=t}get trainableWeights(){return this.trainable_?this._trainableWeights.filter(t=>t.trainable):[]}set trainableWeights(t){this._trainableWeights=t}get nonTrainableWeights(){return this.trainable?this._trainableWeights.filter(t=>!t.trainable).concat(this._nonTrainableWeights):this._trainableWeights.concat(this._nonTrainableWeights)}set nonTrainableWeights(t){this._nonTrainableWeights=t}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}get stateful(){return this._stateful}resetStates(){if(!this.stateful)throw new Error("Cannot call the resetStates() method of a non-stateful Layer object.")}assertInputCompatibility(t){if(t=W(t),this.inputSpec==null||this.inputSpec.length===0)return;const e=W(this.inputSpec);if(t.length!==e.length)throw new c(`Layer ${this.name} expects ${e.length} inputs, but it received ${t.length} input tensors. Input received: ${t}`);for(let s=0;s<t.length;s++){const i=t[s],r=e[s];if(r==null)continue;const o=i.rank;if(r.ndim!=null&&o!==r.ndim)throw new c(`Input ${s} is incompatible with layer ${this.name}: expected ndim=${r.ndim}, found ndim=${o}`);if(r.maxNDim!=null&&o>r.maxNDim)throw new c(`Input ${s} is incompatible with layer ${this.name}: expected max_ndim=${r.maxNDim}, found ndim=${o}`);if(r.minNDim!=null&&o<r.minNDim)throw new c(`Input ${s} is incompatible with layer ${this.name}: expected min_ndim=${r.minNDim}, found ndim=${o}.`);if(r.dtype!=null&&i.dtype!==r.dtype)throw new c(`Input ${s} is incompatible with layer ${this.name} : expected dtype=${r.dtype}, found dtype=${i.dtype}.`);if(r.axes){const a=i.shape;for(const l in r.axes){const u=Number(l),h=r.axes[l],d=u>=0?a[u]:a[a.length+u];if(h!=null&&[h,null].indexOf(d)===-1)throw new c(`Input ${s} is incompatible with layer ${this.name}: expected axis ${u} of input shape to have value ${h} but got shape ${a}.`)}}if(r.shape!=null)for(let a=0;a<r.shape.length;++a){const l=r.shape[a],u=i.shape[a];if(l!=null&&u!=null&&l!==u)throw new c(`Input ${s} is incompatible with layer ${this.name}: expected shape=${r.shape}, found shape=${i.shape}.`)}}}call(t,e){return t}invokeCallHook(t,e){this._callHook!=null&&this._callHook(t,e)}setCallHook(t){this._callHook=t}clearCallHook(){this._callHook=null}apply(t,e){e=e||{},this.assertNotDisposed();const s=W(t);let i=!0;for(const o of s)if(!(o instanceof kt)){i=!1;break}let r=!0;for(const o of s)if(o instanceof kt){r=!1;break}if(i===r)throw new c("Arguments to apply() must be all SymbolicTensors or all Tensors");return Ht(this.name,()=>{if(!this.built){this.assertInputCompatibility(t);const o=[];for(const a of W(t))o.push(a.shape);this.build(et(o)),this.built=!0,this.initialWeights&&this.setWeights(this.initialWeights),this._refCount===null&&r&&(this._refCount=1)}if(this.assertInputCompatibility(t),r){let o=this.call(t,e);const a=W(o),l=[];for(let u of a)s.indexOf(u)!==-1&&(u=u.clone()),l.push(u);if(o=et(l),this.activityRegularizer!=null)throw new L("Layer invocation in the presence of activity regularizer(s) is not supported yet.");return o}else{const o=Ea(t),a=this.computeOutputShape(o);let l;const u=Oa(t);if(this.warnOnIncompatibleInputShape(Array.isArray(t)?o[0]:o),a!=null&&a.length>0&&Array.isArray(a[0])?l=a.map((h,d)=>new kt(u,h,this,W(t),e,this.name,d)):l=new kt(u,a,this,W(t),e,this.name),this.addInboundNode(t,l,null,null,o,a,e),this._refCount++,this.activityRegularizer!=null)throw new L("Layer invocation in the presence of activity regularizer(s) is not supported yet.");return l}})}warnOnIncompatibleInputShape(t){if(this.batchInputShape!=null)if(t.length!==this.batchInputShape.length)console.warn(`The rank of the input tensor provided (shape: ${JSON.stringify(t)}) does not match that of the batchInputShape (${JSON.stringify(this.batchInputShape)}) of the layer ${this.name}`);else{let e=!1;this.batchInputShape.forEach((s,i)=>{s!=null&&t[i]!=null&&t[i]!==s&&(e=!0)}),e&&console.warn(`The shape of the input tensor (${JSON.stringify(t)}) does not match the expectation of layer ${this.name}: ${JSON.stringify(this.batchInputShape)}`)}}get outputShape(){if(this.inboundNodes==null||this.inboundNodes.length===0)throw new It(`The layer ${this.name} has never been called and thus has no defined output shape.`);const t=[];for(const e of this.inboundNodes){const s=JSON.stringify(e.outputShapes);t.indexOf(s)===-1&&t.push(s)}if(t.length===1){const e=this.inboundNodes[0].outputShapes;return Array.isArray(e)&&Array.isArray(e[0])&&e.length===1?e[0]:e}else throw new It(`The layer ${this.name} has multiple inbound nodes with different output shapes. Hence the notion of "output shape" is ill-defined for the layer.`)}countParams(){if(!this.built)throw new ht(`You tried to call countParams() on ${this.name}, but the layer is not built yet. Build it first by calling build(batchInputShape).`);return Ue(this.weights)}build(t){this.built=!0}getWeights(t=!1){return ks(t?this.trainableWeights:this.weights)}setWeights(t){f(()=>{const e=this.weights;if(e.length!==t.length)throw new c(`You called setWeights(weights) on layer "${this.name}" with a weight list of length ${t.length}, but the layer was expecting ${e.length} weights. Provided weights: ${t}...`);if(e.length===0)return;const s=[],i=ks(e);for(let r=0;r<i.length;++r){const o=i[r],a=e[r],l=t[r];if(!Ct(o.shape,l.shape))throw new c(`Layer weight shape ${o.shape} not compatible with provided weight shape ${l.shape}`);s.push([a,l])}Zs(s)})}addWeight(t,e,s,i,r,o,a,l){if(this._addedWeightNames.indexOf(t)!==-1)throw new c(`Duplicate weight name ${t} for layer ${this.name}`);this._addedWeightNames.push(t),s==null&&(s="float32"),this.fastWeightInitDuringBuild&&(i=l!=null?l():U("zeros"));const u=i.apply(e,s),h=new Ta(u,s,t,o,a);return u.dispose(),r!=null&&this.addLoss(()=>r.apply(h.read())),o==null&&(o=!0),o?this._trainableWeights.push(h):this._nonTrainableWeights.push(h),h}setFastWeightInitDuringBuild(t){this.fastWeightInitDuringBuild=t}addLoss(t){t==null||Array.isArray(t)&&t.length===0||(t=W(t),this._losses!==void 0&&this._losses!==null&&this.losses.push(...t))}computeOutputShape(t){return t}computeMask(t,e){if(!this.supportsMasking){if(e!=null)if(Array.isArray(e))e.forEach(s=>{if(s!=null)throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`)});else throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`);return null}return e}addInboundNode(t,e,s,i,r,o,a=null){const l=W(t);e=W(e),s=W(s),i=W(i),r=We(r),o=We(o);const u=[],h=[],d=[];for(const p of l)u.push(p.sourceLayer),h.push(p.nodeIndex),d.push(p.tensorIndex);new ts({outboundLayer:this,inboundLayers:u,nodeIndices:h,tensorIndices:d,inputTensors:l,outputTensors:e,inputMasks:s,outputMasks:i,inputShapes:r,outputShapes:o},a);for(let p=0;p<e.length;p++)e[p].sourceLayer=this,e[p].nodeIndex=this.inboundNodes.length-1,e[p].tensorIndex=p}getConfig(){const t={name:this.name,trainable:this.trainable};return this.batchInputShape!=null&&(t.batchInputShape=this.batchInputShape),this.dtype!=null&&(t.dtype=this.dtype),t}disposeWeights(){return this.weights.forEach(t=>t.dispose()),this.weights.length}assertNotDisposed(){if(this._refCount===0)throw new Error(`Layer '${this.name}' is already disposed.`)}dispose(){if(!this.built)throw new Error(`Cannot dispose Layer ${this.name} because it has not been built yet.`);if(this._refCount===null)throw new Error(`Cannot dispose Layer ${this.name} because it has not been used yet.`);this.assertNotDisposed();let t=0;return--this._refCount===0&&(t=this.disposeWeights()),{refCountAfterDispose:this._refCount,numDisposedVariables:t}}}function Ea(n){n=W(n);const t=[];for(const e of n)t.push(e.shape);return et(t)}function Oa(n){return"float32"}function di(n,t,e){if((t==null||e!=null&&e>0)&&(t=n.sourceLayer,e=n.nodeIndex),t.inboundNodes.length===0)return[n];{const s=t.inboundNodes[e];if(s.inboundLayers.length===0)return s.inputTensors;{const i=[];for(let r=0;r<s.inboundLayers.length;r++){const o=s.inputTensors[r],a=s.inboundLayers[r],l=s.nodeIndices[r],u=di(o,a,l);for(const h of u)i.indexOf(h)===-1&&i.push(h)}return i}}}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */class De extends O{constructor(t){if(super({dtype:t.dtype,name:t.name!=null?t.name:Xe("input").toString()}),t.batchSize==null&&(t.batchSize=null),t.sparse==null&&(t.sparse=!1),this.trainable=!1,this.built=!0,this.sparse=t.sparse,t.inputShape!=null&&t.batchInputShape!=null)throw new c("Only provide the inputShape OR batchInputShape argument to inputLayer, not both at the same time.");let e=t.batchInputShape;if(e==null){if(t.inputShape==null)throw new c("An InputLayer should be passed either a `batchInputShape` or an `inputShape`.");e=[t.batchSize].concat(t.inputShape)}else if(t.batchSize!=null)throw new c("Cannot specify batchSize if batchInputShape is specified when creating an InputLayer.");const s=t.dtype||"float32";this.batchInputShape=e,this.dtype=s,this.inputSpec=[{shape:e}];const i=new kt(this.dtype,this.batchInputShape,this,[],{},this.name);i.nodeIndex=0,i.tensorIndex=0,new ts({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:[i],outputTensors:[i],inputMasks:[null],outputMasks:[null],inputShapes:[e],outputShapes:[e]})}apply(t,e){throw new c(`Cannot pass any input to an InputLayer's apply() method. InputLayer name: ${this.name}`)}dispose(){return{refCountAfterDispose:this._refCount,numDisposedVariables:0}}getConfig(){return{batchInputShape:this.batchInputShape,dtype:this.dtype,sparse:this.sparse,name:this.name}}}De.className="InputLayer";w(De);function $a(n){if(n.batchShape==null&&n.shape==null)throw new Error("Please provide to Input either a `shape` or a `batchShape` argument. Note that `shape` does not include the batch dimension.");if(n.batchShape!=null&&n.shape!=null)throw new c("Please provide either a `shape` or `batchShape` argument to Input, but not both.");let t=n.batchShape;n.shape!=null&&t==null&&(t=[null].concat(n.shape));let e=n.dtype;return e==null&&(e="float32"),new De({batchInputShape:t,name:n.name,dtype:e,sparse:n.sparse}).inboundNodes[0].outputTensors[0]}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function Ra(n,t){if(n.dtype==null||n.dtype===t.dtype)return t;try{return X(t,n.dtype)}catch{throw new c(`The dtype of the feed (${t.dtype}) can not be cast to the dtype of the key '${n.name}' (${n.dtype}).`)}}class Ot{constructor(t){if(this.id2Value={},this.id2Mask={},this.name2Id={},t instanceof Ot)for(const e in t.id2Value)this.id2Value[e]=t.id2Value[e],e in t.id2Mask&&(this.id2Mask[e]=t.id2Mask[e]);else{if(t==null)return;for(const e of t)this.add(e.key,e.value)}}add(t,e,s){if(this.id2Value[t.id]==null)this.id2Value[t.id]=Ra(t,e),this.name2Id[t.name]=t.id,s!=null&&(this.id2Mask[t.id]=s);else throw new c(`Duplicate key: name=${t.name}, id=${t.id}`);return this}addFeed(t){this.add(t.key,t.value)}hasKey(t){return this.id2Value[t.id]!=null}names(){return Object.keys(this.name2Id)}getValue(t){if(t instanceof kt){if(this.id2Value[t.id]==null)throw new c(`Nonexistent key: ${t.name}`);return this.id2Value[t.id]}else{const e=this.name2Id[t];if(e==null)throw new c(`Feed dict has no SymbolicTensor name: ${t}`);return this.id2Value[e]}}getMask(t){if(t instanceof kt){if(this.id2Value[t.id]==null)throw new c(`Nonexistent key: ${t.name}`);return this.id2Mask[t.id]}else{const e=this.name2Id[t];if(e==null)throw new c(`Feed dict has no SymbolicTensor name: ${t}`);return this.id2Mask[e]}}disposeMasks(){this.id2Mask!=null&&_(this.id2Mask)}}const Ve=new Zn,je=new Zn;function Ma(n){Ve?.setMaxEntries(n),je?.setMaxEntries(n)}function fe(n,t,e,s){const i=e==null?!1:e.training,r=Array.isArray(n),o=r?n:[n],a=o.map(b=>b.name),l=[],u=t.names();for(const b of a)u.indexOf(b)!==-1?l.push(t.getValue(b)):l.push(null);s!=null&&(s.maxNumTensors=-1/0,s.minNumTensors=1/0);const h=a.join(",")+"|"+t.names().sort().join(",");let d=Ve.get(h),p;if(d==null){const b=Fa(o,t);d=b.sorted,p=b.recipientCounts,Ve.put(h,d),je.put(h,p)}p={},i||Object.assign(p,je.get(h));const I=new Ot(t);for(let b=0;b<d.length;++b){if(s!=null){const T=ms().numTensors;T>s.maxNumTensors&&(s.maxNumTensors=T),T<s.minNumTensors&&(s.minNumTensors=T)}const g=d[b],y=g.sourceLayer;if(y instanceof De)continue;const A=[],m=[],k=[];let N=!1;for(const T of g.inputs){const $=I.getValue(T),Q=I.getMask(T);A.push($),m.push(Q),Q!=null&&(N=!0),i||(p[T.name]--,p[T.name]===0&&!t.hasKey(T)&&a.indexOf(T.name)===-1&&!$.isDisposed&&T.sourceLayer.stateful!==!0&&k.push($))}N&&(e=e||{},e.mask=m[0]);const S=W(y.apply(A,e));let v=null;y.supportsMasking&&(v=y.computeMask(A,m));const M=Ba(g),x=Array.isArray(M)?M:[M];for(let T=0;T<x.length;++T){I.hasKey(x[T])||I.add(x[T],S[T],Array.isArray(v)?v[0]:v);const $=a.indexOf(x[T].name);$!==-1&&(l[$]=S[T])}i||_(k)}return I.disposeMasks(),r?l:l[0]}function Fa(n,t){P(n!=null&&n.length>0,()=>"Expected at least one fetch, got none");let e=[],s={};if(n.length===1){const i=Sn(n[0],t);e=i.sorted,s=i.recipientMap}else{const i=new Set;for(const r of n){const{sorted:o,recipientMap:a}=Sn(r,t);for(const l of o)i.has(l.name)||(e.push(l),i.add(l.name));for(const l in a)s[l]==null&&(s[l]=new Set),a[l].forEach(u=>s[l].add(u))}}return{sorted:e,recipientCounts:_a(s)}}function _a(n){const t={};for(const e in n)t[e]=n[e].size;return t}function Sn(n,t){const e=new Set,s=[],i={};for(const a of t.names())e.add(a);const r=[],o=[];for(r.push(n);r.length>0;){const a=r[r.length-1];if(e.has(a.name)){r.pop();continue}const l=o[o.length-1]===r.length-1;if(a.inputs.length===0||l)r.pop(),s.push(a),e.add(a.name),l&&o.pop();else{o.push(r.length-1);for(const u of a.inputs)i[u.name]==null&&(i[u.name]=new Set),i[u.name].add(a.name),!e.has(u.name)&&r.push(u)}}return{sorted:s,recipientMap:i}}function Ba(n){let t;if(n.sourceLayer.inboundNodes.length===1)t=n.sourceLayer.output;else{let e=null;for(let s=0;s<n.sourceLayer.inboundNodes.length;++s)for(const i of n.sourceLayer.inboundNodes[s].outputTensors)if(i.id===n.id){e=s;break}t=n.sourceLayer.getOutputAt(e)}return t}/**
 * @license
 * Copyright 2022 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */const Wa=yo();Wa.registerFlag("TOPOLOGICAL_SORT_CACHE_MAX_ENTRIES",()=>100,Ma);/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function Gs(n,t){return f(()=>Vn(nt(z(n,n),t,!0)))}class xe extends Ae{getConfig(){return{}}}class pi extends xe{constructor(t){super(),this.defaultMaxValue=2,this.defaultAxis=0,this.maxValue=t.maxValue!=null?t.maxValue:this.defaultMaxValue,this.axis=t.axis!=null?t.axis:this.defaultAxis}apply(t){return f(()=>{const e=Gs(t,this.axis),s=ct(e,0,this.maxValue);return z(t,rt(s,D(q(),e)))})}getConfig(){return{maxValue:this.maxValue,axis:this.axis}}}pi.className="MaxNorm";w(pi);class fi extends xe{constructor(t){super(),this.defaultAxis=0,this.axis=t.axis!=null?t.axis:this.defaultAxis}apply(t){return f(()=>rt(t,D(q(),Gs(t,this.axis))))}getConfig(){return{axis:this.axis}}}fi.className="UnitNorm";w(fi);class mi extends xe{apply(t){return ke(t)}}mi.className="NonNeg";w(mi);class gi extends xe{constructor(t){super(),this.defaultMinValue=0,this.defaultMaxValue=1,this.defaultRate=1,this.defaultAxis=0,this.minValue=t.minValue!=null?t.minValue:this.defaultMinValue,this.maxValue=t.maxValue!=null?t.maxValue:this.defaultMaxValue,this.rate=t.rate!=null?t.rate:this.defaultRate,this.axis=t.axis!=null?t.axis:this.defaultAxis}apply(t){return f(()=>{const e=Gs(t,this.axis),s=D(z(this.rate,ct(e,this.minValue,this.maxValue)),z(1-this.rate,e));return z(t,rt(s,D(q(),e)))})}getConfig(){return{minValue:this.minValue,maxValue:this.maxValue,rate:this.rate,axis:this.axis}}}gi.className="MinMaxNorm";w(gi);const zn={maxNorm:"MaxNorm",minMaxNorm:"MinMaxNorm",nonNeg:"NonNeg",unitNorm:"UnitNorm"};function J(n){return Bs(n)}function vn(n,t={}){return ze(n,Ne.getMap().classNameMap,t,"constraint")}function Z(n){if(n==null)return null;if(typeof n=="string"){const e={className:n in zn?zn[n]:n,config:{}};return vn(e)}else return n instanceof xe?n:vn(n)}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */async function Ut(n){if(n==null)return;const t=[],e=[],s=[];for(const i in n){const r=n[i];if(typeof r!="number"){const o=r;t.push(o.data()),e.push(i),s.push(o)}}if(t.length>0){const i=await Promise.all(t);for(let r=0;r<i.length;++r)n[e[r]]=i[r][0];_(s)}}function yi(n){if(n!=null)for(const t in n){const e=n[t];typeof e!="number"&&e.dispose()}}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */var Cn;(function(n){n[n.SILENT=0]="SILENT",n[n.VERBOSE=1]="VERBOSE"})(Cn||(Cn={}));const Ua=125;class ye{constructor(){this.validationData=null}setParams(t){this.params=t}async onEpochBegin(t,e){}async onEpochEnd(t,e){}async onBatchBegin(t,e){}async onBatchEnd(t,e){}async onTrainBegin(t){}async onTrainEnd(t){}setModel(t){}}class Va{constructor(t,e=10){t==null&&(t=[]),this.callbacks=t,this.queueLength=e}append(t){this.callbacks.push(t)}setParams(t){for(const e of this.callbacks)e.setParams(t)}setModel(t){for(const e of this.callbacks)e.setModel(t)}async onEpochBegin(t,e){e==null&&(e={});for(const s of this.callbacks)await s.onEpochBegin(t,e)}async onEpochEnd(t,e){e==null&&(e={});for(const s of this.callbacks)await s.onEpochEnd(t,e)}async onBatchBegin(t,e){e==null&&(e={});for(const s of this.callbacks)await s.onBatchBegin(t,e)}async onBatchEnd(t,e){e==null&&(e={});for(const s of this.callbacks)await s.onBatchEnd(t,e)}async onTrainBegin(t){t==null&&(t={});for(const e of this.callbacks)await e.onTrainBegin(t)}async onTrainEnd(t){t==null&&(t={});for(const e of this.callbacks)await e.onTrainEnd(t)}}class ja extends ye{constructor(){super()}async onEpochBegin(t){this.seen=0,this.totals={}}async onBatchEnd(t,e){e==null&&(e={});const s=e.size==null?0:e.size;this.seen+=s;for(const i in e){const r=e[i];if(typeof r=="number")this.totals.hasOwnProperty(i)||(this.totals[i]=0),this.totals[i]=this.totals[i]+r*s;else{let o;i in this.totals?o=this.totals[i]:this.totals[i]=0;const a=f(()=>D(this.totals[i],z(r,s)));this.totals[i]=a,o?.dispose()}}}async onEpochEnd(t,e){if(e!=null)for(const s of this.params.metrics)this.totals[s]!=null&&(typeof this.totals[s]=="number"?e[s]=this.totals[s]/this.seen:f(()=>{const i=z(rt(1,this.seen),this.totals[s]);e[s]=i,this.totals[s].dispose(),Dt(e[s])}))}}class Pa extends ye{async onTrainBegin(t){this.epoch=[],this.history={}}async onEpochEnd(t,e){e==null&&(e={}),this.epoch.push(t);for(const s in e)this.history[s]==null&&(this.history[s]=[]),this.history[s].push(e[s])}async syncData(){const t=[],e=[],s=[];for(const r in this.history){const o=this.history[r];for(let a=0;a<o.length;++a)if(typeof o[a]!="number"){const l=o[a];t.push(l.data()),e.push(r),s.push(a)}}const i=await Promise.all(t);for(let r=0;r<i.length;++r)this.history[e[r]][s[r]].dispose(),this.history[e[r]][s[r]]=i[r][0]}}class Ha extends ye{constructor(t,e){if(super(),this.currentEpoch=0,this.nowFunc=t.nowFunc,this.nextFrameFunc=t.nextFrameFunc||bo,this.yieldEvery=e||"auto",this.yieldEvery==="auto"&&(this.yieldEvery=Ua),this.yieldEvery==="never"&&t.onYield!=null)throw new Error("yieldEvery is `never` but you provided an `onYield` callback. Either change `yieldEvery` or remove the callback");pn(this.yieldEvery)&&(this.maybeWait=oa(this.maybeWait.bind(this),this.yieldEvery,this.nowFunc)),this.trainBegin=t.onTrainBegin,this.trainEnd=t.onTrainEnd,this.epochBegin=t.onEpochBegin,this.epochEnd=t.onEpochEnd,this.batchBegin=t.onBatchBegin,this.batchEnd=t.onBatchEnd,this.yield=t.onYield}async maybeWait(t,e,s){const i=[];this.yield!=null&&(await Ut(s),i.push(this.yield(t,e,s))),i.push(this.nextFrameFunc()),await Promise.all(i)}async onEpochBegin(t,e){this.currentEpoch=t,this.epochBegin!=null&&(await Ut(e),await this.epochBegin(t,e))}async onEpochEnd(t,e){const s=[];this.epochEnd!=null&&(await Ut(e),s.push(this.epochEnd(t,e))),this.yieldEvery==="epoch"&&s.push(this.nextFrameFunc()),await Promise.all(s)}async onBatchBegin(t,e){this.batchBegin!=null&&(await Ut(e),await this.batchBegin(t,e))}async onBatchEnd(t,e){const s=[];this.batchEnd!=null&&(await Ut(e),s.push(this.batchEnd(t,e))),this.yieldEvery==="batch"?s.push(this.nextFrameFunc()):pn(this.yieldEvery)&&s.push(this.maybeWait(this.currentEpoch,t,e)),await Promise.all(s)}async onTrainBegin(t){this.trainBegin!=null&&(await Ut(t),await this.trainBegin(t))}async onTrainEnd(t){this.trainEnd!=null&&(await Ut(t),await this.trainEnd(t))}}function bi(n,t){return n==null&&(n={}),n instanceof ye?[n]:Array.isArray(n)&&n[0]instanceof ye?n:W(n).map(s=>new Ha(s,t))}class lt{constructor(){}static registerCallbackConstructor(t,e){P(t>=0&&Number.isInteger(t),()=>`Verbosity level is expected to be an integer >= 0, but got ${t}`),lt.checkForDuplicate(e),lt.constructors[t]==null&&(lt.constructors[t]=[]),lt.constructors[t].push(e)}static checkForDuplicate(t){for(const e in lt.constructors)lt.constructors[+e].forEach(i=>{if(i===t)throw new c("Duplicate callback constructor.")})}static clear(){lt.constructors={}}static createCallbacks(t){const e=[];for(const s in lt.constructors){const i=+s;t>=i&&e.push(...lt.constructors[i])}return e.map(s=>new s)}}lt.constructors={};function wi(n,t,e,s,i,r,o,a,l){const u=new Pa,h=[new ja,...lt.createCallbacks(t)];n!=null&&h.push(...n),h.push(u);const d=new Va(h);return d.setParams({epochs:e,initialEpoch:s,samples:i,steps:r,batchSize:o,verbose:t,doValidation:a,metrics:l}),{callbackList:d,history:u}}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function vt(n,t={},e=!1){return ze(n,Ne.getMap().classNameMap,t,"layer",e)}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function Pe(n,t){return f(()=>{n.dtype!=="float32"&&(n=X(n,"float32"));const e=nt(Ce(n),t,!0),s=Ao(e.shape,q()),i=Vn(Se(e,s));return rt(n,i)})}function es(n,t){return f(()=>Y(Ce(tt(t,n)),-1))}function Ys(n,t){return f(()=>Y(se(tt(t,n)),-1))}function Xs(n,t){return f(()=>{const e=tt(n,t),s=ct(se(n),q(),Number.MAX_VALUE),i=se(rt(e,s));return z(100,Y(i,-1))})}function qa(n,t){return f(()=>{const e=ct(t,q(),Number.MAX_VALUE),s=ne(D(1,e)),i=ct(n,q(),Number.MAX_VALUE),r=ne(D(1,i));return Y(Ce(tt(s,r)),-1)})}function Ka(n,t){return f(()=>{const e=Se(0,tt(1,z(n,t)));return Y(Ce(e),-1)})}function Ja(n,t){return f(()=>{const e=Se(0,tt(1,z(n,t)));return Y(e,-1)})}function Za(n,t){return f(()=>{const e=nt(z(n,t),-1),s=ge(z(tt(1,n),t),-1);return Se(0,D(1,tt(s,e)))})}function Ga(n,t){return f(()=>{const e=Math.log(2),s=tt(t,n),i=tt(D(s,$s(z(-2,s))),e);return Y(i,-1)})}function be(n,t,e=!1){return f(()=>{if(e)t=jn(t);else{const s=nt(t,t.shape.length-1,!0);t=rt(t,s)}return t=ct(t,q(),1-q()),Ge(nt(z(X(n,"float32"),ne(t)),t.shape.length-1))})}function He(n,t,e=!1){return f(()=>{const s=X(wo(ba(n)),"int32");t=ct(t,q(),1-q());const i=t.shape,r=E(Io(s,i[i.length-1]),i);return be(r,t,e)})}function Ya(n,t){if(!Ct(n.shape,t.shape))throw new c(`logits and labels must have the same shape, but got shapes ${JSON.stringify(n.shape)} and ${JSON.stringify(t.shape)}`);return f(()=>{const e=ke(t),s=Ge(se(t));return D(tt(e,z(t,n)),No(ko(s)))})}function ss(n,t){return f(()=>{let e;return e=ct(t,q(),1-q()),e=ne(rt(e,tt(1,e))),Y(Ya(n,e),-1)})}function Xa(n,t){return f(()=>{const e=ct(n,q(),1),s=ct(t,q(),1);return nt(z(n,ne(rt(e,s))),-1)})}function Qa(n,t){return f(()=>{const e=ne(D(q(),t));return Y(tt(t,z(n,e)),-1)})}function Ii(n,t){return f(()=>{const e=Pe(n,-1),s=Pe(t,-1),i=z(e,s);return Ge(nt(i,-1))})}const qe={meanSquaredError:es,meanAbsoluteError:Ys,meanAbsolutePercentageError:Xs,meanSquaredLogarithmicError:qa,squaredHinge:Ka,hinge:Ja,categoricalHinge:Za,logcosh:Ga,categoricalCrossentropy:be,sparseCategoricalCrossentropy:He,binaryCrossentropy:ss,kullbackLeiblerDivergence:Xa,poisson:Qa,cosineProximity:Ii};function cs(n){if(typeof n=="string"){if(n in qe)return qe[n];let t=`Unknown loss ${n}`;throw n.toLowerCase().includes("softmaxcrossentropy")&&(t=`Unknown loss ${n}. Use "categoricalCrossentropy" as the string name for tf.losses.softmaxCrossEntropy`),new c(t)}else return n}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function Ai(n,t){return f(()=>{const e=z(.5,gt(t)),s=St(Ye(t,e),n.dtype);return Y(Kt(n,s),-1)})}function Ni(n,t){return f(()=>St(Kt(Be(n,-1),Be(t,-1)),"float32"))}function tl(n,t){return f(()=>X(nt(Ms(Kt(n,1),Kt(t,1))),"float32"))}function el(n,t){return f(()=>X(nt(Ms(Kt(n,0),Kt(t,1))),"float32"))}function sl(n,t){return f(()=>{const e=tl(n,t),s=el(n,t),i=D(e,s);return X(So(Ye(i,0),rt(e,i),0),"float32")})}function nl(n,t){return ss(n,t)}function il(n,t){return n.rank===t.rank&&(n=Rs(n,[n.rank-1])),t=Be(t,-1),t.dtype!==n.dtype&&(t=X(t,n.dtype)),X(Kt(n,t),"float32")}const rl=es,ol=es,al=Ys,ll=Ys,ul=Xs,hl=Xs,ki=be,cl=Ii,Si=He,Ke={binaryAccuracy:Ai,categoricalAccuracy:Ni,precision:sl,categoricalCrossentropy:ki,sparseCategoricalCrossentropy:Si,mse:rl,MSE:ol,mae:al,MAE:ll,mape:ul,MAPE:hl,cosine:cl};function dl(n){if(typeof n=="string"&&n in Ke)return Ke[n];if(typeof n!="string"&&n!=null)return n;throw new c(`Unknown metric ${n}`)}function Me(n){if(At(n!==null,`Unknown LossOrMetricFn ${n}`),typeof n=="string")return n;{let t;for(const e of Object.keys(qe))if(qe[e]===n){t=e;break}if(t!==void 0)return t;for(const e of Object.keys(Ke))if(Ke[e]===n){t=e;break}return t!==void 0?t:n.name}}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function pl(n){const t={Adagrad:()=>Xt.adagrad(.01),Adadelta:()=>Xt.adadelta(1,.95,q()),Adam:()=>Xt.adam(.001,.9,.999,q()),Adamax:()=>Xt.adamax(.002,.9,.999,q(),0),RMSProp:()=>Xt.rmsprop(.001,.9,0,q()),SGD:()=>Xt.sgd(.01)};if(t.adagrad=t.Adagrad,t.adadelta=t.Adadelta,t.adam=t.Adam,t.adamax=t.Adamax,t.rmsprop=t.RMSProp,t.sgd=t.SGD,n in t)return t[n]();throw new c(`Unknown Optimizer ${n}`)}/**
 * @license
 * Copyright 2019 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */const Tn=1*1024*1024;function Dn(n,t,e=!1){if(n==null||typeof n!="object"||Object.getPrototypeOf(n)!==Object.prototype||!Ss(n))throw new Error("User-defined metadata is expected to be a JSON object, but is not.");if(e){const s=JSON.stringify(n);s.length>Tn&&console.warn(`User-defined metadata of model "${t}" is too large in size (length=${s.length} when serialized). It is not recommended to store such large objects in user-defined metadata. Please make sure its serialized length is <= ${Tn}.`)}}function Ss(n){if(n===null)return!0;if(typeof n=="object")if(Object.getPrototypeOf(n)===Object.prototype){const t=Object.keys(n);for(const e of t)if(typeof e!="string"||!Ss(n[e]))return!1;return!0}else if(Array.isArray(n)){for(const t of n)if(!Ss(t))return!1;return!0}else return!1;else{const t=typeof n;return t==="string"||t==="number"||t==="boolean"}}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function fl(n,t,e,s=console.log){const i=gl(n),r=["Layer (type)","Input Shape","Output shape","Param #"];i?(t=t||90,e=e||[.32,.61,.89,1]):(t=t||115,e=e||[.24,.48,.7,.8,1]),e[e.length-1]<=1&&(e=e.map(h=>Math.floor(t*h)));let o;if(!i){r.push("Receives inputs"),o=[];for(const h in n.nodesByDepth)o.push(...n.nodesByDepth[h])}s("_".repeat(t)),Je(r,e,s),s("=".repeat(t));const a=n.layers;for(let h=0;h<a.length;++h)i?yl(a[h],e,s):bl(a[h],e,o,s),s((h===a.length-1?"=":"_").repeat(t));n.checkTrainableWeightsConsistency();const l=ml(n),u=Ue(n.nonTrainableWeights);s(`Total params: ${l+u}`),s(`Trainable params: ${l}`),s(`Non-trainable params: ${u}`),s("_".repeat(t))}function ml(n){let t;return n.collectedTrainableWeights!=null?t=Ue(n.collectedTrainableWeights):t=Ue(n.trainableWeights),t}function gl(n){let t=!0;const e=[],s=[];for(const i in n.nodesByDepth)e.push(n.nodesByDepth[i]);for(const i of e){if(i.length>1||i.length===1&&i[0].inboundLayers.length>1){t=!1;break}s.push(...i)}if(t)for(const i of n.layers){let r=!1;for(const o of i.inboundNodes)if(s.indexOf(o)!==-1)if(r){t=!1;break}else r=!0;if(!t)break}return t}function Je(n,t,e=console.log){let s="";for(let i=0;i<n.length;++i)i>0&&(s=s.slice(0,s.length-1)+" "),s+=n[i],s=s.slice(0,t[i]),s+=" ".repeat(t[i]-s.length);e(s)}function yl(n,t,e){let s,i;try{i=n.inboundNodes.map(l=>JSON.stringify(l.inputShapes)).join(",")}catch{i="multiple"}try{s=JSON.stringify(n.outputShape)}catch{s="multiple"}const r=n.name,o=n.getClassName(),a=[`${r} (${o})`,i,s,n.countParams().toString()];Je(a,t,e)}function bl(n,t,e,s){let i,r;try{r=n.inboundNodes.map(d=>JSON.stringify(d.inputShapes)).join(",")}catch{r="multiple"}try{i=JSON.stringify(n.outputShape)}catch{i="multiple"}const o=[];for(const d of n.inboundNodes)if(!(e!=null&&e.length>0&&e.indexOf(d)===-1))for(let p=0;p<d.inboundLayers.length;++p){const I=d.inboundLayers[p].name,b=d.nodeIndices[p],g=d.tensorIndices[p];o.push(`${I}[${b}][${g}]`)}const a=n.name,l=n.getClassName(),u=o.length===0?"":o[0],h=[`${a} (${l})`,r,i,n.countParams().toString(),u];Je(h,t,s);for(let d=1;d<o.length;++d)Je(["","","","",o[d]],t,s)}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function zi(n,t,e){return(n==="inboundNodes"||n==="outputLayers"||n==="inputLayers")&&t===0&&typeof e=="string"}function Ze(n,t){if(n===null)return null;if(typeof n=="string")return Vt(n);if(typeof n=="number"||typeof n=="boolean")return n;if(n instanceof Array){const e=[],s=n.length;for(let i=0;i<s;++i){const r=n[i];zi(t,i,r)?e.push(r):e.push(Ze(r,t))}return e}else{const e={};for(const s of Object.keys(n)){const i=n[s];if(s==="name"&&typeof i=="string")e[s]=i;else{const r=Vt(s);e[r]=Ze(i,r)}}return e}}function zs(n,t){if(n==null)return null;if(typeof n=="string")return Tt(n);if(typeof n=="number"||typeof n=="boolean")return n;if(n instanceof Array){const e=[],s=n.length;for(let i=0;i<s;++i){const r=n[i];zi(t,i,r)?e.push(r):e.push(zs(r,t))}return e}else{const e={};for(const s of Object.keys(n)){const i=n[s],r=Tt(s);(s==="name"||s==="className")&&typeof i=="string"?e[r]=i:e[r]=zs(i,s)}return e}}/** @license See the LICENSE file. */const vi="4.2.0";/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */class ft extends O{constructor(t){if(super({}),this.containerNodes=new Set,this.name=t.name,this.name==null){const m=this.getClassName().toLowerCase();this.name=Xe(m)}if(this.supportsMasking=!1,this.trainable_=!0,Array.isArray(t.inputs)?this.inputs=t.inputs.slice():this.inputs=[t.inputs],Array.isArray(t.outputs)?this.outputs=t.outputs.slice():this.outputs=[t.outputs],$t(this.inputs).length!==this.inputs.length)throw new c(`The list of inputs passed to the model is redundant. All inputs should only appear once. Found: ${this.inputs.map(m=>m.name)}`);$t(this.outputs).length!==this.outputs.length&&console.warn(`The list of outputs passed to the model is redundant. All outputs should only appear once. Found: ${this.outputs.map(m=>m.name)}`),this.inputLayers=[],this.inputLayersNodeIndices=[],this.inputLayersTensorIndices=[],this.outputLayers=[],this.outputLayersNodeIndices=[],this.outputLayersTensorIndices=[],this.layers=[],this.internalContainerRefs=[];for(const m of this.outputs){const k=m.sourceLayer,N=m.nodeIndex,S=m.tensorIndex;this.outputLayers.push(k),this.outputLayersNodeIndices.push(N),this.outputLayersTensorIndices.push(S)}for(const m of this.inputs){const k=m.sourceLayer,N=m.nodeIndex,S=m.tensorIndex;At(N===0,"input layer has >1 nodes"),At(S===0,"input layer has >1 tensors"),this.inputLayers.push(k),this.inputLayersNodeIndices.push(N),this.inputLayersTensorIndices.push(S)}this.inputNames=[],this.outputNames=[],this.feedInputShapes=[],this.feedInputNames=[],this.feedOutputNames=[];for(let m=0;m<this.inputLayers.length;m++){const k=this.inputLayers[m];if(!(k instanceof De))throw new TypeError(`Input layers to a LayersModel must be InputLayer objects. Received inputs: ${t.inputs}. Input ${m} (0-based) originates from layer type ${k.getClassName()}.`);this.inputNames.push(k.name),this.feedInputShapes.push(k.batchInputShape),this.feedInputNames.push(k.name)}for(const m of this.outputLayers)this.outputNames.push(m.name);this.internalInputShapes=this.inputs.map(m=>m.shape),this.internalOutputShapes=this.outputs.map(m=>m.shape);const e={},s={},i={},r={},o={},a=[],l=(m,k,N,S,v,M)=>{(S==null||v==null||M==null)&&(S=m.sourceLayer,v=m.nodeIndex,M=m.tensorIndex);const x=S.inboundNodes[v];if(N.indexOf(x)!==-1)throw new ht(`The tensor ${m.name} at layer "${S.name}" is part of a cycle.`);if(k.indexOf(x)!==-1)return;this.containerNodes.add(ft.nodeKey(S,v)),S.id in o||(o[S.id]=Object.keys(o).length),N.indexOf(x)===-1&&N.push(x);const T=x.inboundLayers.length;for(let $=0;$<T;$++){const Q=x.inputTensors[$],xt=x.inboundLayers[$],le=x.nodeIndices[$],ue=x.tensorIndices[$];l(Q,k,N,xt,le,ue)}for(k.push(x);N.indexOf(x)>=0;)N.splice(N.indexOf(x),1);a.push(x)},u=[],h=[];for(const m of this.outputs)l(m,u,h);const d=a.slice().reverse();for(const m of d){s[m.id]=m,m.id in e||(e[m.id]=0);let k=e[m.id];const N=i[m.outboundLayer.id]==null?0:i[m.outboundLayer.id];k=Math.max(k,N),i[m.outboundLayer.id]=k,r[m.outboundLayer.id]=m.outboundLayer,e[m.id]=k;for(let S=0;S<m.inboundLayers.length;S++){const v=m.inboundLayers[S],M=m.nodeIndices[S],x=v.inboundNodes[M],T=e[x.id]==null?0:e[x.id];e[x.id]=Math.max(k+1,T),s[x.id]=x}}const p={};for(const m in e){const k=e[m];k in p||(p[k]=[]),p[k].push(s[m])}const I={};for(const m in i){const k=i[m];k in I||(I[k]=[]),I[k].push(r[m])}let b=Object.keys(I).map(m=>parseInt(m,10)).sort(Oe);this.layers=[];for(const m of b){const k=I[m];k.sort((N,S)=>{const v=o[N.id],M=o[S.id];return v<M?-1:v>M?1:0});for(const N of k)N instanceof ft&&this.internalContainerRefs.push(N),this.layers.push(N)}this.layersByDepth=I,b=Object.keys(p).map(m=>parseInt(m,10)).sort(Oe);const g=this.inputs.slice(),y=[];for(const m of b)for(const k of p[m]){const N=k.outboundLayer;if(N!=null){for(const S of k.inputTensors)if(g.indexOf(S)===-1)throw new ht(`Graph disconnected: cannot obtain value for tensor ${S} at layer "${N.name}". The following previous layers were accessed without issue: ${y}`);for(const S of k.outputTensors)g.push(S);y.push(N.name)}}this.nodesByDepth=p;const A=this.layers.map(m=>m.name);for(const m of A){const k=A.filter(N=>N===m).length;if(k!==1)throw new ht(`The name "${m}" is used ${k} times in the model. All layer names should be unique. Layer names: `+JSON.stringify(A))}this.outboundNodes=[],this.inboundNodes=[],new ts({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:this.inputs,outputTensors:this.outputs,inputMasks:this.inputs.map(m=>null),outputMasks:this.outputs.map(m=>null),inputShapes:this.inputs.map(m=>m.shape),outputShapes:this.outputs.map(m=>m.shape)}),this.built=!0,this._refCount=1}assertNotDisposed(){if(this._refCount===0)throw new Error(`Container '${this.name}' is already disposed.`)}dispose(){this.assertNotDisposed();const t={refCountAfterDispose:null,numDisposedVariables:0};if(--this._refCount===0){for(const e of this.layers)t.numDisposedVariables+=e.dispose().numDisposedVariables;for(const e of this.internalContainerRefs)t.numDisposedVariables+=e.dispose().numDisposedVariables}return t.refCountAfterDispose=this._refCount,t}get trainable(){return this.trainable_}set trainable(t){this.layers.forEach(e=>{e._trainableWeights.forEach(s=>s.trainable=t)}),this.trainable_=t}get trainableWeights(){if(this._trainableWeights.length>0)throw new c("Container instance unexpectedly contains _trainableWeights.The trainable weights of a Container are a union of the trainable weights of its consituent Layers. Its own _trainableWeights must remain an empty Array.");if(!this.trainable)return[];let t=[];for(const e of this.layers)t=t.concat(e.trainableWeights);return t}get nonTrainableWeights(){const t=[];for(const e of this.layers)t.push(...e.nonTrainableWeights);if(!this.trainable){const e=[];for(const s of this.layers)e.push(...s.trainableWeights);return e.concat(t)}return t}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}loadWeights(t,e=!0){const s={};let i=0;for(const o of this.layers)for(const a of o.weights){if(s[a.originalName]!=null)throw new c(`Duplicate weight name: ${a.originalName}`);s[a.originalName]=a,i++}const r=[];for(const o in t){let a=o;if(s[o]==null){const l=o.split("/");a=l.slice(0,-2).concat([l[l.length-1]]).join("/")}if(s[a]!=null)r.push([s[a],t[o]]);else if(e)throw new c(`Provided weight data has no target variable: ${o}`);delete s[a]}if(e){const o=[];for(const a in s)o.push(a);if(o.length>0)throw new c(`${o.length} of ${i} weights are not set: ${o}`)}Zs(r)}updatedConfig(){const t=this.getConfig(),e={};return e.className=this.getClassName(),e.config=t,e.kerasVersion=`tfjs-layers ${vi}`,e.backend="TensorFlow.js",e}toJSON(t,e=!0){const s=zs(this.updatedConfig());return e?JSON.stringify(s):s}call(t,e){return f(()=>{t=W(t);const s=new Ot;for(let i=0;i<this.inputs.length;++i)s.add(this.inputs[i],t[i]);return fe(this.outputs,s,e)})}computeMask(t,e){return f(()=>{t=W(t);let s;return e==null?s=Jt(null,t.length):s=W(e),this.runInternalGraph(t,s)[1]})}computeOutputShape(t){const e=We(t);if(e.length!==this.inputLayers.length)throw new c(`Invalid inputShape argument ${t}: model has ${this.inputLayers.length} tensor inputs.`);const s={};for(let a=0;a<e.length;a++){const l=this.inputLayers[a],u=e[a],h=l.name+"_0_0";s[h]=u}const i=Object.keys(this.nodesByDepth).map(a=>parseInt(a,10)).sort(Oe);if(i.length>1)for(const a of i){const l=this.nodesByDepth[a];for(const u of l){const h=u.outboundLayer;if(this.inputLayers.map(g=>g.id).indexOf(h.id)!==-1)continue;const d=[];for(let g=0;g<u.inboundLayers.length;g++){const y=u.inboundLayers[g],A=u.nodeIndices[g],m=u.tensorIndices[g],k=`${y.name}_${A}_${m}`,N=s[k];d.push(N)}const p=h.computeOutputShape(et(d)),I=We(p),b=h.inboundNodes.indexOf(u);for(let g=0;g<I.length;g++){const y=`${h.name}_${b}_${g}`;s[y]=I[g]}}}const r=[],o=[];for(let a=0;a<this.outputLayers.length;a++){const l=this.outputLayers[a],u=this.outputLayersNodeIndices[a],h=this.outputLayersTensorIndices[a],d=`${l.name}_${u}_${h}`;o.push(d)}for(let a=0;a<o.length;a++){const l=o[a];At(l in s),r.push(s[l])}return et(r)}runInternalGraph(t,e){e==null&&(e=Jt(null,t.length));const s={};for(let l=0;l<this.inputs.length;++l){const u=this.inputs[l],h=t[l],d=e[l];s[u.id]=[h,d]}const i=Object.keys(this.nodesByDepth).map(l=>parseInt(l,10)).sort(Oe);for(const l of i){const u=this.nodesByDepth[l];for(const h of u){const d=h.outboundLayer,p=h.inputTensors,I=h.outputTensors,b=new Array;for(const g of p)g.id in s&&b.push(s[g.id]);if(b.length===p.length){let g={},y,A,m,k;if(h.callArgs!=null&&(g=h.callArgs),b.length===1){const[N,S]=b[0];g.mask==null&&(g.mask=S),m=W(d.call(N,g)),k=W(d.computeMask(N,S)),y=[N],A=[S]}else y=b.map(N=>N[0]),A=b.map(N=>N[1]),g.mask==null&&(g.mask=A),m=W(d.call(y,g)),k=W(d.computeMask(y,A));if(d.activityRegularizer)throw new L("LayersModel invocation with concrete Tensor value(s) in the presence of activity regularizer(s) is not supported yet.");for(let N=0;N<I.length;++N){const S=I[N],v=m[N],M=k[N];s[S.id]=[v,M]}}}}const r=[],o=[],a=[];for(const l of this.outputs){At(l.id in s,`Could not compute output ${l.name} : ${l.id}`);const[u,h]=s[l.id];a.push(u.shape),r.push(u),o.push(h)}return[r,o,a]}buildNodeConversionMap(t){const e={};let s;for(const i of this.layers){s=i instanceof ft?1:0;for(let r=0;r<i.inboundNodes.length;r++){const o=ft.nodeKey(i,r);this.containerNodes.has(o)&&(e[o]=s,s+=1)}}return e}getLayer(t,e){if(e!=null){if(this.layers.length<=e)throw new c(`Was asked to retrieve layer at index ${e}, but model only has ${this.layers.length} layer(s).`);return this.layers[e]}else if(t==null)throw new c("Provide either a layer name or layer index");for(const s of this.layers)if(s.name===t)return s;throw new c(`No such layer: ${t}`)}calculateLosses(){return f(()=>{const t=[];for(const e of this.layers)for(let s=0;s<e.inboundNodes.length;++s){const i=ft.nodeKey(e,s);this.containerNodes.has(i)&&t.push(...e.calculateLosses())}return t})}getConfig(){const t={name:this.name},e=this.buildNodeConversionMap(this.layers),s=[];for(const o of this.layers){const a=o.getClassName(),l=o.getConfig(),u=[];for(let d=0;d<o.inboundNodes.length;d++){const p=o.inboundNodes[d],I=ft.nodeKey(o,d);let b={};if(this.containerNodes.has(I)){if(p.callArgs)try{JSON.stringify(p.callArgs),b=p.callArgs}catch{console.warn(`Layer ${o.name} was passed non-serializable keyword arguments: ${p.callArgs}. They will not be included in the serialized model (and thus will be missing at deserialization time).`),b={}}if(p.inboundLayers.length>0){const g=[];for(let y=0;y<p.inboundLayers.length;y++){const A=p.inboundLayers[y],m=p.nodeIndices[y],k=p.tensorIndices[y],N=ft.nodeKey(A,m);let S=e[N];S==null&&(S=0),g.push([A.name,S,k,b])}u.push(g)}}}const h={};h.name=o.name,h.className=a,h.config=l,h.inboundNodes=u,s.push(h)}t.layers=s;const i=[];for(let o=0;o<this.inputLayers.length;o++){const a=this.inputLayers[o],l=this.inputLayersNodeIndices[o],u=ft.nodeKey(a,l);if(!this.containerNodes.has(u))continue;let h=e[u];h==null&&(h=0);const d=this.inputLayersTensorIndices[o];i.push([a.name,h,d])}t.inputLayers=i;const r=[];for(let o=0;o<this.outputLayers.length;o++){const a=this.outputLayers[o],l=this.outputLayersNodeIndices[o],u=ft.nodeKey(a,l);if(!this.containerNodes.has(u))continue;let h=e[u];h==null&&(h=0);const d=this.outputLayersTensorIndices[o];r.push([a.name,h,d])}return t.outputLayers=r,t}static fromConfig(t,e,s={},i=!1){const r={},o={};function a(y,A){y.name in o?o[y.name].push(A):o[y.name]=[A]}function l(y,A){const m=[];let k;for(const N of A){const S=N[0],v=N[1],M=N[2];if(k=N[3]==null?{}:N[3],!(S in r)){a(y,A);return}const x=r[S];if(x.inboundNodes.length<=v){a(y,A);return}const T=x.inboundNodes[v];m.push(T.outputTensors[M])}m.length>0&&y.apply(et(m),k)}function u(y){const A=y.name,m=vt(y,e.customObjects!=null?e.customObjects:{});m.setFastWeightInitDuringBuild(i),r[A]=m,y.inboundNodes.forEach(N=>{if(!(N instanceof Array))throw new c(`Corrupted configuration, expected array for nodeData: ${N}`);a(m,N)})}const h=e.name,d=e.layers;for(const y of d)u(y);for(;!ra(o);)for(const y of d){const A=r[y.name];if(A.name in o){const m=o[A.name];delete o[A.name];for(const k of m)l(A,k)}}const p=[],I=[],b=e.inputLayers;for(const y of b){const A=y[0],m=y[1],k=y[2];At(A in r);const S=r[A].inboundNodes[m].outputTensors;p.push(S[k])}const g=e.outputLayers;for(const y of g){const A=y[0],m=y[1],k=y[2];At(A in r);const S=r[A].inboundNodes[m].outputTensors;I.push(S[k])}return new t({inputs:p,outputs:I,name:h})}get stateful(){if(this._stateful)throw new c("Container instance unexpectedly has _stateful = true. The statefulness of a Container is determined by the Layers it contains. Its _stateful property must remain the default false.");for(const t of this.layers)if(t.stateful)return!0;return!1}resetStates(){f(()=>{this.layers.forEach(t=>{t.stateful&&t.resetStates()})})}}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function wl(n,t,e){const s=t.length;if(n==null||Array.isArray(n)&&n.length===0)return t.map(i=>null);if(s===1)return Array.isArray(n)&&n.length===1?n:typeof n=="object"&&t[0]in n?[n[t[0]]]:[n];if(Array.isArray(n)){if(n.length!==s)throw new Error(`Provided ${e} is an array of ${n.length} element(s), but the model has ${s} outputs. Make sure a set of weights is provided for each model output.`);return n}else if(typeof n=="object"&&Object.keys(n).length>0&&typeof n[Object.keys(n)[0]]=="object"){const i=[];return t.forEach(r=>{r in n?i.push(n[r]):i.push(null)}),i}else throw new Error(`The model has multiple (${s}) outputs, so ${e} must be either an array with ${s} elements or an object with ${t} keys. Provided ${e} not understood: ${JSON.stringify(n)}`)}function Ci(n,t){return wl(n,t,"classWeight")}async function Ti(n,t,e,s){if(t!=null||s!=null)throw new Error("Support sampleWeight is not implemented yet");if(e!=null){const i=f(()=>{if(n.shape.length===1)return zo(n);if(n.shape.length===2){if(n.shape[1]>1)return Be(n,1);if(n.shape[1]===1)return E(n,[n.shape[0]]);throw new Error(`Encountered unexpected last-dimension size (${n.shape[1]}) during handling of class weights. The size is expected to be >= 1.`)}else throw new Error(`Unexpected rank of target (y) tensor (${n.rank}) during handling of class weights. The rank is expected to be 1 or 2.`)}),r=Array.from(await i.data());_(i);const o=[];return r.forEach(a=>{if(e[a]==null)throw new Error(`classWeight must contain all classes in the training data. The class ${a} exists in the data but not in classWeight`);o.push(e[a])}),_e(o,"float32")}else return null}function Il(n,t){return z(n,t)}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */const Al=32;function Di(n,t){let e,s;const i=t;e=i.xs,s=i.ys,P(e!=null&&s!=null,()=>`A Dataset iterator for fitDataset() is expected to generate objects of the form \`{xs: xVal, ys: yVal}\`, where the two values may be \`tf.Tensor\`, an array of Tensors, or a map of string to Tensor.  The provided Dataset instead generates ${t}`);const r=xn("input",n.inputNames,e),o=xn("output",n.outputNames,s),a=r[0].shape[0];P(r.length===n.inputs.length,()=>`LayersModel has ${n.inputs.length} inputs, but the dataset provides ${r.length} inputs.  (Expected input keys: ${JSON.stringify(n.inputNames)})`),P(o.length===n.outputs.length,()=>`LayersModel has ${n.outputs.length} outputs, but the dataset provides ${o.length} outputs.  (Expected output keys: ${JSON.stringify(n.outputNames)})`);for(let l=0;l<r.length;l++)P(r[l].shape[0]===a,()=>`Batch size mismatch: input ${n.inputNames[l]} has ${r[l].shape[0]}; expected  ${a} based on input ${n.inputNames[0]}.`);for(let l=0;l<o.length;l++)P(o[l].shape[0]===a,()=>`Batch size mismatch: output ${n.outputNames[l]} has ${o[l].shape[0]}; expected  ${a} based on input ${n.inputNames[0]}.`);return{xs:r,ys:o}}function xn(n,t,e){if(e instanceof ie)return[e];if(Array.isArray(e))return P(e.length===t.length,()=>`Received an array of ${e.length} Tensors, but expected ${t.length} to match the ${n} keys ${t}.`),e;{const s=[];for(const i of t){if(e[i]==null)throw new c(`The feature data generated by the dataset lacks the required ${n} key '${i}'.`);s.push(e[i])}return s}}function Nl(n){if(n.length===3)throw new L("Validation with sample weights is not implemented yet.");return{xs:n[0],ys:n[1]}}async function kl(n,t,e){const s=e.batchesPerEpoch!=null;if(P(n.optimizer!=null,()=>"You must compile a model before training/testing. Use LayersModel.compile(modelCompileConfig)."),P(e!=null,()=>"For fitDataset(), the 2nd argument (config) is required, but it is not provided in this call."),P(e.epochs!=null&&e.epochs>0&&Number.isInteger(e.epochs),()=>`For fitDataset(), config.epochs is expected to be a positive integer, but got ${e.epochs}`),P(!s||e.batchesPerEpoch>0&&Number.isInteger(e.batchesPerEpoch),()=>`For fitDataset(), config.batchesPerEpoch is expected to be a positive integer if specified, but got ${e.batchesPerEpoch}`),P(e.validationSplit==null,()=>"`validationSplit` is not supported by `fitDataset()`. Use validationData instead."),n.isTraining)throw new Error("Cannot start training because another fit() call is ongoing.");n.isTraining=!0;try{const i=e.validationData!=null;let r,o;if(i)if(Ln(e.validationData))P(e.validationBatches==null||e.validationBatches>0&&Number.isInteger(e.validationBatches),()=>`For fitDataset() with dataset-based validation, config.validationBatches is expected not to be provided, or to be a positive integer, but got ${e.validationBatches}`);else{const y=Nl(e.validationData);r=y.xs,o=y.ys}const a=n.makeTrainFunction(),l=n.getDedupedMetricsNames();let u;i?u=l.slice().concat(l.map(y=>"val_"+y)):u=l.slice();const h=bi(e.callbacks,e.yieldEvery),d=e.verbose==null?1:e.verbose,{callbackList:p,history:I}=wi(h,d,e.epochs,null,null,Sl(t,e),null,i,u);p.setModel(n),n.history=I,await p.onTrainBegin(),n.stopTraining_=!1;let b=e.initialEpoch==null?0:e.initialEpoch,g=await t.iterator();for(;b<e.epochs;){const y={};await p.onEpochBegin(b);let A=0,m=0;for(s||(g=await t.iterator());!s||A<e.batchesPerEpoch;){const k=await g.next();if(s&&k.done){console.warn(`You provided \`batchesPerEpoch\` as ${e.batchesPerEpoch}, but your dataset iterator ran out of data after ${A} batches; interrupting training. Make sure that your dataset can generate at least \`batchesPerEpoch * epochs\` batches (in this case, ${e.batchesPerEpoch*e.epochs} batches). You may need to use the repeat() function when building your dataset.`);break}if(k.value!=null){const{xs:N,ys:S}=Di(n,k.value),v={};v.batch=m,v.size=N[0].shape[0],await p.onBatchBegin(m,v);const M=[];if(e.classWeight!=null){const $=Ci(e.classWeight,n.outputNames);for(let Q=0;Q<$.length;++Q)M.push(await Ti(S[Q],null,$[Q]))}const x=N.concat(S).concat(M),T=a(x);_(x);for(let $=0;$<l.length;++$){const Q=l[$],xt=T[$];v[Q]=xt,Dt(xt)}await p.onBatchEnd(m,v),yi(v),m++,A++}if(s?A>=e.batchesPerEpoch:k.done){if(i){let N;Ln(e.validationData)?N=W(await n.evaluateDataset(e.validationData,{batches:e.validationBatches})):N=W(n.evaluate(r,o,{batchSize:e.validationBatchSize==null?Al:e.validationBatchSize,verbose:0}));for(let S=0;S<n.metricsNames.length;++S)y[`val_${n.metricsNames[S]}`]=N[S]}break}if(n.stopTraining_)break}if(await p.onEpochEnd(b,y),b++,n.stopTraining_)break}return await p.onTrainEnd(),await n.history.syncData(),n.history}finally{n.isTraining=!1}}function Sl(n,t){let e=null;return t.batchesPerEpoch!=null?e=t.batchesPerEpoch:Number.isFinite(n.size)&&(e=n.size),e}function Ln(n){return typeof n.iterator=="function"}function zl(n){return typeof n.next=="function"}async function vl(n,t,e){e=e||{};const s=e.batches!=null,i=n.testFunction;let r=[];if(e.verbose>0)throw new L("Verbose mode is not implemented yet.");P(!s||e.batches>0&&Number.isInteger(e.batches),()=>`Test loop expects \`batches\` to be a positive integer, but received ${JSON.stringify(e.batches)}`);const o=zl(t)?t:await t.iterator();let a=0,l=0;for(;!s||l<e.batches;){const u=await o.next();if(r=f(()=>{if(u.value){const{xs:h,ys:d}=Di(n,u.value),p=h.concat(d),I=f(()=>i(p));if(_(p),l===0)for(let g=0;g<I.length;++g)r.push(Es(0));const b=p[0].shape[0];for(let g=0;g<I.length;++g){const y=I[g],A=r[g];r[g]=f(()=>D(r[g],z(b,y))),l>0&&_(A)}_(I),a+=b,++l}return r}),u.done){s&&console.warn(`Your dataset iterator ran out of data during evaluateDataset(). Interrupting evalution. Make sure that your dataset can generate at least \`batches\` batches (in this case, ${e.batches} batches). You may need to use the repeat() function when building your dataset.`);break}}for(let u=0;u<r.length;++u){const h=r[u];r[u]=rt(r[u],a),_(h)}return et(r)}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function ds(n){P(n>0&&Number.isInteger(n),()=>`batchSize is required to be a positive integer, but got ${n}`)}function ce(n,t,e){return n==null?[null]:Array.isArray(n)?n.map(s=>qt(s,t,e-t)):qt(n,t,e-t)}function vs(n,t){return f(()=>n==null?null:Array.isArray(n)?n.map(e=>vs(e,t)):ni(n,t.dtype==="int32"?t:X(t,"int32")))}function ps(n,t){const e=[];let s=0,i=null;for(;s<n;)i=s+t,i>=n&&(i=n),e.push([s,i]),s=i;return e}function xi(n){const t=[];n instanceof ie&&(n=[n]);for(let e=0;e<n.length;++e){const s=n[e];if(s.rank===1)t.push(ve(s,1));else{if(s.rank===0)throw new Error("Expected tensor to be at least 1D, but received a 0D tensor (scalar).");t.push(s)}}return t}function pt(n,t){if(n==null)return;const e=[];if(t instanceof ie)e.push(t.id);else if(Array.isArray(t))t.forEach(i=>e.push(i.id));else if(t!=null)for(const i in t){const r=t[i];e.push(r.id)}const s=[];if(n instanceof ie)e.indexOf(n.id)===-1&&s.push(n);else if(Array.isArray(n))n.forEach(i=>{e.indexOf(i.id)===-1&&s.push(i)});else if(n!=null)for(const i in n){const r=n[i];e.indexOf(r.id)===-1&&s.push(r)}s.forEach(i=>{i.isDisposed||i.dispose()})}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function Cl(n){return n instanceof ie}function Cs(n){return Array.isArray(n)}function En(n){return!Cl(n)&&!Cs(n)}function On(n,t,e,s=!0,i=""){if(t==null||t.length===0){if(n!=null){let o=!1;if(Cs(n)&&n.length>0)o=!0;else if(En(n)){for(const a in n)if(n.hasOwnProperty(a)){o=!0;break}}else o=!0;if(o)throw new c(`Error when checking model ${i} expected no data, but got ${n}`)}return[]}if(n==null)return t.map(o=>null);let r;if(En(n)){n=n,r=[];for(const o of t){if(n[o]==null)throw new c(`No data provided for "${o}". Need data for each key in: ${t}`);r.push(n[o])}}else if(Cs(n)){if(n=n,n.length!==t.length)throw new c(`Error when checking model ${i}: the Array of Tensors that you are passing to your model is not the size the model expected. Expected to see ${t.length} Tensor(s), but instead got the following list of Tensor(s): ${n}`);r=n}else{if(n=n,t.length>1)throw new c(`The model ${i} expects ${t.length} Tensor(s), but only received one Tensor. Found: Tensor with shape ${n.shape}`);r=[n]}if(r=xi(r),e!=null)for(let o=0;o<t.length;++o){if(e[o]==null)continue;const a=r[o];if(a.shape.length!==e[o].length)throw new c(`Error when checking ${i}: expected ${t[o]} to have ${e[o].length} dimension(s). but got array with shape ${a.shape}`);for(let l=0;l<e[o].length;++l){if(l===0&&!s)continue;const u=a.shape[l],h=e[o][l];if(h!=null&&h>=0&&u!==h)throw new c(`${i} expected a batch of elements where each example has shape [${e[o].slice(1,e[o].length)}] (i.e.,tensor shape [*,${e[o].slice(1,e[o].length)}]) but the ${i} received an input with ${a.shape[0]} examples, each with shape [${a.shape.slice(1,a.shape.length)}] (tensor shape [${a.shape}])`)}}return r}function Tl(n,t,e){const s=$t(n.map(r=>r.shape[0]));s.sort();const i=$t(t.map(r=>r.shape[0]));if(i.sort(),s.length>1)throw new c(`All input Tensors (x) should have the same number of samples. Got array shapes: ${JSON.stringify(n.map(r=>r.shape))}`);if(i.length>1)throw new c(`All target Tensors (y) should have the same number of samples. Got array shapes: ${JSON.stringify(t.map(r=>r.shape))}`);if(s.length>0&&i.length>0&&!Ct(s,i))throw new c(`Input Tensors should have the same number of samples as target Tensors. Found ${s[0]} input sample(s) and ${i[0]} target sample(s).`)}function Dl(n,t,e){const s=[es,ss,be];for(let i=0;i<n.length;++i){const r=n[i],o=t[i],a=e[i];if(o!=null){if(o===be&&r.shape[r.shape.length-1]===1)throw new c(`You are passing a target array of shape ${r.shape} while using a loss 'categorical_crossentropy'. 'categorical_crossentropy'expects targets to be binary matrices (1s and 0s) of shape [samples, classes].`);if(s.indexOf(o)!==-1){const l=r.shape.slice(1),u=a.slice(1);for(let h=0;h<l.length;++h){const d=l[h],p=u[h];if(p!=null&&d!==p)throw new c(`A target Tensor with shape ${r.shape} was passed for an output of shape ${a}, while using a loss function that expects targets to have the same shape as the output.`)}}}}}function $n(n,t,e,s=!0,i=""){let r;if(Array.isArray(n)){if(n.length!==t.length)throw new c(`Error when checking model ${i}: the Array of Tensors that you are passing to your model is not the size the the model expected. Expected to see ${t.length} Tensor(s), but instead got ${n.length} Tensors(s).`);r=n}else{if(t.length>1)throw new c(`The model expects ${t.length} ${i} Tensors, but only received one Tensor. Found: array with shape ${JSON.stringify(n.shape)}.`);r=[n]}if(e!=null)for(let o=0;o<t.length;++o){if(e[o]==null)continue;const a=r[o];if(a.shape.length!==e[o].length)throw new c(`Error when checking ${i}: expected ${t[o]} to have ${e[o].length} dimension(s), but got array with shape ${JSON.stringify(a.shape)}`);for(let l=0;l<e[o].length;++l){if(l===0&&!s)continue;const u=a.shape[l],h=e[o][l];if(h!=null&&h!==u)throw new c(`Error when checking ${i}: expected ${t[o]} to have shape ${JSON.stringify(e[o])} but got array with shape ${JSON.stringify(a.shape)}.`)}}}function xl(n,t){if(n==null||Array.isArray(n)&&n.length===0)return t.map(s=>[]);let e;if(typeof n=="string"||typeof n=="function")e=[n];else if(Array.isArray(n)||typeof n=="object")e=n;else throw new TypeError(`Type of metrics argument not understood. Expected an string,function, Array, or Object, found: ${n}`);if(Array.isArray(e))return t.map(s=>e);{const s=[];for(const i of t){let r=e.hasOwnProperty(i)?e[i]:[];Array.isArray(r)||(r=[r]),s.push(r)}return s}}const Ll="layers-model";class te extends ft{constructor(t){super(t),this.isTraining=!1}summary(t,e,s=console.log){if(!this.built)throw new c("This model has never been called, thus its weights have not been created yet. So no summary can be displayed. Build the model first (e.g., by calling it on some test data).");fl(this,t,e,s)}compile(t){if(t.loss==null&&(t.loss=[]),this.loss=t.loss,typeof t.optimizer=="string")this.optimizer_=pl(t.optimizer),this.isOptimizerOwned=!0;else{if(!(t.optimizer instanceof vo))throw new c("User-defined optimizer must be an instance of tf.Optimizer.");this.optimizer_=t.optimizer,this.isOptimizerOwned=!1}let e=[];if(!Array.isArray(t.loss)&&typeof t.loss!="string"&&typeof t.loss!="function"){t.loss=t.loss;for(const o in t.loss)if(this.outputNames.indexOf(o)===-1)throw new c(`Unknown entry in loss dictionary: "${o}". Only expected the following keys: ${this.outputNames}`);for(const o of this.outputNames)t.loss[o]==null&&console.warn(`Output "${o}" is missing from loss dictionary. We assume this was done on purpose, and we will not be expecting data to be passed to ${o} during training`),e.push(cs(t.loss[o]))}else if(Array.isArray(t.loss)){if(t.loss.length!==this.outputs.length)throw new c(`When passing an Array as loss, it should have one entry per model output. The model has ${this.outputs.length} output(s), but you passed loss=${t.loss}.`);e=t.loss.map(a=>cs(a))}else{const o=cs(t.loss);this.outputs.forEach(a=>{e.push(o)})}this.lossFunctions=e,this.feedOutputNames=[],this.feedOutputShapes=[],this.feedLossFns=[];for(let o=0;o<this.outputs.length;++o){const a=this.internalOutputShapes[o],l=this.outputNames[o];this.feedOutputNames.push(l),this.feedOutputShapes.push(a),this.feedLossFns.push(this.lossFunctions[o])}const s=[];this.metrics=t.metrics,this.metricsNames=["loss"],this.metricsTensors=[],Ht("loss",()=>{for(let o=0;o<this.outputs.length;++o){if(s.indexOf(o)!==-1)continue;const a=this.lossFunctions[o];this.outputs.length>1&&(this.metricsTensors.push([a,o]),this.metricsNames.push(this.outputNames[o]+"_loss"))}});const i=xl(t.metrics,this.outputNames),r=(o,a,l)=>{this.outputNames.length>1&&(a=this.outputNames[o]+"_"+a),this.metricsNames.push(a),this.metricsTensors.push([l,o])};Ht("metric",()=>{for(let o=0;o<this.outputs.length;++o){if(s.indexOf(o)!==-1)continue;const a=i[o];(u=>{const h="";let d,p,I;for(const b of u){if(typeof b=="string"&&["accuracy","acc","crossentropy","ce"].indexOf(b)!==-1){const y=this.internalOutputShapes[o];y[y.length-1]===1||this.lossFunctions[o]===ss?["accuracy","acc"].indexOf(b)!==-1?p=Ai:["crossentropy","ce"].indexOf(b)!==-1&&(p=nl):this.lossFunctions[o]===He?["accuracy","acc"].indexOf(b)!==-1?p=il:["crossentropy","ce"].indexOf(b)!==-1&&(p=Si):["accuracy","acc"].indexOf(b)!==-1?p=Ni:["crossentropy","ce"].indexOf(b)!==-1&&(p=ki);let A;["accuracy","acc"].indexOf(b)!==-1?A="acc":["crossentropy","ce"].indexOf(b)!==-1&&(A="ce"),I=p,d=h+A}else I=dl(b),d=h+Me(b);let g;Ht(d,()=>{g=I}),r(o,d,g)}})(a)}}),this.collectedTrainableWeights=this.trainableWeights}checkTrainableWeightsConsistency(){this.collectedTrainableWeights!=null&&this.trainableWeights.length!==this.collectedTrainableWeights.length&&console.warn("Discrepancy between trainableweights and collected trainable weights. Did you set `model.trainable` without calling `model.compile()` afterwards?")}evaluate(t,e,s={}){const i=s.batchSize==null?32:s.batchSize;ds(i);const r=!0,o=this.standardizeUserDataXY(t,e,r,i);try{const a=o[0].concat(o[1]);this.makeTestFunction();const l=this.testFunction,u=this.testLoop(l,a,i,s.verbose,s.steps);return et(u)}finally{pt(o[0],t),pt(o[1],e)}}async evaluateDataset(t,e){return this.makeTestFunction(),vl(this,t,e)}checkNumSamples(t,e,s,i="steps"){let r;if(s!=null){if(r=null,e!=null)throw new c(`If ${i} is set, batchSize must be null or undefined.Got batchSize = ${e}`)}else if(t!=null)Array.isArray(t)?r=t[0].shape[0]:r=t.shape[0];else throw new c(`Either the input data should have a defined shape, or ${i} shoud be specified.`);return r}execute(t,e){if(Array.isArray(e)&&e.length===0)throw new c("`outputs` is an empty Array, which is not allowed.");const s=Array.isArray(e),i=s?e:[e],r=this.retrieveSymbolicTensors(i),o=new Ot;if(t instanceof ie&&(t=[t]),Array.isArray(t)){if(t.length!==this.inputs.length)throw new c(`The number of inputs provided (${t.length}) does not match the number of inputs of this model (${this.inputs.length}).`);for(let l=0;l<this.inputs.length;++l)o.add(this.inputs[l],t[l])}else for(const l of this.inputs){const u=t[l.name];if(u==null)throw new c(`No value is provided for the model's input ${l.name}`);o.add(l,u)}const a=fe(r,o);return s?a:a[0]}retrieveSymbolicTensors(t){const e=Jt(null,t.length);let s=t.length;for(const i of this.layers){const r=Array.isArray(i.output)?i.output:[i.output],o=r.map(a=>a.name);for(let a=0;a<t.length;++a){const l=o.indexOf(t[a]);if(l!==-1&&(e[a]=r[l],s--),s===0)break}if(s===0)break}if(s>0){const i=[];throw e.forEach((r,o)=>{r==null&&i.push(t[o])}),new c(`Cannot find SymbolicTensors for output name(s): ${JSON.stringify(i)}`)}return e}predictLoop(t,e=32,s=!1){return f(()=>{const i=this.checkNumSamples(t);if(s)throw new L("Verbose predictLoop() is not implemented yet.");const r=ps(i,e),o=this.outputs.map(a=>[]);for(let a=0;a<r.length;++a)f(()=>{const u=r[a][0],h=r[a][1],d=ce(t,u,h),p=[];if(Array.isArray(d))for(let b=0;b<d.length;++b)p.push({key:this.inputs[b],value:d[b]});else p.push({key:this.inputs[0],value:d});const I=new Ot(p);return fe(this.outputs,I)}).forEach((u,h)=>o[h].push(u));return et(o.map(a=>xs(a,0)))})}predict(t,e={}){const s=xi(t);$n(s,this.inputNames,this.feedInputShapes,!1);try{const i=e.batchSize==null?32:e.batchSize;return ds(i),this.predictLoop(s,i)}finally{pt(s,t)}}predictOnBatch(t){$n(t,this.inputNames,this.feedInputShapes,!0);const e=(Array.isArray(t)?t[0]:t).shape[0];return this.predictLoop(t,e)}standardizeUserDataXY(t,e,s=!0,i){if(this.optimizer_==null)throw new ht("You must compile a model before training/testing. Use LayersModel.compile(modelCompileArgs).");const r=[];for(let o=0;o<this.feedOutputShapes.length;++o){const a=this.feedOutputShapes[o];this.feedLossFns[o]===He?r.push(a.slice(0,a.length-1).concat([1])):r.push(a)}if(t=On(t,this.feedInputNames,this.feedInputShapes,!1,"input"),e=On(e,this.feedOutputNames,r,!1,"target"),Tl(t,e),Dl(e,this.feedLossFns,this.feedOutputShapes),this.stateful&&i!=null&&i>0&&t[0].shape[0]%i!==0)throw new c(`In a stateful network, you should only pass inputs with a number of samples that is divisible by the batch size ${i}. Found: ${t[0].shape[0]} sample(s).`);return[t,e]}async standardizeUserData(t,e,s,i,r=!0,o){const[a,l]=this.standardizeUserDataXY(t,e,r,o);if(s!=null)throw new Error("sample weight is not supported yet.");let u=null;if(i!=null){const h=Ci(i,this.outputNames);u=[];for(let d=0;d<h.length;++d)u.push(await Ti(l[d],null,h[d]))}return[a,l,u]}testLoop(t,e,s,i=0,r){return f(()=>{const o=this.checkNumSamples(e,s,r,"steps"),a=[];if(i>0)throw new L("Verbose mode is not implemented yet.");if(r!=null)throw new L("steps mode in testLoop() is not implemented yet");{const l=ps(o,s),u=_e(yt(0,o));for(let h=0;h<l.length;++h){const d=l[h][0],p=l[h][1],I=qt(u,d,p-d),b=vs(e,I),g=t(b);if(h===0)for(let y=0;y<g.length;++y)a.push(Es(0));for(let y=0;y<g.length;++y){const A=g[y];a[y]=D(a[y],z(p-d,A))}}for(let h=0;h<a.length;++h)a[h]=rt(a[h],o)}return a})}getDedupedMetricsNames(){const t=this.metricsNames,e=[];for(let s=0;s<t.length;++s){const i=t[s];let r=i;if(bn(t,i)>1){const o=bn(t.slice(0,s),i);r+=`_${o}`}e.push(r)}return e}makeTrainFunction(){return t=>{const e=[],s=t.slice(0,this.inputs.length),i=t.slice(this.inputs.length,this.inputs.length+this.outputs.length),r=t.slice(this.inputs.length+this.outputs.length,this.inputs.length+this.outputs.length*2),o=[],a=()=>{const d=[];for(let g=0;g<this.inputs.length;++g)d.push({key:this.inputs[g],value:s[g]});const p=new Ot(d),I=fe(this.outputs,p,{training:!0});let b;for(let g=0;g<this.lossFunctions.length;++g){const y=this.lossFunctions[g];let A=y(i[g],I[g]);r[g]!=null&&(A=Il(A,r[g]));const m=Y(A);e.push(m),g===0?b=A:b=D(b,A)}for(let g=0;g<this.metricsTensors.length;++g){let y;if(this.outputs.length>1&&g<this.outputs.length)y=e[g];else{const A=this.metricsTensors[g][0],m=this.metricsTensors[g][1];y=Y(A(i[m],I[m]))}Dt(y),o.push(y)}return b=Y(b),this.calculateLosses().forEach(g=>{b=D(b,g)}),b},l=this.collectedTrainableWeights.map(d=>d.read()),u=!0;return[this.optimizer_.minimize(a,u,l)].concat(o)}}makeTestFunction(){this.testFunction=t=>f(()=>{const e=[];let s;const i=t.slice(0,this.inputs.length),r=t.slice(this.inputs.length,this.inputs.length+this.outputs.length),o=[];for(let u=0;u<this.inputs.length;++u)o.push({key:this.inputs[u],value:i[u]});const a=new Ot(o),l=fe(this.outputs,a);for(let u=0;u<this.lossFunctions.length;++u){const h=this.lossFunctions[u],d=Y(h(r[u],l[u]));u===0?s=d:s=D(s,d),e.push(s)}for(let u=0;u<this.metricsTensors.length;++u){const h=this.metricsTensors[u][0],d=this.metricsTensors[u][1],p=Y(h(r[d],l[d]));e.push(p)}return e})}async fit(t,e,s={}){if(this.isTraining)throw new Error("Cannot start training because another fit() call is ongoing.");this.isTraining=!0;let i,r,o,a,l,u,h,d,p;try{const I=s.batchSize==null?32:s.batchSize;ds(I);const b=!1,g=await this.standardizeUserData(t,e,s.sampleWeight,s.classWeight,b,I);i=g[0],r=g[1],p=g[2];let y=!1,A;if(s.validationData!=null&&s.validationData.length>0){if(y=!0,s.validationData.length===2)l=s.validationData[0],u=s.validationData[1];else throw s.validationData.length===3?new L("validationData including sample weights is not supported yet."):new c(`When passing validation data, it must contain 2 (valX, valY) or 3 (valX, valY, valSampleWeight) items; ${s.validationData} is invalid.`);const T=!0,$=await this.standardizeUserData(l,u,null,null,T,I);h=$[0],d=$[1],A=h.concat(d)}else if(s.validationSplit!=null&&s.validationSplit>0&&s.validationSplit<1){y=!0;const T=Math.floor(i[0].shape[0]*(1-s.validationSplit)),$=i[0].shape[0];h=ce(i,T,$),o=i,i=ce(i,0,T),d=ce(r,T,$),a=r,r=ce(r,0,T),A=h.concat(d)}else s.validationSteps!=null&&(y=!0);const m=i.concat(r).concat(p);this.checkTrainableWeightsConsistency();const k=this.makeTrainFunction(),N=this.getDedupedMetricsNames();let S,v;y?(this.makeTestFunction(),S=this.testFunction,v=N.slice().concat(N.map(T=>"val_"+T))):(S=null,A=[],v=N.slice());const M=bi(s.callbacks,s.yieldEvery);return await this.fitLoop(k,m,N,I,s.epochs,s.verbose,M,S,A,s.shuffle,v,s.initialEpoch,null,null)}finally{this.isTraining=!1,pt(i,t),pt(r,e),pt(o,t),pt(a,e),pt(h,l),pt(d,u),p!=null&&_(p)}}async fitLoop(t,e,s,i,r,o,a,l,u,h,d,p,I,b){i==null&&(i=32),r==null&&(r=1),h==null&&(h=!0),p==null&&(p=0);let g=!1;if(l!=null&&u!=null&&(g=!0),b!=null&&(g=!0,I==null))throw new c("Can only use `validationSteps` when doing step-wise training, i.e., `stepsPerEpoch` must be set.");const y=this.checkNumSamples(e,i,I,"steps_per_epoch");let A;y!=null&&(A=yt(0,y)),o==null&&(o=1);const{callbackList:m,history:k}=wi(a,o,r,p,y,I,i,g,d);m.setModel(this),this.history=k,await m.onTrainBegin(),this.stopTraining_=!1;for(let N=p;N<r;++N){await m.onEpochBegin(N);const S={};if(I!=null)throw new L("stepsPerEpoch mode is not implemented yet.");{if(h==="batch")throw new L("batch shuffling is not implemneted yet");h&&Co(A);const v=_e(A),M=ps(y,i);for(let x=0;x<M.length;++x){const T={};if(await m.onBatchBegin(x,T),f(()=>{const $=M[x][0],Q=M[x][1],xt=qt(v,$,Q-$);T.batch=x,T.size=Q-$;const le=vs(e,xt),ue=t(le);for(let Lt=0;Lt<s.length;++Lt){const Et=s[Lt],Yt=ue[Lt];T[Et]=Yt,Dt(Yt)}if(x===M.length-1&&g){const Lt=this.testLoop(l,u,i);for(let Et=0;Et<s.length;++Et){const Yt=s[Et],he=Lt[Et];Dt(he),S["val_"+Yt]=he}}}),await m.onBatchEnd(x,T),yi(T),this.stopTraining_)break}v.dispose()}if(await m.onEpochEnd(N,S),this.stopTraining_)break}return await m.onTrainEnd(),await this.history.syncData(),this.history}async fitDataset(t,e){return kl(this,t,e)}async trainOnBatch(t,e){const s=await this.standardizeUserData(t,e),i=s[0],r=s[1],a=this.makeTrainFunction()(i.concat(r)),l=[];for(const u of a){const h=await u.data();l.push(h[0])}return _(a),pt(s[0],t),pt(s[1],e),et(l)}getNamedWeights(t){const e=[],s=t!=null&&t.trainableOnly,i=s?this.trainableWeights:this.weights,r=this.getWeights(s);for(let o=0;o<i.length;++o)s&&!i[o].trainable||e.push({name:i[o].originalName,tensor:r[o]});return e}set stopTraining(t){this.stopTraining_=t}get stopTraining(){return this.stopTraining_}get optimizer(){return this.optimizer_}set optimizer(t){this.optimizer_!==t&&(this.optimizer_=t,this.isOptimizerOwned=!1)}dispose(){const t=super.dispose();if(t.refCountAfterDispose===0&&this.optimizer!=null&&this.isOptimizerOwned){const e=ms().numTensors;this.optimizer_.dispose(),t.numDisposedVariables+=e-ms().numTensors}return t}getLossIdentifiers(){let t;if(typeof this.loss=="string")t=Tt(this.loss);else if(Array.isArray(this.loss)){for(const e of this.loss)if(typeof e!="string")throw new Error("Serialization of non-string loss is not supported.");t=this.loss.map(e=>Tt(e))}else{const e=Object.keys(this.loss);t={};const s=this.loss;for(const i of e)if(typeof s[i]=="string")t[i]=Tt(s[i]);else throw new Error("Serialization of non-string loss is not supported.")}return t}getMetricIdentifiers(){if(typeof this.metrics=="string"||typeof this.metrics=="function")return[Tt(Me(this.metrics))];if(Array.isArray(this.metrics))return this.metrics.map(t=>Tt(Me(t)));{const t={};for(const e in this.metrics)t[e]=Tt(Me(this.metrics[e]));return t}}getTrainingConfig(){return{loss:this.getLossIdentifiers(),metrics:this.getMetricIdentifiers(),optimizer_config:{class_name:this.optimizer.getClassName(),config:this.optimizer.getConfig()}}}loadTrainingConfig(t){if(t.weighted_metrics!=null)throw new Error("Loading weight_metrics is not supported yet.");if(t.loss_weights!=null)throw new Error("Loading loss_weights is not supported yet.");if(t.sample_weight_mode!=null)throw new Error("Loading sample_weight_mode is not supported yet.");const e=Ze(t.optimizer_config),s=vt(e);let i;if(typeof t.loss=="string")i=Vt(t.loss);else if(Array.isArray(t.loss))i=t.loss.map(o=>Vt(o));else if(t.loss!=null){i={};for(const o in t.loss)i[o]=Vt(t.loss[o])}let r;if(Array.isArray(t.metrics))r=t.metrics.map(o=>Vt(o));else if(t.metrics!=null){r={};for(const o in t.metrics)r[o]=Vt(t.metrics[o])}this.compile({loss:i,metrics:r,optimizer:s})}async save(t,e){if(typeof t=="string"){const u=To(t);if(u.length===0)throw new c(`Cannot find any save handlers for URL '${t}'`);if(u.length>1)throw new c(`Found more than one (${u.length}) save handlers for URL '${t}'`);t=u[0]}if(t.save==null)throw new c("LayersModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");const s=await fn(this.getNamedWeights(e)),i=!1,r=null,a={modelTopology:this.toJSON(r,i),format:Ll,generatedBy:`TensorFlow.js tfjs-layers v${vi}`,convertedBy:null};if((e==null?!1:e.includeOptimizer)&&this.optimizer!=null){a.trainingConfig=this.getTrainingConfig();const u="optimizer",{data:h,specs:d}=await fn(await this.optimizer.getWeights(),u);s.specs.push(...d),s.data=Do([s.data,h])}return this.userDefinedMetadata!=null&&(Dn(this.userDefinedMetadata,this.name,!0),a.userDefinedMetadata=this.userDefinedMetadata),a.weightData=s.data,a.weightSpecs=s.specs,t.save(a)}setUserDefinedMetadata(t){Dn(t,this.name),this.userDefinedMetadata=t}getUserDefinedMetadata(){return this.userDefinedMetadata}}te.className="Model";w(te);class Li extends te{}Li.className="Functional";w(Li);/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */async function Yl(n,t){if(t==null&&(t={}),typeof n=="string"){const e=xo(n,t);if(e.length===0)e.push(Lo(n,t));else if(e.length>1)throw new c(`Found more than one (${e.length}) load handlers for URL '${n}'`);n=e[0]}return El(n,void 0,t)}async function El(n,t,e){if(e==null&&(e={}),n.load==null)throw new c("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");const s=await n.load();let i=s.modelTopology;i.model_config!=null&&(i=i.model_config);const r=e.strict==null?!0:e.strict,o=s.weightData!=null&&s.weightSpecs!=null&&r,a=vt(Ze(i),t,o),l=s.trainingConfig;if(l!=null&&a.loadTrainingConfig(l),s.userDefinedMetadata!=null&&a.setUserDefinedMetadata(s.userDefinedMetadata),s.weightData!=null){if(s.weightSpecs==null)throw new c("LayersModel artifacts contains weight data, but not weight specs. Therefore loading of weights cannot proceed.");const{modelWeights:u,optimizerWeights:h}=Ol(s.weightData,s.weightSpecs);a.loadWeights(u,r),a.optimizer!=null&&h.length>0&&await a.optimizer.setWeights(h),_(u),_(h.map(d=>d.tensor))}return a}function Ol(n,t){const e=Eo(n,t),s={},i=[];return t.forEach(r=>{r.group==="optimizer"?i.push({name:r.name,tensor:e[r.name]}):s[r.name]=e[r.name]}),{modelWeights:s,optimizerWeights:i}}class we extends te{constructor(t){if(super({inputs:[],outputs:[]}),t=t||{},this.trainable=!0,this.built=!1,this.name=t.name!=null?t.name:Xe("sequential_"),t.layers!=null)for(const e of t.layers)this.add(e)}checkShape(t){if(t.inboundNodes[0].outputTensors[0].shape.some(s=>s<0))throw new c(`Negative dimension size caused by adding layer ${t.name} with input shape [${t.inboundNodes[0].inputTensors[0].shape}]`)}add(t){const e=t instanceof we||t instanceof te;let s;if(e){if(s=t,s.outputs.length!==1)throw new c("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");if(s.inputs.length!==1)throw new c("All layers in a Sequential model should have a single input tensor. For multi-input layers, use the functional API.")}if(this.outputs.length===0){if(t.inboundNodes.length===0){if(t.batchInputShape==null)throw new c("The first layer in a Sequential model must get an `inputShape` or `batchInputShape` argument.");const i=$a({batchShape:t.batchInputShape,dtype:t.dtype,name:t.name+"_input"});t.apply(i)}if(e)this.outputs=s.outputs,this.inputs=s.inputs;else{if(t.inboundNodes.length!==1)throw new c(`A layer added to a Sequential model must not already be connected somewhere else. LayersModel received layer ${t.name} which has ${t.inboundNodes.length} pre-existing inbound connections.`);if(t.inboundNodes[0].outputTensors.length!==1)throw new c("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");this.checkShape(t),this.outputs=[t.inboundNodes[0].outputTensors[0]],this.inputs=di(this.outputs[0])}this.inboundNodes=[],new ts({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:this.inputs,outputTensors:this.outputs,inputMasks:Jt(null,this.inputs.length),outputMasks:[null],inputShapes:this.inputs.map(i=>i.shape),outputShapes:this.outputs[0].shape})}else{const i=t.apply(this.outputs[0]);if(Array.isArray(i))throw new TypeError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");this.checkShape(t),this.outputs=[i],this.inboundNodes[0].outputTensors=this.outputs,this.inboundNodes[0].outputShapes=[this.outputs[0].shape]}this.layers.push(t),this.built=!1}pop(){if(this.layers.length===0)throw new TypeError("There are no layers in the model.");if(this.layers.pop(),this.layers.length===0)this.outputs=[],this.inboundNodes=[],this.outboundNodes=[];else{const t=this.layers.length-1;this.layers[t].outboundNodes=[],this.outputs=[this.layers[t].output],this.inboundNodes[0].outputTensors=this.outputs,this.inboundNodes[0].outputShapes=[this.outputs[0].shape]}}call(t,e){return this.model==null&&this.build(),this.model.call(t,e)}build(t){if(R(t),this.inputs.length===0||this.outputs.length===0)throw new TypeError("Sequential model cannot be built: model is empty. Add some layers first.");this.model=new te({inputs:this.inputs,outputs:this.outputs[0],name:this.name+"_model"}),this.model.trainable=this.trainable,this.supportsMasking=this.model.supportsMasking,this.inputLayers=this.model.inputLayers,this.inputLayersNodeIndices=this.model.inputLayersNodeIndices,this.inputLayersTensorIndices=this.model.inputLayersTensorIndices,this.outputLayers=this.model.outputLayers,this.outputLayersNodeIndices=this.model.outputLayersNodeIndices,this.outputLayersTensorIndices=this.model.outputLayersTensorIndices,this.nodesByDepth=this.model.nodesByDepth,this.containerNodes=this.model.containerNodes,this.outputNames=this.model.outputNames,this.inputNames=this.model.inputNames,this.built=!0}countParams(){return this.built||this.build(),super.countParams()}summary(t,e,s=console.log){this.built||this.build(),super.summary(t,e,s)}setWeights(t){this.model==null&&this.build(),this.model.setWeights(t)}evaluate(t,e,s={}){if(!this.built)throw new ht("The model needs to be compiled before being used.");return this.model.evaluate(t,e,s)}async evaluateDataset(t,e){if(!this.built)throw new ht("The model needs to be compiled before being used.");return this.model.evaluateDataset(t,e)}predict(t,e={}){return this.model==null&&this.build(),this.model.predict(t,e)}predictOnBatch(t){return this.model==null&&this.build(),this.model.predictOnBatch(t)}compile(t){this.build(),this.model.compile(t),this.optimizer_=this.model.optimizer,this.isOptimizerOwned=this.model.isOptimizerOwned,this.loss=this.model.loss,this.metrics=this.model.metrics,this.metricsTensors=this.model.metricsTensors,this.metricsNames=this.model.metricsNames}get optimizer(){return this.model==null?void 0:this.model.optimizer}set optimizer(t){this.model.optimizer=t}async fit(t,e,s={}){if(!this.built)throw new ht("The model needs to be compiled before being used.");return this.model.fit(t,e,s)}async fitDataset(t,e){if(!this.built)throw new ht("The model needs to be compiled before being used.");return this.model.fitDataset(t,e)}async trainOnBatch(t,e){return this.model.trainOnBatch(t,e)}static fromConfig(t,e,s={},i=!1){let r,o={};if(e instanceof Array){if(e[0].className==null||e[0].className==="Merge")throw new c("Legacy serialization format not supported yet.");r=e}else P(e.layers!=null,()=>"When the config data for a Sequential model is not an Array, it must be an Object that contains the 'layers' field."),r=e.layers,delete e.layers,o=e;const a=new t(o);if(!(a instanceof we))throw new L(`Sequential.fromConfig called on non-Sequential input: ${a}`);for(const l of r){const h=vt(l,void 0,i);i&&h.setFastWeightInitDuringBuild(!0),a.add(h)}return a}set stopTraining(t){if(this.model==null)throw new c("Cannot set the stopTraining property of a sequential model before it is compiled.");this.model.stopTraining=t}get stopTraining(){if(this.model==null)throw new c("Cannot get the stopTraining property of a sequential model before it is compiled.");return this.model.stopTraining}getConfig(){const t=[];for(const e of this.layers){const s={};s.className=e.getClassName(),s.config=e.getConfig(),t.push(s)}return{name:this.name,layers:t}}}we.className="Sequential";w(we);/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */let st=class extends Ae{getConfig(){return{}}};class Ei extends st{apply(t,e=1){return Ia(t,e)}}Ei.className="elu";w(Ei);class Oi extends st{apply(t){return Oo(t)}}Oi.className="selu";w(Oi);class $i extends st{apply(t){return ke(t)}}$i.className="relu";w($i);class Ri extends st{apply(t){return f(()=>Pn(6,ke(t)))}}Ri.className="relu6";w(Ri);class Mi extends st{apply(t){return t}}Mi.className="linear";w(Mi);class Fi extends st{apply(t){return Hn(t)}}Fi.className="sigmoid";w(Fi);class _i extends st{apply(t){return Na(t)}}_i.className="hardSigmoid";w(_i);class Bi extends st{apply(t){return $s(t)}}Bi.className="softplus";w(Bi);class Wi extends st{apply(t){return Aa(t)}}Wi.className="softsign";w(Wi);class Ui extends st{apply(t){return qn(t)}}Ui.className="tanh";w(Ui);let Qs=class extends st{apply(t,e=-1){return jn(t,e)}};Qs.className="softmax";w(Qs);class Vi extends st{apply(t,e=-1){return $o(t,e)}}Vi.className="logSoftmax";w(Vi);class ji extends st{apply(t,e=1){return f(()=>z(Hn(z(t,e)),t))}}ji.className="swish";w(ji);class Pi extends st{apply(t){return f(()=>z(t,qn($s(t))))}}Pi.className="mish";w(Pi);function Ft(n){return n.getClassName()}function fs(n,t={}){return ze(n,Ne.getMap().classNameMap,t,"activation")}function _t(n){if(n==null){const t={};return t.className="linear",t.config={},fs(t)}if(typeof n=="string"){const t={};return t.className=n,t.config={},fs(t)}else return n instanceof st?n:fs(n)}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function $l(n){if(n!=null&&typeof n!="object")throw new Error(`Argument to L1L2 regularizer's constructor is expected to be an object, but received: ${n}`)}class Hi extends Ae{}class qi extends Hi{constructor(t){super(),$l(t),this.l1=t==null||t.l1==null?.01:t.l1,this.l2=t==null||t.l2==null?.01:t.l2,this.hasL1=this.l1!==0,this.hasL2=this.l2!==0}apply(t){return f(()=>{let e=ut([1]);return this.hasL1&&(e=D(e,nt(z(this.l1,se(t))))),this.hasL2&&(e=D(e,nt(z(this.l2,Ce(t))))),E(e,[])})}getConfig(){return{l1:this.l1,l2:this.l2}}static fromConfig(t,e){return new t({l1:e.l1,l2:e.l2})}}qi.className="L1L2";w(qi);const Rn={l1l2:"L1L2"};function F(n){return Bs(n)}function Mn(n,t={}){return ze(n,Ne.getMap().classNameMap,t,"regularizer")}function V(n){if(n==null)return null;if(typeof n=="string"){const e={className:n in Rn?Rn[n]:n,config:{}};return Mn(e)}else return n instanceof Hi?n:Mn(n)}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */class Ki extends O{constructor(t){super(t??{}),this.supportsMasking=!0,t!=null&&(this.maxValue=t.maxValue)}call(t,e){t=C(t);let s=ke(t);return this.maxValue!=null&&(s=ct(s,0,this.maxValue)),s}computeOutputShape(t){return t}getConfig(){const t={maxValue:this.maxValue},e=super.getConfig();return Object.assign(t,e),t}}Ki.className="ReLU";w(Ki);class Ji extends O{constructor(t){super(t??{}),this.DEFAULT_ALPHA=.3,t==null&&(t={}),this.alpha=t.alpha==null?this.DEFAULT_ALPHA:t.alpha}call(t,e){const s=C(t);return Ro(s,this.alpha)}computeOutputShape(t){return t}getConfig(){const t={alpha:this.alpha},e=super.getConfig();return Object.assign(t,e),t}}Ji.className="LeakyReLU";w(Ji);class Zi extends O{constructor(t){if(super(t??{}),this.DEFAULT_ALPHA_INITIALIZER="zeros",t==null&&(t={}),this.supportsMasking=!0,this.alphaInitializer=U(t.alphaInitializer||this.DEFAULT_ALPHA_INITIALIZER),this.alphaRegularizer=V(t.alphaRegularizer),this.alphaConstraint=Z(t.alphaConstraint),t.sharedAxes==null)this.sharedAxes=null;else if(Array.isArray(t.sharedAxes))this.sharedAxes=t.sharedAxes;else if(typeof t.sharedAxes=="number")this.sharedAxes=[t.sharedAxes];else throw new c(`Expected sharedAxes to be a number or an array of numbers, but got ${t.sharedAxes}`)}build(t){t=R(t);const e=t.slice(1);if(this.sharedAxes!=null)for(const i of this.sharedAxes)e[i-1]=1;this.alpha=this.addWeight("alpha",e,"float32",this.alphaInitializer,this.alphaRegularizer,!0,this.alphaConstraint);const s={};if(this.sharedAxes!=null)for(let i=1;i<t.length;++i)s[i]=t[i];this.inputSpec=[new K({ndim:t.length,axes:s})],this.built=!0}call(t,e){return t=C(t),Mo(t,this.alpha.read())}getConfig(){const t={alphaInitializer:j(this.alphaInitializer),alphaRegularizer:F(this.alphaRegularizer),alphaConstraint:J(this.alphaConstraint),sharedAxes:this.sharedAxes},e=super.getConfig();return Object.assign(t,e),t}}Zi.className="PReLU";w(Zi);class Gi extends O{constructor(t){if(super(t??{}),this.DEFAULT_ALPHA=1,t==null&&(t={}),t.alpha!=null&&t.alpha!==this.DEFAULT_ALPHA)throw new L(`Non-default alpha value (${t.alpha}) is not supported by the ELU layer yet.`);this.alpha=t.alpha==null?this.DEFAULT_ALPHA:t.alpha}call(t,e){const s=C(t);return Bn(s)}computeOutputShape(t){return t}getConfig(){const t={alpha:this.alpha},e=super.getConfig();return Object.assign(t,e),t}}Gi.className="ELU";w(Gi);class Yi extends O{constructor(t){super(t??{}),this.DEFAULT_THETA=1,t==null&&(t={}),this.theta=t.theta==null?this.DEFAULT_THETA:t.theta}call(t,e){const s=C(t);return z(s,X(Ye(s,this.theta),"float32"))}computeOutputShape(t){return t}getConfig(){const t={theta:this.theta},e=super.getConfig();return Object.assign(t,e),t}}Yi.className="ThresholdedReLU";w(Yi);class Xi extends O{constructor(t){super(t??{}),this.DEFAULT_AXIS=1,t==null&&(t={}),this.softmax=new Qs().apply,this.axis=t.axis==null?this.DEFAULT_AXIS:t.axis}call(t,e){const s=C(t);return this.softmax(s,this.axis)}computeOutputShape(t){return t}getConfig(){const t={axis:this.axis},e=super.getConfig();return Object.assign(t,e),t}}Xi.className="Softmax";w(Xi);/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function ee(n,t,e){if(typeof n=="number")return Jt(n,t);if(n.length!==t)throw new c(`The ${e} argument must be an integer or tuple of ${t} integers. Received: ${n.length} elements.`);for(let s=0;s<t;++s){const i=n[s];if(!ga(i))throw new c(`The ${e} argument must be an integer or tuple of ${t} integers. Received: ${JSON.stringify(n)} including a non-integer number ${i}`)}return n}function mt(n,t,e,s,i=1){if(n==null)return n;const r=t+(t-1)*(i-1);let o;return e==="same"?o=n:o=n-r+1,Math.floor((o+s-1)/s)}function Nt(n,t,e,s){if(n==null)return null;if(s==="valid")n=n*t+Mt([e-t,0]);else if(s==="same")n=n*t;else throw new c(`Unsupport padding mode: ${s}.`);return n}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function tn(n,t){return f(()=>(H(t),t==="channelsFirst"?B(n,[0,2,3,1]):n))}function Qi(n,t){return f(()=>(H(t),t==="channelsFirst"?B(n,[0,2,3,4,1]):n))}function Rl(n,t,e,s=1,i="valid",r,o=1){return f(()=>{if(r==null&&(r=bt()),H(r),n.shape.length!==3)throw new c(`The input of a conv1dWithBias operation should be 3, but is ${n.shape.length} instead.`);if(t.shape.length!==3)throw new c(`The kernel for a conv1dWithBias operation should be 3, but is ${t.shape.length} instead`);if(e!=null&&e.shape.length!==1)throw new c(`The bias for a conv1dWithBias operation should be 1, but is ${t.shape.length} instead`);if(r==="channelsFirst"&&(n=B(n,[0,2,1])),i==="causal")throw new L("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");let a=Wo(n,t,s,i==="same"?"same":"valid","NWC",o);return e!=null&&(a=wt(a,e)),a})}function Fn(n,t,e,s=[1,1],i="valid",r,o,a=null){return f(()=>{if(r==null&&(r=bt()),H(r),n.rank!==3&&n.rank!==4)throw new c(`conv2dWithBiasActivation expects input to be of rank 3 or 4, but received ${n.rank}.`);if(t.rank!==3&&t.rank!==4)throw new c(`conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received ${n.rank}.`);let l=tn(n,r);if(i==="causal")throw new L("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");return l=Uo({x:l,filter:t,strides:s,pad:i==="same"?"same":"valid",dilations:o,dataFormat:"NHWC",bias:e,activation:a}),r==="channelsFirst"&&(l=B(l,[0,3,1,2])),l})}function Ml(n,t,e,s=[1,1,1],i="valid",r,o){return f(()=>{if(r==null&&(r=bt()),H(r),n.rank!==4&&n.rank!==5)throw new c(`conv3dWithBias expects input to be of rank 4 or 5, but received ${n.rank}.`);if(t.rank!==4&&t.rank!==5)throw new c(`conv3dWithBias expects kernel to be of rank 4 or 5, but received ${n.rank}.`);let a=Qi(n,r);if(i==="causal")throw new L("The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.");return a=Vo(a,t,s,i==="same"?"same":"valid","NDHWC",o),e!=null&&(a=wt(a,e)),r==="channelsFirst"&&(a=B(a,[0,4,1,2,3])),a})}class ns extends O{constructor(t,e){if(super(e),this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",ns.verifyArgs(e),this.rank=t,G(this.rank,"rank"),this.rank!==1&&this.rank!==2&&this.rank!==3)throw new L(`Convolution layer for rank other than 1, 2, or 3 (${this.rank}) is not implemented yet.`);if(this.kernelSize=ee(e.kernelSize,t,"kernelSize"),this.strides=ee(e.strides==null?1:e.strides,t,"strides"),this.padding=e.padding==null?"valid":e.padding,ot(this.padding),this.dataFormat=e.dataFormat==null?"channelsLast":e.dataFormat,H(this.dataFormat),this.activation=_t(e.activation),this.useBias=e.useBias==null?!0:e.useBias,this.biasInitializer=U(e.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.biasConstraint=Z(e.biasConstraint),this.biasRegularizer=V(e.biasRegularizer),this.activityRegularizer=V(e.activityRegularizer),this.dilationRate=ee(e.dilationRate==null?1:e.dilationRate,t,"dilationRate"),this.rank===1&&Array.isArray(this.dilationRate)&&this.dilationRate.length!==1)throw new c(`dilationRate must be a number or an array of a single number for 1D convolution, but received ${JSON.stringify(this.dilationRate)}`);if(this.rank===2){if(typeof this.dilationRate=="number")this.dilationRate=[this.dilationRate,this.dilationRate];else if(this.dilationRate.length!==2)throw new c(`dilationRate must be a number or array of two numbers for 2D convolution, but received ${JSON.stringify(this.dilationRate)}`)}else if(this.rank===3){if(typeof this.dilationRate=="number")this.dilationRate=[this.dilationRate,this.dilationRate,this.dilationRate];else if(this.dilationRate.length!==3)throw new c(`dilationRate must be a number or array of three numbers for 3D convolution, but received ${JSON.stringify(this.dilationRate)}`)}}static verifyArgs(t){if(At("kernelSize"in t,"required key 'kernelSize' not in config"),typeof t.kernelSize!="number"&&!Ws(t.kernelSize,"number",1,3))throw new c(`BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received ${JSON.stringify(t.kernelSize)}.`)}getConfig(){const t={kernelSize:this.kernelSize,strides:this.strides,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,activation:Ft(this.activation),useBias:this.useBias,biasInitializer:j(this.biasInitializer),biasRegularizer:F(this.biasRegularizer),activityRegularizer:F(this.activityRegularizer),biasConstraint:J(this.biasConstraint)},e=super.getConfig();return Object.assign(t,e),t}}class ae extends ns{constructor(t,e){super(t,e),this.kernel=null,ae.verifyArgs(e),this.filters=e.filters,G(this.filters,"filters"),this.kernelInitializer=U(e.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.kernelConstraint=Z(e.kernelConstraint),this.kernelRegularizer=V(e.kernelRegularizer)}build(t){t=R(t);const e=this.dataFormat==="channelsFirst"?1:t.length-1;if(t[e]==null)throw new c(`The channel dimension of the input should be defined. Found ${t[e]}`);const s=t[e],i=this.kernelSize.concat([s,this.filters]);this.kernel=this.addWeight("kernel",i,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[{ndim:this.rank+2,axes:{[e]:s}}],this.built=!0}call(t,e){return f(()=>{t=C(t);let s;const i=this.bias==null?null:this.bias.read(),r=Yn(this.activation.getClassName());if(r!=null&&this.rank===2)s=Fn(t,this.kernel.read(),i,this.strides,this.padding,this.dataFormat,this.dilationRate,r);else{if(this.rank===1)s=Rl(t,this.kernel.read(),i,this.strides[0],this.padding,this.dataFormat,this.dilationRate[0]);else if(this.rank===2)s=Fn(t,this.kernel.read(),i,this.strides,this.padding,this.dataFormat,this.dilationRate);else if(this.rank===3)s=Ml(t,this.kernel.read(),i,this.strides,this.padding,this.dataFormat,this.dilationRate);else throw new L("convolutions greater than 3D are not implemented yet.");this.activation!=null&&(s=this.activation.apply(s))}return s})}computeOutputShape(t){t=R(t);const e=[],s=this.dataFormat==="channelsLast"?t.slice(1,t.length-1):t.slice(2);for(let r=0;r<s.length;++r){const o=mt(s[r],this.kernelSize[r],this.padding,this.strides[r],typeof this.dilationRate=="number"?this.dilationRate:this.dilationRate[r]);e.push(o)}let i=[t[0]];return this.dataFormat==="channelsLast"?(i=i.concat(e),i.push(this.filters)):(i.push(this.filters),i=i.concat(e)),i}getConfig(){const t={filters:this.filters,kernelInitializer:j(this.kernelInitializer),kernelRegularizer:F(this.kernelRegularizer),kernelConstraint:J(this.kernelConstraint)},e=super.getConfig();return Object.assign(t,e),t}static verifyArgs(t){if(!("filters"in t)||typeof t.filters!="number"||t.filters<1)throw new c(`Convolution layer expected config.filters to be a 'number' > 0 but got ${JSON.stringify(t.filters)}`)}}class Le extends ae{constructor(t){super(2,t),Le.verifyArgs(t)}getConfig(){const t=super.getConfig();return delete t.rank,t}static verifyArgs(t){if(typeof t.kernelSize!="number"&&!Ws(t.kernelSize,"number",1,2))throw new c(`Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received ${JSON.stringify(t.kernelSize)}.`)}}Le.className="Conv2D";w(Le);class Ee extends ae{constructor(t){super(3,t),Ee.verifyArgs(t)}getConfig(){const t=super.getConfig();return delete t.rank,t}static verifyArgs(t){if(typeof t.kernelSize!="number"&&!(Array.isArray(t.kernelSize)&&(t.kernelSize.length===1||t.kernelSize.length===3)))throw new c(`Conv3D expects config.kernelSize to be number or [number, number, number], but received ${JSON.stringify(t.kernelSize)}.`)}}Ee.className="Conv3D";w(Ee);class tr extends Le{constructor(t){if(super(t),this.inputSpec=[new K({ndim:4})],this.padding!=="same"&&this.padding!=="valid")throw new c(`Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)}build(t){if(t=R(t),t.length!==4)throw new c("Input should have rank 4; Received input shape: "+JSON.stringify(t));const e=this.dataFormat==="channelsFirst"?1:t.length-1;if(t[e]==null)throw new c("The channel dimension of the inputs should be defined. Found `None`.");const s=t[e],i=this.kernelSize.concat([this.filters,s]);this.kernel=this.addWeight("kernel",i,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new K({ndim:4,axes:{[e]:s}})],this.built=!0}call(t,e){return f(()=>{let s=C(t);if(s.shape.length!==4)throw new c(`Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${s.shape.length}`);const i=s.shape,r=i[0];let o,a;this.dataFormat==="channelsFirst"?(o=2,a=3):(o=1,a=2);const l=i[o],u=i[a],h=this.kernelSize[0],d=this.kernelSize[1],p=this.strides[0],I=this.strides[1],b=Nt(l,p,h,this.padding),g=Nt(u,I,d,this.padding),y=[r,b,g,this.filters];this.dataFormat!=="channelsLast"&&(s=B(s,[0,2,3,1]));let A=Fo(s,this.kernel.read(),y,this.strides,this.padding);return this.dataFormat!=="channelsLast"&&(A=B(A,[0,3,1,2])),this.bias!=null&&(A=wt(A,this.bias.read(),this.dataFormat)),this.activation!=null&&(A=this.activation.apply(A)),A})}computeOutputShape(t){t=R(t);const e=t.slice();let s,i,r;this.dataFormat==="channelsFirst"?(s=1,i=2,r=3):(s=3,i=1,r=2);const o=this.kernelSize[0],a=this.kernelSize[1],l=this.strides[0],u=this.strides[1];return e[s]=this.filters,e[i]=Nt(e[i],l,o,this.padding),e[r]=Nt(e[r],u,a,this.padding),e}getConfig(){const t=super.getConfig();return delete t.dilationRate,t}}tr.className="Conv2DTranspose";w(tr);class er extends Ee{constructor(t){if(super(t),this.inputSpec=[new K({ndim:5})],this.padding!=="same"&&this.padding!=="valid")throw new c(`Conv3DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)}build(t){if(t=R(t),t.length!==5)throw new c("Input should have rank 5; Received input shape: "+JSON.stringify(t));const e=this.dataFormat==="channelsFirst"?1:t.length-1;if(t[e]==null)throw new c("The channel dimension of the inputs should be defined. Found `None`.");const s=t[e],i=this.kernelSize.concat([this.filters,s]);this.kernel=this.addWeight("kernel",i,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new K({ndim:5,axes:{[e]:s}})],this.built=!0}call(t,e){return f(()=>{let s=C(t);if(s.shape.length!==5)throw new c(`Conv3DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${s.shape.length}`);const i=s.shape,r=i[0];let o,a,l;this.dataFormat==="channelsFirst"?(l=2,o=3,a=4):(l=1,o=2,a=3);const u=i[l],h=i[o],d=i[a],p=this.kernelSize[0],I=this.kernelSize[1],b=this.kernelSize[2],g=this.strides[0],y=this.strides[1],A=this.strides[2],m=Nt(u,g,p,this.padding),k=Nt(h,y,I,this.padding),N=Nt(d,A,b,this.padding),S=[r,m,k,N,this.filters];this.dataFormat!=="channelsLast"&&(s=B(s,[0,2,3,4,1]));let v=_o(s,this.kernel.read(),S,this.strides,this.padding);return this.dataFormat!=="channelsLast"&&(v=B(v,[0,4,1,2,3])),this.bias!==null&&(v=wt(v,this.bias.read(),this.dataFormat)),this.activation!==null&&(v=this.activation.apply(v)),v})}computeOutputShape(t){t=R(t);const e=t.slice();let s,i,r,o;this.dataFormat==="channelsFirst"?(s=1,i=2,r=3,o=4):(s=4,i=1,r=2,o=3);const a=this.kernelSize[0],l=this.kernelSize[1],u=this.kernelSize[2],h=this.strides[0],d=this.strides[1],p=this.strides[2];return e[s]=this.filters,e[i]=Nt(e[i],h,a,this.padding),e[r]=Nt(e[r],d,l,this.padding),e[o]=Nt(e[o],p,u,this.padding),e}getConfig(){const t=super.getConfig();return delete t.dilationRate,t}}er.className="Conv3DTranspose";w(er);class sr extends ae{constructor(t,e){if(super(t,e),this.DEFAULT_DEPTHWISE_INITIALIZER="glorotUniform",this.DEFAULT_POINTWISE_INITIALIZER="glorotUniform",this.depthwiseKernel=null,this.pointwiseKernel=null,e.filters==null)throw new c("The `filters` configuration field is required by SeparableConv, but is unspecified.");if(e.kernelInitializer!=null||e.kernelRegularizer!=null||e.kernelConstraint!=null)throw new c("Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.");if(e.padding!=null&&e.padding!=="same"&&e.padding!=="valid")throw new c(`SeparableConv${this.rank}D supports only padding modes: 'same' and 'valid', but received ${JSON.stringify(e.padding)}`);this.depthMultiplier=e.depthMultiplier==null?1:e.depthMultiplier,this.depthwiseInitializer=U(e.depthwiseInitializer||this.DEFAULT_DEPTHWISE_INITIALIZER),this.depthwiseRegularizer=V(e.depthwiseRegularizer),this.depthwiseConstraint=Z(e.depthwiseConstraint),this.pointwiseInitializer=U(e.depthwiseInitializer||this.DEFAULT_POINTWISE_INITIALIZER),this.pointwiseRegularizer=V(e.pointwiseRegularizer),this.pointwiseConstraint=Z(e.pointwiseConstraint)}build(t){if(t=R(t),t.length<this.rank+2)throw new c(`Inputs to SeparableConv${this.rank}D should have rank ${this.rank+2}, but received input shape: ${JSON.stringify(t)}`);const e=this.dataFormat==="channelsFirst"?1:t.length-1;if(t[e]==null||t[e]<0)throw new c(`The channel dimension of the inputs should be defined, but found ${JSON.stringify(t[e])}`);const s=t[e],i=this.kernelSize.concat([s,this.depthMultiplier]),r=[];for(let a=0;a<this.rank;++a)r.push(1);r.push(s*this.depthMultiplier,this.filters);const o=!0;this.depthwiseKernel=this.addWeight("depthwise_kernel",i,"float32",this.depthwiseInitializer,this.depthwiseRegularizer,o,this.depthwiseConstraint),this.pointwiseKernel=this.addWeight("pointwise_kernel",r,"float32",this.pointwiseInitializer,this.pointwiseRegularizer,o,this.pointwiseConstraint),this.useBias?this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,o,this.biasConstraint):this.bias=null,this.inputSpec=[new K({ndim:this.rank+2,axes:{[e]:s}})],this.built=!0}call(t,e){return f(()=>{t=C(t);let s;if(this.rank===1)throw new L("1D separable convolution is not implemented yet.");return this.rank===2&&(this.dataFormat==="channelsFirst"&&(t=B(t,[0,2,3,1])),s=Bo(t,this.depthwiseKernel.read(),this.pointwiseKernel.read(),this.strides,this.padding,this.dilationRate,"NHWC")),this.useBias&&(s=wt(s,this.bias.read(),this.dataFormat)),this.activation!=null&&(s=this.activation.apply(s)),this.dataFormat==="channelsFirst"&&(s=B(s,[0,3,1,2])),s})}getConfig(){const t=super.getConfig();return delete t.rank,delete t.kernelInitializer,delete t.kernelRegularizer,delete t.kernelConstraint,t.depthwiseInitializer=j(this.depthwiseInitializer),t.pointwiseInitializer=j(this.pointwiseInitializer),t.depthwiseRegularizer=F(this.depthwiseRegularizer),t.pointwiseRegularizer=F(this.pointwiseRegularizer),t.depthwiseConstraint=J(this.depthwiseConstraint),t.pointwiseConstraint=J(this.pointwiseConstraint),t}}sr.className="SeparableConv";class nr extends sr{constructor(t){super(2,t)}}nr.className="SeparableConv2D";w(nr);class is extends ae{constructor(t){super(1,t),is.verifyArgs(t),this.inputSpec=[{ndim:3}]}getConfig(){const t=super.getConfig();return delete t.rank,delete t.dataFormat,t}static verifyArgs(t){if(typeof t.kernelSize!="number"&&!Ws(t.kernelSize,"number",1,1))throw new c(`Conv1D expects config.kernelSize to be number or number[] with length 1, but received ${JSON.stringify(t.kernelSize)}.`)}}is.className="Conv1D";w(is);class ir extends O{constructor(t){super(t),typeof t.cropping=="number"?this.cropping=[[t.cropping,t.cropping],[t.cropping,t.cropping]]:typeof t.cropping[0]=="number"?this.cropping=[[t.cropping[0],t.cropping[0]],[t.cropping[1],t.cropping[1]]]:this.cropping=t.cropping,this.dataFormat=t.dataFormat===void 0?"channelsLast":t.dataFormat,this.inputSpec=[{ndim:4}]}computeOutputShape(t){return this.dataFormat==="channelsFirst"?[t[0],t[1],t[2]-this.cropping[0][0]-this.cropping[0][1],t[3]-this.cropping[1][0]-this.cropping[1][1]]:[t[0],t[1]-this.cropping[0][0]-this.cropping[0][1],t[2]-this.cropping[1][0]-this.cropping[1][1],t[3]]}call(t,e){return f(()=>{if(t=C(t),this.dataFormat==="channelsLast"){const s=Re(t,this.cropping[0][0],t.shape[1]-this.cropping[0][0]-this.cropping[0][1],2);return Re(s,this.cropping[1][0],t.shape[2]-this.cropping[1][1]-this.cropping[1][0],3)}else{const s=Re(t,this.cropping[0][0],t.shape[2]-this.cropping[0][0]-this.cropping[0][1],3);return Re(s,this.cropping[1][0],t.shape[3]-this.cropping[1][1]-this.cropping[1][0],4)}})}getConfig(){const t={cropping:this.cropping,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}ir.className="Cropping2D";w(ir);class rr extends O{constructor(t){super(t),this.DEFAULT_SIZE=[2,2],this.inputSpec=[{ndim:4}],this.size=t.size==null?this.DEFAULT_SIZE:t.size,this.dataFormat=t.dataFormat==null?"channelsLast":t.dataFormat,H(this.dataFormat),this.interpolation=t.interpolation==null?"nearest":t.interpolation,pa(this.interpolation)}computeOutputShape(t){if(this.dataFormat==="channelsFirst"){const e=t[2]==null?null:this.size[0]*t[2],s=t[3]==null?null:this.size[1]*t[3];return[t[0],t[1],e,s]}else{const e=t[1]==null?null:this.size[0]*t[1],s=t[2]==null?null:this.size[1]*t[2];return[t[0],e,s,t[3]]}}call(t,e){return f(()=>{let s=C(t);const i=s.shape;if(this.dataFormat==="channelsFirst"){s=B(s,[0,2,3,1]);const r=this.size[0]*i[2],o=this.size[1]*i[3],a=this.interpolation==="nearest"?jt.resizeNearestNeighbor(s,[r,o]):jt.resizeBilinear(s,[r,o]);return B(a,[0,3,1,2])}else{const r=this.size[0]*i[1],o=this.size[1]*i[2];return this.interpolation==="nearest"?jt.resizeNearestNeighbor(s,[r,o]):jt.resizeBilinear(s,[r,o])}})}getConfig(){const t={size:this.size,dataFormat:this.dataFormat,interpolation:this.interpolation},e=super.getConfig();return Object.assign(t,e),t}}rr.className="UpSampling2D";w(rr);/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function Fl(n,t,e=[1,1],s="valid",i,r){return f(()=>{i==null&&(i=bt()),H(i);let o=tn(n,i);if(n.rank!==4)throw new c(`Input for depthwiseConv2d is required to be 4-D, but is instead ${n.rank}-D`);if(t.rank!==4)throw new c(`depthwiseKernel is required to be 4-D, but is instead ${t.rank}-D`);return o=jo(o,t,e,s==="same"?"same":"valid","NHWC",r),i==="channelsFirst"&&(o=B(o,[0,3,1,2])),o})}class or extends ns{constructor(t){super(2,t),this.depthwiseKernel=null,this.depthMultiplier=t.depthMultiplier==null?1:t.depthMultiplier,this.depthwiseInitializer=U(t.depthwiseInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.depthwiseConstraint=Z(t.depthwiseConstraint),this.depthwiseRegularizer=V(t.depthwiseRegularizer)}build(t){if(t=R(t),t.length<4)throw new c(`Inputs to DepthwiseConv2D should have rank 4. Received input shape: ${JSON.stringify(t)}.`);const e=this.dataFormat==="channelsFirst"?1:3;if(t[e]==null||t[e]<0)throw new c(`The channel dimension of the inputs to DepthwiseConv2D should be defined, but is not (${t[e]}).`);const s=t[e],i=[this.kernelSize[0],this.kernelSize[1],s,this.depthMultiplier];this.depthwiseKernel=this.addWeight("depthwise_kernel",i,null,this.depthwiseInitializer,this.depthwiseRegularizer,!0,this.depthwiseConstraint),this.useBias?this.bias=this.addWeight("bias",[s*this.depthMultiplier],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.built=!0}call(t,e){return f(()=>{t=C(t);let s=Fl(t,this.depthwiseKernel.read(),this.strides,this.padding,this.dataFormat,null);return this.useBias&&(s=wt(s,this.bias.read(),this.dataFormat)),this.activation!=null&&(s=this.activation.apply(s)),s})}computeOutputShape(t){t=R(t);const e=this.dataFormat==="channelsFirst"?t[2]:t[1],s=this.dataFormat==="channelsFirst"?t[3]:t[2],i=this.dataFormat==="channelsFirst"?t[1]*this.depthMultiplier:t[3]*this.depthMultiplier,r=mt(e,this.kernelSize[0],this.padding,this.strides[0]),o=mt(s,this.kernelSize[1],this.padding,this.strides[1]);return this.dataFormat==="channelsFirst"?[t[0],i,r,o]:[t[0],r,o,i]}getConfig(){const t=super.getConfig();return t.depthMultiplier=this.depthMultiplier,t.depthwiseInitializer=j(this.depthwiseInitializer),t.depthwiseRegularizer=F(this.depthwiseRegularizer),t.depthwiseConstraint=J(this.depthwiseRegularizer),t}}or.className="DepthwiseConv2D";w(or);/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function ar(n,t,e,s){if(Array.isArray(n)){if(t!=null||e!=null)throw new c("When inputs is an array, neither initialState or constants should be provided");s!=null&&(e=n.slice(n.length-s,n.length),n=n.slice(0,n.length-s)),n.length>1&&(t=n.slice(1,n.length)),n=n[0]}function i(r){return r==null||Array.isArray(r)?r:[r]}return t=i(t),e=i(e),{inputs:n,initialState:t,constants:e}}function lr(n,t,e,s=!1,i,r,o=!1,a=!1){return f(()=>{const l=t.shape.length;if(l<3)throw new c(`Input should be at least 3D, but is ${l}D.`);const u=[1,0].concat(yt(2,l));if(t=B(t,u),r!=null)throw new L("The rnn() functoin of the deeplearn.js backend does not support constants yet.");o&&console.warn("Backend rnn(): the unroll = true option is not applicable to the imperative deeplearn.js backend."),i!=null&&(i=X(X(i,"bool"),"float32"),i.rank===l-1&&(i=re(i,-1)),i=B(i,u)),s&&(t=gs(t,0),i!=null&&(i=gs(i,0)));const h=[];let d,p=e;const I=t.shape[0],b=ys(t);let g;i!=null&&(g=ys(i));for(let A=0;A<I;++A){const m=b[A],k=f(()=>n(m,p));if(i==null)d=k[0],p=k[1];else{const N=f(()=>{const S=g[A],v=tt(gt(S),S),M=D(z(k[0],S),z(p[0],v)),x=p.map((T,$)=>D(z(k[1][$],S),z(T,v)));return{output:M,newStates:x}});d=N.output,p=N.newStates}a&&h.push(d)}let y;return a&&(y=Kn(h,1)),[d,y,p]})}class Wt extends O{constructor(t){super(t);let e;if(t.cell==null)throw new c("cell property is missing for the constructor of RNN.");if(Array.isArray(t.cell)?e=new nn({cells:t.cell}):e=t.cell,e.stateSize==null)throw new c("The RNN cell should have an attribute `stateSize` (tuple of integers, one integer per RNN state).");this.cell=e,this.returnSequences=t.returnSequences==null?!1:t.returnSequences,this.returnState=t.returnState==null?!1:t.returnState,this.goBackwards=t.goBackwards==null?!1:t.goBackwards,this._stateful=t.stateful==null?!1:t.stateful,this.unroll=t.unroll==null?!1:t.unroll,this.supportsMasking=!0,this.inputSpec=[new K({ndim:3})],this.stateSpec=null,this.states_=null,this.numConstants=null,this.keptStates=[]}getStates(){if(this.states_==null){const t=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1;return yt(0,t).map(e=>null)}else return this.states_}setStates(t){this.states_=t}computeOutputShape(t){Ns(t)&&(t=t[0]),t=t;let e=this.cell.stateSize;Array.isArray(e)||(e=[e]);const s=e[0];let i;if(this.returnSequences?i=[t[0],t[1],s]:i=[t[0],s],this.returnState){const r=[];for(const o of e)r.push([t[0],o]);return[i].concat(r)}else return i}computeMask(t,e){return f(()=>{Array.isArray(e)&&(e=e[0]);const s=this.returnSequences?e:null;if(this.returnState){const i=this.states.map(r=>null);return[s].concat(i)}else return s})}get states(){if(this.states_==null){const t=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1,e=[];for(let s=0;s<t;++s)e.push(null);return e}else return this.states_}set states(t){this.states_=t}build(t){if(this.numConstants!=null)throw new L("Constants support is not implemented in RNN yet.");Ns(t)&&(t=t[0]),t=t;const e=this.stateful?t[0]:null,s=t.slice(2);this.inputSpec[0]=new K({shape:[e,null,...s]});const i=[t[0]].concat(t.slice(2));this.cell.build(i);let r;if(Array.isArray(this.cell.stateSize)?r=this.cell.stateSize:r=[this.cell.stateSize],this.stateSpec!=null){if(!Ct(this.stateSpec.map(o=>o.shape[o.shape.length-1]),r))throw new c(`An initialState was passed that is not compatible with cell.stateSize. Received stateSpec=${this.stateSpec}; However cell.stateSize is ${this.cell.stateSize}`)}else this.stateSpec=r.map(o=>new K({shape:[null,o]}));this.stateful&&this.resetStates()}resetStates(t,e=!1){f(()=>{if(!this.stateful)throw new It("Cannot call resetStates() on an RNN Layer that is not stateful.");const s=this.inputSpec[0].shape[0];if(s==null)throw new c("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(this.states_==null)Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map(i=>ut([s,i])):this.states_=[ut([s,this.cell.stateSize])];else if(t==null)_(this.states_),this.keptStates!=null&&(_(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map(i=>ut([s,i])):this.states_[0]=ut([s,this.cell.stateSize]);else{if(Array.isArray(t)||(t=[t]),t.length!==this.states_.length)throw new c(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${t.length} state value(s). Input received: ${t}`);e===!0?this.keptStates.push(this.states_.slice()):_(this.states_);for(let i=0;i<this.states_.length;++i){const r=t[i],o=Array.isArray(this.cell.stateSize)?this.cell.stateSize[i]:this.cell.stateSize,a=[s,o];if(!Ct(r.shape,a))throw new c(`State ${i} is incompatible with layer ${this.name}: expected shape=${a}, received shape=${r.shape}`);this.states_[i]=r}}this.states_=this.states_.map(i=>Dt(i.clone()))})}apply(t,e){let s=e==null?null:e.initialState,i=e==null?null:e.constants;e==null&&(e={});const r=ar(t,s,i,this.numConstants);t=r.inputs,s=r.initialState,i=r.constants;let o=[],a=[];if(s!=null){e.initialState=s,o=o.concat(s),this.stateSpec=[];for(const u of s)this.stateSpec.push(new K({shape:u.shape}));a=a.concat(this.stateSpec)}if(i!=null&&(e.constants=i,o=o.concat(i),this.numConstants=i.length),o[0]instanceof kt){const u=[t].concat(o),h=this.inputSpec.concat(a),d=this.inputSpec;this.inputSpec=h;const p=super.apply(u,e);return this.inputSpec=d,p}else return super.apply(t,e)}call(t,e){return f(()=>{const s=e==null?null:e.mask,i=e==null?null:e.training;let r=e==null?null:e.initialState;t=C(t),r==null&&(this.stateful?r=this.states_:r=this.getInitialState(t));const o=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1;if(r.length!==o)throw new c(`RNN Layer has ${o} state(s) but was passed ${r.length} initial state(s).`);this.unroll&&console.warn("Ignoring unroll = true for RNN layer, due to imperative backend.");const a={training:i},u=lr((b,g)=>{const y=this.cell.call([b].concat(g),a);return[y[0],y.slice(1)]},t,r,this.goBackwards,s,null,this.unroll,this.returnSequences),h=u[0],d=u[1],p=u[2];this.stateful&&this.resetStates(p,i);const I=this.returnSequences?d:h;return this.returnState?[I].concat(p):I})}getInitialState(t){return f(()=>{let e=ut(t.shape);return e=nt(e,[1,2]),e=ve(e),Array.isArray(this.cell.stateSize)?this.cell.stateSize.map(s=>s>1?Is(e,[1,s]):e):this.cell.stateSize>1?[Is(e,[1,this.cell.stateSize])]:[e]})}get trainableWeights(){return this.trainable?this.cell.trainableWeights:[]}get nonTrainableWeights(){return this.trainable?this.cell.nonTrainableWeights:this.cell.weights}setFastWeightInitDuringBuild(t){super.setFastWeightInitDuringBuild(t),this.cell!=null&&this.cell.setFastWeightInitDuringBuild(t)}getConfig(){const t=super.getConfig(),e={returnSequences:this.returnSequences,returnState:this.returnState,goBackwards:this.goBackwards,stateful:this.stateful,unroll:this.unroll};this.numConstants!=null&&(e.numConstants=this.numConstants);const s=this.cell.getConfig();return this.getClassName()===Wt.className&&(e.cell={className:this.cell.getClassName(),config:s}),Object.assign(Object.assign(Object.assign({},s),t),e)}static fromConfig(t,e,s={}){const i=e.cell,r=vt(i,s);return new t(Object.assign(e,{cell:r}))}}Wt.className="RNN";w(Wt);class rs extends O{}class en extends rs{constructor(t){super(t),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",this.units=t.units,G(this.units,"units"),this.activation=_t(t.activation==null?this.DEFAULT_ACTIVATION:t.activation),this.useBias=t.useBias==null?!0:t.useBias,this.kernelInitializer=U(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=U(t.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=U(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelRegularizer=V(t.kernelRegularizer),this.recurrentRegularizer=V(t.recurrentRegularizer),this.biasRegularizer=V(t.biasRegularizer),this.kernelConstraint=Z(t.kernelConstraint),this.recurrentConstraint=Z(t.recurrentConstraint),this.biasConstraint=Z(t.biasConstraint),this.dropout=oe([1,Mt([0,t.dropout==null?0:t.dropout])]),this.recurrentDropout=oe([1,Mt([0,t.recurrentDropout==null?0:t.recurrentDropout])]),this.dropoutFunc=t.dropoutFunc,this.stateSize=this.units,this.dropoutMask=null,this.recurrentDropoutMask=null}build(t){t=R(t),this.kernel=this.addWeight("kernel",[t[t.length-1],this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias?this.bias=this.addWeight("bias",[this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.built=!0}call(t,e){return f(()=>{if(t=t,t.length!==2)throw new c(`SimpleRNNCell expects 2 input Tensors, got ${t.length}.`);let s=t[1];t=t[0];const i=e.training==null?!1:e.training;0<this.dropout&&this.dropout<1&&this.dropoutMask==null&&(this.dropoutMask=Bt({ones:()=>gt(t),rate:this.dropout,training:i,dropoutFunc:this.dropoutFunc})),0<this.recurrentDropout&&this.recurrentDropout<1&&this.recurrentDropoutMask==null&&(this.recurrentDropoutMask=Bt({ones:()=>gt(s),rate:this.recurrentDropout,training:i,dropoutFunc:this.dropoutFunc}));let r;const o=this.dropoutMask,a=this.recurrentDropoutMask;o!=null?r=zt(z(t,o),this.kernel.read()):r=zt(t,this.kernel.read()),this.bias!=null&&(r=wt(r,this.bias.read())),a!=null&&(s=z(s,a));let l=D(r,zt(s,this.recurrentKernel.read()));return this.activation!=null&&(l=this.activation.apply(l)),[l,l]})}getConfig(){const t=super.getConfig(),e={units:this.units,activation:Ft(this.activation),useBias:this.useBias,kernelInitializer:j(this.kernelInitializer),recurrentInitializer:j(this.recurrentInitializer),biasInitializer:j(this.biasInitializer),kernelRegularizer:F(this.kernelRegularizer),recurrentRegularizer:F(this.recurrentRegularizer),biasRegularizer:F(this.biasRegularizer),activityRegularizer:F(this.activityRegularizer),kernelConstraint:J(this.kernelConstraint),recurrentConstraint:J(this.recurrentConstraint),biasConstraint:J(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout};return Object.assign(Object.assign({},t),e)}}en.className="SimpleRNNCell";w(en);class ur extends Wt{constructor(t){t.cell=new en(t),super(t)}call(t,e){return f(()=>{this.cell.dropoutMask!=null&&(_(this.cell.dropoutMask),this.cell.dropoutMask=null),this.cell.recurrentDropoutMask!=null&&(_(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);const s=e==null?null:e.mask,i=e==null?null:e.training,r=e==null?null:e.initialState;return super.call(t,{mask:s,training:i,initialState:r})})}static fromConfig(t,e){return new t(e)}}ur.className="SimpleRNN";w(ur);class sn extends rs{constructor(t){if(super(t),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_RECURRENT_ACTIVATION="hardSigmoid",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",t.resetAfter)throw new c("GRUCell does not support reset_after parameter set to true.");this.units=t.units,G(this.units,"units"),this.activation=_t(t.activation===void 0?this.DEFAULT_ACTIVATION:t.activation),this.recurrentActivation=_t(t.recurrentActivation===void 0?this.DEFAULT_RECURRENT_ACTIVATION:t.recurrentActivation),this.useBias=t.useBias==null?!0:t.useBias,this.kernelInitializer=U(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=U(t.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=U(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelRegularizer=V(t.kernelRegularizer),this.recurrentRegularizer=V(t.recurrentRegularizer),this.biasRegularizer=V(t.biasRegularizer),this.kernelConstraint=Z(t.kernelConstraint),this.recurrentConstraint=Z(t.recurrentConstraint),this.biasConstraint=Z(t.biasConstraint),this.dropout=oe([1,Mt([0,t.dropout==null?0:t.dropout])]),this.recurrentDropout=oe([1,Mt([0,t.recurrentDropout==null?0:t.recurrentDropout])]),this.dropoutFunc=t.dropoutFunc,this.implementation=t.implementation,this.stateSize=this.units,this.dropoutMask=null,this.recurrentDropoutMask=null}build(t){t=R(t);const e=t[t.length-1];this.kernel=this.addWeight("kernel",[e,this.units*3],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,this.units*3],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias?this.bias=this.addWeight("bias",[this.units*3],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.built=!0}call(t,e){return f(()=>{if(t=t,t.length!==2)throw new c(`GRUCell expects 2 input Tensors (inputs, h, c), got ${t.length}.`);const s=e.training==null?!1:e.training;let i=t[1];t=t[0],0<this.dropout&&this.dropout<1&&this.dropoutMask==null&&(this.dropoutMask=Bt({ones:()=>gt(t),rate:this.dropout,training:s,count:3,dropoutFunc:this.dropoutFunc})),0<this.recurrentDropout&&this.recurrentDropout<1&&this.recurrentDropoutMask==null&&(this.recurrentDropoutMask=Bt({ones:()=>gt(i),rate:this.recurrentDropout,training:s,count:3,dropoutFunc:this.dropoutFunc}));const r=this.dropoutMask,o=this.recurrentDropoutMask;let a,l,u;0<this.dropout&&this.dropout<1&&(t=z(t,r[0]));let h=zt(t,this.kernel.read());this.useBias&&(h=wt(h,this.bias.read())),0<this.recurrentDropout&&this.recurrentDropout<1&&(i=z(i,o[0]));const d=this.recurrentKernel.read(),[p,I]=Pt(d,[2*this.units,this.units],d.rank-1),b=zt(i,p),[g,y,A]=Pt(h,3,h.rank-1),[m,k]=Pt(b,2,b.rank-1);a=this.recurrentActivation.apply(D(g,m)),l=this.recurrentActivation.apply(D(y,k));const N=zt(z(l,i),I);u=this.activation.apply(D(A,N));const S=D(z(a,i),z(D(1,Ge(a)),u));return[S,S]})}getConfig(){const t=super.getConfig(),e={units:this.units,activation:Ft(this.activation),recurrentActivation:Ft(this.recurrentActivation),useBias:this.useBias,kernelInitializer:j(this.kernelInitializer),recurrentInitializer:j(this.recurrentInitializer),biasInitializer:j(this.biasInitializer),kernelRegularizer:F(this.kernelRegularizer),recurrentRegularizer:F(this.recurrentRegularizer),biasRegularizer:F(this.biasRegularizer),activityRegularizer:F(this.activityRegularizer),kernelConstraint:J(this.kernelConstraint),recurrentConstraint:J(this.recurrentConstraint),biasConstraint:J(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout,implementation:this.implementation,resetAfter:!1};return Object.assign(Object.assign({},t),e)}}sn.className="GRUCell";w(sn);class hr extends Wt{constructor(t){t.implementation===0&&console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."),t.cell=new sn(t),super(t)}call(t,e){return f(()=>{this.cell.dropoutMask!=null&&(_(this.cell.dropoutMask),this.cell.dropoutMask=null),this.cell.recurrentDropoutMask!=null&&(_(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);const s=e==null?null:e.mask,i=e==null?null:e.training,r=e==null?null:e.initialState;return super.call(t,{mask:s,training:i,initialState:r})})}static fromConfig(t,e){return e.implmentation===0&&(e.implementation=1),new t(e)}}hr.className="GRU";w(hr);class os extends rs{constructor(t){super(t),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_RECURRENT_ACTIVATION="hardSigmoid",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",this.units=t.units,G(this.units,"units"),this.activation=_t(t.activation===void 0?this.DEFAULT_ACTIVATION:t.activation),this.recurrentActivation=_t(t.recurrentActivation===void 0?this.DEFAULT_RECURRENT_ACTIVATION:t.recurrentActivation),this.useBias=t.useBias==null?!0:t.useBias,this.kernelInitializer=U(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=U(t.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=U(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.unitForgetBias=t.unitForgetBias,this.kernelRegularizer=V(t.kernelRegularizer),this.recurrentRegularizer=V(t.recurrentRegularizer),this.biasRegularizer=V(t.biasRegularizer),this.kernelConstraint=Z(t.kernelConstraint),this.recurrentConstraint=Z(t.recurrentConstraint),this.biasConstraint=Z(t.biasConstraint),this.dropout=oe([1,Mt([0,t.dropout==null?0:t.dropout])]),this.recurrentDropout=oe([1,Mt([0,t.recurrentDropout==null?0:t.recurrentDropout])]),this.dropoutFunc=t.dropoutFunc,this.implementation=t.implementation,this.stateSize=[this.units,this.units],this.dropoutMask=null,this.recurrentDropoutMask=null}build(t){var e;t=R(t);const s=t[t.length-1];this.kernel=this.addWeight("kernel",[s,this.units*4],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,this.units*4],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint);let i;if(this.useBias){if(this.unitForgetBias){const r=this.biasInitializer,o=this.units;i=new(e=class extends dt{apply(l,u){const h=r.apply([o]),d=new Vs().apply([o]),p=r.apply([o*2]);return In(In(h,d),p)}},e.className="CustomInit",e)}else i=this.biasInitializer;this.bias=this.addWeight("bias",[this.units*4],null,i,this.biasRegularizer,!0,this.biasConstraint)}else this.bias=null;this.built=!0}call(t,e){return f(()=>{const s=e.training==null?!1:e.training;if(t=t,t.length!==3)throw new c(`LSTMCell expects 3 input Tensors (inputs, h, c), got ${t.length}.`);let i=t[1];const r=t[2];t=t[0],0<this.dropout&&this.dropout<1&&this.dropoutMask==null&&(this.dropoutMask=Bt({ones:()=>gt(t),rate:this.dropout,training:s,count:4,dropoutFunc:this.dropoutFunc})),0<this.recurrentDropout&&this.recurrentDropout<1&&this.recurrentDropoutMask==null&&(this.recurrentDropoutMask=Bt({ones:()=>gt(i),rate:this.recurrentDropout,training:s,count:4,dropoutFunc:this.dropoutFunc}));const o=this.dropoutMask,a=this.recurrentDropoutMask;let l,u,h,d;0<this.dropout&&this.dropout<1&&(t=z(t,o[0]));let p=zt(t,this.kernel.read());0<this.recurrentDropout&&this.recurrentDropout<1&&(i=z(i,a[0])),p=D(p,zt(i,this.recurrentKernel.read())),this.useBias&&(p=wt(p,this.bias.read()));const[I,b,g,y]=Pt(p,4,p.rank-1);l=this.recurrentActivation.apply(I),u=this.recurrentActivation.apply(b),h=D(z(u,r),z(l,this.activation.apply(g))),d=this.recurrentActivation.apply(y);const A=z(d,this.activation.apply(h));return[A,A,h]})}getConfig(){const t=super.getConfig(),e={units:this.units,activation:Ft(this.activation),recurrentActivation:Ft(this.recurrentActivation),useBias:this.useBias,kernelInitializer:j(this.kernelInitializer),recurrentInitializer:j(this.recurrentInitializer),biasInitializer:j(this.biasInitializer),unitForgetBias:this.unitForgetBias,kernelRegularizer:F(this.kernelRegularizer),recurrentRegularizer:F(this.recurrentRegularizer),biasRegularizer:F(this.biasRegularizer),activityRegularizer:F(this.activityRegularizer),kernelConstraint:J(this.kernelConstraint),recurrentConstraint:J(this.recurrentConstraint),biasConstraint:J(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout,implementation:this.implementation};return Object.assign(Object.assign({},t),e)}}os.className="LSTMCell";w(os);class cr extends Wt{constructor(t){t.implementation===0&&console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."),t.cell=new os(t),super(t)}call(t,e){return f(()=>{this.cell.dropoutMask!=null&&(_(this.cell.dropoutMask),this.cell.dropoutMask=null),this.cell.recurrentDropoutMask!=null&&(_(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);const s=e==null?null:e.mask,i=e==null?null:e.training,r=e==null?null:e.initialState;return super.call(t,{mask:s,training:i,initialState:r})})}static fromConfig(t,e){return e.implmentation===0&&(e.implementation=1),new t(e)}}cr.className="LSTM";w(cr);class nn extends rs{constructor(t){super(t),this.cells=t.cells}get stateSize(){const t=[];for(const e of this.cells.slice().reverse())Array.isArray(e.stateSize)?t.push(...e.stateSize):t.push(e.stateSize);return t}call(t,e){return f(()=>{t=t;let s=t.slice(1);const i=[];for(const a of this.cells.slice().reverse())Array.isArray(a.stateSize)?i.push(s.splice(0,a.stateSize.length)):i.push(s.splice(0,1));i.reverse();const r=[];let o;for(let a=0;a<this.cells.length;++a){const l=this.cells[a];s=i[a],a===0?o=[t[0]].concat(s):o=[o[0]].concat(s),o=l.call(o,e),r.push(o.slice(1))}s=[];for(const a of r.slice().reverse())s.push(...a);return[o[0]].concat(s)})}build(t){Ns(t)&&(t=t[0]),t=t;let e;this.cells.forEach((s,i)=>{Ht(`RNNCell_${i}`,()=>{s.build(t),Array.isArray(s.stateSize)?e=s.stateSize[0]:e=s.stateSize,t=[t[0],e]})}),this.built=!0}getConfig(){const t=super.getConfig(),e=r=>({className:r.getClassName(),config:r.getConfig()}),i={cells:this.cells.map(e)};return Object.assign(Object.assign({},t),i)}static fromConfig(t,e,s={}){const i=[];for(const r of e.cells)i.push(vt(r,s));return new t({cells:i})}get trainableWeights(){if(!this.trainable)return[];const t=[];for(const e of this.cells)t.push(...e.trainableWeights);return t}get nonTrainableWeights(){const t=[];for(const e of this.cells)t.push(...e.nonTrainableWeights);if(!this.trainable){const e=[];for(const s of this.cells)e.push(...s.trainableWeights);return e.concat(t)}return t}getWeights(){const t=[];for(const e of this.cells)t.push(...e.weights);return ks(t)}setWeights(t){const e=[];for(const s of this.cells){const i=s.weights.length,r=t.splice(i);for(let o=0;o<s.weights.length;++o)e.push([s.weights[o],r[o]])}Zs(e)}}nn.className="StackedRNNCells";w(nn);function Bt(n){const{ones:t,rate:e,training:s=!1,count:i=1,dropoutFunc:r}=n,o=()=>r!=null?r(t(),e):ii(t(),e),a=()=>Te(o,t,s);return!i||i<=1?Dt(a().clone()):Array(i).fill(void 0).map(a).map(u=>Dt(u.clone()))}/**
 * @license
 * Copyright 2020 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */var _l=globalThis&&globalThis.__rest||function(n,t){var e={};for(var s in n)Object.prototype.hasOwnProperty.call(n,s)&&t.indexOf(s)<0&&(e[s]=n[s]);if(n!=null&&typeof Object.getOwnPropertySymbols=="function")for(var i=0,s=Object.getOwnPropertySymbols(n);i<s.length;i++)t.indexOf(s[i])<0&&Object.prototype.propertyIsEnumerable.call(n,s[i])&&(e[s[i]]=n[s[i]]);return e};class dr extends Wt{constructor(t){if(t.unroll)throw new L("Unrolling is not possible with convolutional RNNs.");if(Array.isArray(t.cell))throw new L("It is not possible at the moment to stack convolutional cells.");super(t),this.inputSpec=[new K({ndim:5})]}call(t,e){return f(()=>{if(this.cell.dropoutMask!=null&&(_(this.cell.dropoutMask),this.cell.dropoutMask=null),this.cell.recurrentDropoutMask!=null&&(_(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null),e&&e.constants)throw new c("ConvRNN2D cell does not support constants");const s=e==null?null:e.mask,i=e==null?null:e.training,r=e==null?null:e.initialState;return super.call(t,{mask:s,training:i,initialState:r})})}computeOutputShape(t){let e=this.computeSingleOutputShape(t);return this.returnSequences||(e=[e[0],...e.slice(2)]),this.returnState&&(e=[e,...Array(2).fill([t[0],...e.slice(-3)])]),e}getInitialState(t){return f(()=>{const{stateSize:e}=this.cell,s=t.shape,i=this.computeSingleOutputShape(s),r=[i[0],...i.slice(2)],o=ut(r);return Array.isArray(e)?Array(e.length).fill(o):[o]})}resetStates(t,e=!1){f(()=>{if(!this.stateful)throw new It("Cannot call resetStates() on an RNN Layer that is not stateful.");const s=this.inputSpec[0].shape,i=this.computeSingleOutputShape(s),r=[i[0],...i.slice(2)];if(s[0]==null)throw new c("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(this.getStates()==null)Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map(()=>ut(r)):this.states_=[ut(r)];else if(t==null)_(this.states_),this.keptStates!=null&&(_(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map(()=>ut(r)):this.states_[0]=ut(r);else{if(Array.isArray(t)||(t=[t]),t.length!==this.states_.length)throw new c(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${t.length} state value(s). Input received: ${t}`);e?this.keptStates.push(this.states_.slice()):_(this.states_);for(let a=0;a<this.states_.length;++a){const l=t[a],u=r;if(!Ct(l.shape,u))throw new c(`State ${a} is incompatible with layer ${this.name}: expected shape=${u}, received shape=${l.shape}`);this.states_[a]=l}}this.states_=this.states_.map(a=>Dt(a.clone()))})}computeSingleOutputShape(t){const{dataFormat:e,filters:s,kernelSize:i,padding:r,strides:o,dilationRate:a}=this.cell,l=e==="channelsFirst",u=t[l?3:2],h=t[l?4:3],d=mt(u,i[0],r,o[0],a[0]),p=mt(h,i[1],r,o[1],a[1]);return[...t.slice(0,2),...l?[s,d,p]:[d,p,s]]}}dr.className="ConvRNN2D";class rn extends os{constructor(t){const{filters:e,kernelSize:s,strides:i,padding:r,dataFormat:o,dilationRate:a}=t;super(Object.assign(Object.assign({},t),{units:e})),this.filters=e,G(this.filters,"filters"),this.kernelSize=ee(s,2,"kernelSize"),this.kernelSize.forEach(l=>G(l,"kernelSize")),this.strides=ee(i||1,2,"strides"),this.strides.forEach(l=>G(l,"strides")),this.padding=r||"valid",ot(this.padding),this.dataFormat=o||"channelsLast",H(this.dataFormat),this.dilationRate=ee(a||1,2,"dilationRate"),this.dilationRate.forEach(l=>G(l,"dilationRate"))}build(t){var e;t=R(t);const s=this.dataFormat==="channelsFirst"?1:t.length-1;if(t[s]==null)throw new c(`The channel dimension of the input should be defined. Found ${t[s]}`);const i=t[s],r=4,o=this.kernelSize.concat([i,this.filters*r]);this.kernel=this.addWeight("kernel",o,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint);const a=this.kernelSize.concat([this.filters,this.filters*r]);if(this.recurrentKernel=this.addWeight("recurrent_kernel",a,null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias){let l;if(this.unitForgetBias){const u=this.biasInitializer,h=this.filters;l=new(e=class extends dt{apply(p,I){const b=u.apply([h]),g=Ls([h]),y=u.apply([h*2]);return Us([b,g,y])}},e.className="CustomInit",e)}else l=this.biasInitializer;this.bias=this.addWeight("bias",[this.filters*r],null,l,this.biasRegularizer,!0,this.biasConstraint)}this.built=!0}call(t,e){return f(()=>{if(t.length!==3)throw new c(`ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ${t.length}.`);const s=e.training||!1,i=t[0],r=t[1],o=t[2],a=4;0<this.dropout&&this.dropout<1&&this.dropoutMask==null&&(this.dropoutMask=Bt({ones:()=>gt(i),rate:this.dropout,training:s,count:a,dropoutFunc:this.dropoutFunc}));const l=this.dropoutMask,u=(ln,ls,un)=>!ls||!ls[un]?ln:z(ls[un],ln);let h=u(i,l,0),d=u(i,l,1),p=u(i,l,2),I=u(i,l,3);0<this.recurrentDropout&&this.recurrentDropout<1&&this.recurrentDropoutMask==null&&(this.recurrentDropoutMask=Bt({ones:()=>gt(r),rate:this.recurrentDropout,training:s,count:a,dropoutFunc:this.dropoutFunc}));const b=this.recurrentDropoutMask;let g=u(r,b,0),y=u(r,b,1),A=u(r,b,2),m=u(r,b,3);const k=3,[N,S,v,M]=Pt(this.kernel.read(),a,k),[x,T,$,Q]=this.useBias?Pt(this.bias.read(),a):[null,null,null,null];h=this.inputConv(h,N,x,this.padding),d=this.inputConv(d,S,T,this.padding),p=this.inputConv(p,v,$,this.padding),I=this.inputConv(I,M,Q,this.padding);const[xt,le,ue,Lt]=Pt(this.recurrentKernel.read(),a,k);g=this.recurrentConv(g,xt),y=this.recurrentConv(y,le),A=this.recurrentConv(A,ue),m=this.recurrentConv(m,Lt);const Et=this.recurrentActivation.apply(D(h,g)),Yt=this.recurrentActivation.apply(D(d,y)),he=D(z(Yt,o),z(Et,this.activation.apply(D(p,A)))),an=z(this.recurrentActivation.apply(D(I,m)),this.activation.apply(he));return[an,an,he]})}getConfig(){const t=super.getConfig(),e=_l(t,["units"]),s={filters:this.filters,kernelSize:this.kernelSize,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,strides:this.strides};return Object.assign(Object.assign({},e),s)}inputConv(t,e,s,i){const r=mn(t,e,this.strides,i||"valid",this.dataFormat==="channelsFirst"?"NCHW":"NHWC",this.dilationRate);return s?wt(r,s,this.dataFormat):r}recurrentConv(t,e){return mn(t,e,1,"same",this.dataFormat==="channelsFirst"?"NCHW":"NHWC")}}rn.className="ConvLSTM2DCell";w(rn);class pr extends dr{constructor(t){const e=new rn(t);super(Object.assign(Object.assign({},t),{cell:e}))}static fromConfig(t,e){return new t(e)}}pr.className="ConvLSTM2D";w(pr);/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */class on extends O{constructor(t){super(t),this.rate=Math.max(Math.min(t.rate,1),0),this.noiseShape=t.noiseShape,this.seed=t.seed,this.supportsMasking=!0}getNoiseShape(t){if(this.noiseShape==null)return this.noiseShape;const e=t.shape,s=[];for(let i=0;i<this.noiseShape.length;++i)s.push(this.noiseShape[i]==null?e[i]:this.noiseShape[i]);return s}call(t,e){return f(()=>{this.invokeCallHook(t,e);const s=C(t);if(0<this.rate&&this.rate<1){const i=e.training==null?!1:e.training,r=this.getNoiseShape(s);return Te(()=>ii(s,this.rate,r,this.seed),()=>s,i)}return t})}getConfig(){const t={rate:this.rate,noiseShape:this.noiseShape,seed:this.seed},e=super.getConfig();return Object.assign(t,e),t}dispose(){return super.dispose()}}on.className="Dropout";w(on);class fr extends on{constructor(t){super(t),this.inputSpec=[{ndim:3}]}getNoiseShape(t){const e=t.shape;return[e[0],1,e[2]]}}fr.className="SpatialDropout1D";w(fr);class mr extends O{constructor(t){if(super(t),this.activation=null,this.useBias=!0,this.kernel=null,this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",t.batchInputShape==null&&t.inputShape==null&&t.inputDim!=null){let e=null;t.batchSize!=null&&(e=t.batchSize),this.batchInputShape=[e,t.inputDim]}this.units=t.units,G(this.units,"units"),this.activation=_t(t.activation),t.useBias!=null&&(this.useBias=t.useBias),this.kernelInitializer=U(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.biasInitializer=U(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelConstraint=Z(t.kernelConstraint),this.biasConstraint=Z(t.biasConstraint),this.kernelRegularizer=V(t.kernelRegularizer),this.biasRegularizer=V(t.biasRegularizer),this.activityRegularizer=V(t.activityRegularizer),this.supportsMasking=!0,this.inputSpec=[{minNDim:2}]}build(t){t=R(t);const e=t[t.length-1];this.kernel==null&&(this.kernel=this.addWeight("kernel",[e,this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint))),this.inputSpec=[{minNDim:2,axes:{[-1]:e}}],this.built=!0}computeOutputShape(t){t=R(t);const e=t.slice();return e[e.length-1]=this.units,e}call(t,e){return f(()=>{this.invokeCallHook(t,e);const s=C(t),i=Yn(this.activation.getClassName());let r;return i!=null?r=zt(s,this.kernel.read(),i,this.bias?this.bias.read():null):(r=zt(s,this.kernel.read()),this.bias!=null&&(r=wt(r,this.bias.read())),this.activation!=null&&(r=this.activation.apply(r))),r})}getConfig(){const t={units:this.units,activation:Ft(this.activation),useBias:this.useBias,kernelInitializer:j(this.kernelInitializer),biasInitializer:j(this.biasInitializer),kernelRegularizer:F(this.kernelRegularizer),biasRegularizer:F(this.biasRegularizer),activityRegularizer:F(this.activityRegularizer),kernelConstraint:J(this.kernelConstraint),biasConstraint:J(this.biasConstraint)},e=super.getConfig();return Object.assign(t,e),t}}mr.className="Dense";w(mr);class gr extends O{constructor(t){t=t||{},super(t),this.inputSpec=[{minNDim:3}],this.dataFormat=t.dataFormat}computeOutputShape(t){t=R(t);for(const e of t.slice(1))if(e==null)throw new c(`The shape of the input to "Flatten" is not fully defined (got ${t.slice(1)}). Make sure to pass a complete "input_shape" or "batch_input_shape" argument to the first layer in your model.`);return[t[0],Rt(t,1)]}call(t,e){return f(()=>{this.invokeCallHook(t,e);let s=C(t);if(this.dataFormat==="channelsFirst"&&s.rank>1){const i=[0];for(let r=2;r<s.rank;++r)i.push(r);i.push(1),s=B(s,i)}return wa(s)})}getConfig(){const t={};this.dataFormat!=null&&(t.dataFormat=this.dataFormat);const e=super.getConfig();return Object.assign(t,e),t}}gr.className="Flatten";w(gr);class yr extends O{constructor(t){super(t),this.supportsMasking=!0,this.activation=_t(t.activation)}call(t,e){return f(()=>{this.invokeCallHook(t,e);const s=C(t);return this.activation.apply(s)})}getConfig(){const t={activation:Ft(this.activation)},e=super.getConfig();return Object.assign(t,e),t}}yr.className="Activation";w(yr);class br extends O{constructor(t){super(t),this.n=t.n,this.inputSpec=[{ndim:2}]}computeOutputShape(t){return[t[0],this.n,t[1]]}call(t,e){return f(()=>(t=C(t),ya(t,this.n)))}getConfig(){const t={n:this.n},e=super.getConfig();return Object.assign(t,e),t}}br.className="RepeatVector";w(br);class wr extends O{constructor(t){super(t),this.targetShape=t.targetShape;for(let e=0;e<this.targetShape.length;++e)this.isUnknown(this.targetShape[e])&&(this.targetShape[e]=null)}isUnknown(t){return t<0||t==null}fixUnknownDimension(t,e){const s="Total size of new array must be unchanged.",i=e.slice();let r=1,o=null;for(let l=0;l<i.length;++l){const u=i[l];if(this.isUnknown(u))if(o===null)o=l;else throw new c("Can only specifiy one unknown dimension.");else r*=u}const a=Rt(t);if(o!==null){if(r===0||a%r!==0)throw new c(s);i[o]=a/r}else if(a!==r)throw new c(s);return i}computeOutputShape(t){let e=!1;for(let s=0;s<t.length;++s)if(this.isUnknown(t[s])){e=!0;break}return e?t.slice(0,1).concat(this.targetShape):t.slice(0,1).concat(this.fixUnknownDimension(t.slice(1),this.targetShape))}call(t,e){return f(()=>{this.invokeCallHook(t,e);const s=C(t),i=s.shape,r=i.slice(0,1).concat(this.fixUnknownDimension(i.slice(1),this.targetShape));return E(s,r)})}getConfig(){const t={targetShape:this.targetShape},e=super.getConfig();return Object.assign(t,e),t}}wr.className="Reshape";w(wr);class Ir extends O{constructor(t){if(super(t),t.dims==null)throw new Error("Required configuration field `dims` is missing during Permute constructor call.");if(!Array.isArray(t.dims))throw new Error(`Permute constructor requires \`dims\` to be an Array, but received ${t.dims} instead.`);const e=yt(1,t.dims.length+1);if(!Ct(t.dims.slice().sort(),e))throw new Error("Invalid permutation `dims`: "+JSON.stringify(t.dims)+" `dims` must contain consecutive integers starting from 1.");this.dims=t.dims,this.dimsIncludingBatch=[0].concat(this.dims),this.inputSpec=[new K({ndim:this.dims.length+1})]}computeOutputShape(t){t=R(t);const e=t.slice();return this.dims.forEach((s,i)=>{e[i+1]=t[s]}),e}call(t,e){return B(C(t),this.dimsIncludingBatch)}getConfig(){const t={dims:this.dims},e=super.getConfig();return Object.assign(t,e),t}}Ir.className="Permute";w(Ir);class Ar extends O{constructor(t){super(t??{}),this.supportsMasking=!0,t!=null?this.maskValue=t.maskValue==null?0:t.maskValue:this.maskValue=0}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={maskValue:this.maskValue};return Object.assign(e,t),e}computeMask(t,e){const s=C(t),i=-1;return gn(bs(s,this.maskValue),i)}call(t,e){return f(()=>{this.invokeCallHook(t,e);const s=C(t),i=-1,r=!0,o=gn(bs(s,this.maskValue),i,r);return z(s,X(o,s.dtype))})}}Ar.className="Masking";w(Ar);/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */class Nr extends O{constructor(t){if(super(t),this.embeddings=null,this.DEFAULT_EMBEDDINGS_INITIALIZER="randomUniform",t.batchInputShape==null&&t.inputShape==null){let e=null;t.batchSize!=null&&(e=t.batchSize),t.inputLength==null?this.batchInputShape=[e,null]:this.batchInputShape=[e].concat(W(t.inputLength))}this.inputDim=t.inputDim,G(this.inputDim,"inputDim"),this.outputDim=t.outputDim,G(this.outputDim,"outputDim"),this.embeddingsInitializer=U(t.embeddingsInitializer||this.DEFAULT_EMBEDDINGS_INITIALIZER),this.embeddingsRegularizer=V(t.embeddingsRegularizer),this.activityRegularizer=V(t.activityRegularizer),this.embeddingsConstraint=Z(t.embeddingsConstraint),this.maskZero=t.maskZero,this.supportsMasking=t.maskZero,this.inputLength=t.inputLength}build(t){this.embeddings=this.addWeight("embeddings",[this.inputDim,this.outputDim],this.dtype,this.embeddingsInitializer,this.embeddingsRegularizer,!0,this.embeddingsConstraint),this.built=!0}warnOnIncompatibleInputShape(t){}computeMask(t,e){return f(()=>this.maskZero?(t=C(t),bs(t,Po(t))):null)}computeOutputShape(t){if(t=R(t),this.inputLength==null)return[...t,this.outputDim];const e=W(this.inputLength);if(e.length!==t.length-1)throw new c(`"inputLength" is ${this.inputLength}, but received input shape has shape ${t}`);{let s=0;for(let i=0;i<e.length;++i){const r=e[i],o=t[i+1];if(r!=null&&o!=null&&r!==o)throw new c(`"inputLength" is ${this.inputLength}, but received input shape has shape ${t}`);r==null&&(e[s]=o),s++}}return[t[0],...e,this.outputDim]}call(t,e){return f(()=>{this.invokeCallHook(t,e);let s=C(t);s.dtype!=="int32"&&(s=St(s,"int32"));const i=ni(this.embeddings.read(),E(s,[s.size]));return E(i,R(this.computeOutputShape(s.shape)))})}getConfig(){const t={inputDim:this.inputDim,outputDim:this.outputDim,embeddingsInitializer:j(this.embeddingsInitializer),embeddingsRegularizer:F(this.embeddingsRegularizer),activityRegularizer:F(this.activityRegularizer),embeddingsConstraint:J(this.embeddingsConstraint),maskZero:this.maskZero,inputLength:this.inputLength},e=super.getConfig();return Object.assign(t,e),t}}Nr.className="Embedding";w(Nr);/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */class Gt extends O{constructor(t){super(t||{}),this.supportsMasking=!0}mergeFunction(t){throw new L}computeElementwiseOpOutputShape(t,e){if(t==null||e==null)return null;if(t.length<e.length)return this.computeElementwiseOpOutputShape(e,t);if(e.length===0)return t;const s=t.slice(0,t.length-e.length);for(let i=0;i<e.length;++i){const r=t[t.length-e.length+i],o=e[i];if(r==null||o==null||r<0||o<0)s.push(null);else if(r===1)s.push(o);else if(o===1)s.push(r);else{if(r!==o)throw new c("Operands could not be broadcast together with shapes "+JSON.stringify(t)+" "+JSON.stringify(e));s.push(r)}}return s}build(t){if(Array.isArray(t)&&!Array.isArray(t[0])&&(t=[R(t)]),t=t,t.length<2)throw new c(`A merge layer should be called on an Array of at least 2 inputs. Got ${t.length} input(s).`);let e=[];for(const r of t)r!=null&&r[0]!==null&&e.push(r[0]);if(e=$t(e),e.length>1)throw new c(`Can not merge tensors with different batch sizes. Got tensors with shapes: ${JSON.stringify(t)}.`);let s=t[0]==null?null:t[0].slice(1);for(let r=1;r<t.length;++r){const o=t[r]==null?null:t[r].slice(1);s=this.computeElementwiseOpOutputShape(s,o)}const i=t.map(r=>r.length);t.indexOf(null)===-1&&$t(i).length===1?this.reshapeRequired=!1:this.reshapeRequired=!0}call(t,e){return f(()=>{if(t=t,this.reshapeRequired){const s=[],i=t.map(r=>r.rank);if(i.indexOf(null)===-1){const r=Mt(i);for(let o of t){const a=o.rank;for(let l=0;l<r-a;++l)o=ve(o,1);s.push(o)}return this.mergeFunction(s)}else{let r=!1;for(const l of t){const u=l.rank;if(u==null){const h=l.shape,d=h[0],p=h.slice(1).concat([d]);let I=E(l,[d].concat(Rt(h.slice(1))));I=B(I,[1,0]),I=E(I,p),s.push(I),r=!0}else if(u>1){const h=yt(1,u).concat([0]);s.push(B(l,h)),r=!0}else s.push(l)}let o=this.mergeFunction(s);const a=o.rank;if(r){if(a==null){const l=o.shape,u=l.length,h=l[u-1],d=[h].concat(l.slice(0,l.length-1));o=E(B(E(o,[-1,h]),[1,0]),d)}else if(a>1){const l=[a-1].concat(yt(0,a-1));o=B(o,l)}}return o}}else return this.mergeFunction(t)})}computeOutputShape(t){t=t;let e;t[0]==null?e=null:e=t[0].slice(1);for(let i=1;i<t.length;++i){const r=t[i]==null?null:t[i].slice(1);e=this.computeElementwiseOpOutputShape(e,r)}let s=[];for(const i of t)i!=null&&i[0]!==null&&s.push(i[0]);return s=$t(s),s.length===1?e=s.concat(e):e=[null].concat(e),e}computeMask(t,e){return f(()=>{if(e==null)return null;if(!Array.isArray(e))throw new c("`mask` should be an Array");if(!Array.isArray(t))throw new c("`inputs` should be an Array");if(e.length!==t.length)throw new c(`The Array 'inputs' and 'mask' are expected to have the same length, but have different lengths (${t.length} vs ${e.length})`);if(e.every(i=>i==null))return null;e=e.map(i=>i==null?i:re(i,0));let s=e[0];for(let i=1;i<e.length-1;++i)s=Ms(s,e[i]);return s})}}class kr extends Gt{constructor(t){super(t)}mergeFunction(t){return f(()=>{let e=t[0].clone();for(let s=1;s<t.length;++s)e=D(e,t[s]);return e})}}kr.className="Add";w(kr);class Sr extends Gt{constructor(t){super(t)}mergeFunction(t){return f(()=>{let e=t[0].clone();for(let s=1;s<t.length;++s)e=z(e,t[s]);return e})}}Sr.className="Multiply";w(Sr);class zr extends Gt{constructor(t){super(t)}mergeFunction(t){return f(()=>{let e=t[0].clone();for(let s=1;s<t.length;++s)e=D(e,t[s]);return z(1/t.length,e)})}}zr.className="Average";w(zr);class vr extends Gt{constructor(t){super(t)}mergeFunction(t){return f(()=>{let e=t[0];for(let s=1;s<t.length;++s)e=Se(e,t[s]);return e})}}vr.className="Maximum";w(vr);class Cr extends Gt{constructor(t){super(t)}mergeFunction(t){return f(()=>{let e=t[0];for(let s=1;s<t.length;++s)e=Pn(e,t[s]);return e})}}Cr.className="Minimum";w(Cr);class Tr extends Gt{constructor(t){super(t),this.DEFAULT_AXIS=-1,t==null&&(t={}),this.axis=t.axis==null?this.DEFAULT_AXIS:t.axis,this.supportsMasking=!0,this.reshapeRequired=!1}build(t){if(!(Array.isArray(t)&&Array.isArray(t[0]))||t.length===1)throw new c("A `Concatenate` layer should be called on a list of at least 2 inputs");t=t;let e=!0;for(const i of t)if(i!=null){e=!1;break}if(e)return;const s=[];for(let i=0;i<t.length;++i){const r=t[i].slice();r.splice(this.axis,1);let o=!1;for(const a of s)if(Ct(a,r)){o=!0;break}o||s.push(r)}if(s.length>1)throw new c("A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got input shapes: "+JSON.stringify(t))}mergeFunction(t){return f(()=>Us(t,this.axis))}computeOutputShape(t){if(!(Array.isArray(t)&&Array.isArray(t[0])))throw new c("A `Concatenate` layer should be called on a list of inputs.");const e=t,s=e[0].slice(),i=this.axis<0?s.length+this.axis:this.axis;for(const r of e.slice(1)){if(s[i]==null||r[i]==null){s[i]=null;break}s[i]+=r[i]}return s}computeMask(t,e){if(e==null)return null;if(!Array.isArray(e))throw new c("`mask` should be an array for Concatenate");if(!Array.isArray(t))throw new c("`inputs` should be an array for Concatenate");if(e.length!==t.length)throw new c(`Mismatch in the length of mask (${e.length}) and the legnth of inputs (${t.length})`);return f(()=>{let s=!0;if(e.forEach(o=>{if(o!=null){s=!1;return}}),s)return null;const i=[];for(let o=0;o<t.length;++o)e[o]==null?i.push(X(gt(t[o]),"bool")):e[o].rank<t[o].rank?i.push(re(e[o],-1)):i.push(e[o]);const r=xs(i,this.axis);return Ho(r,-1,!1)})}getConfig(){const t={axis:this.axis},e=super.getConfig();return Object.assign(t,e),t}}Tr.className="Concatenate";w(Tr);function de(n,t){for(;n<0;)n+=t;return n}function Bl(n,t,e){if(n.shape.length>3||t.shape.length>3)throw new L("batchDot is not implemented for tensors of 4D or higher rank yet");if(P(n.shape.length>=2,()=>`batchDot requires the rank of x to be >= 2, but got ${n.shape.length}`),P(n.shape.length>=2,()=>`batchDot requires the rank of y to be >= 2, but got ${t.shape.length}`),typeof e=="number"&&(e=[e,e]),n.dtype==="complex64"||t.dtype==="complex64")throw new L("batchDot is not implemented for complex64-type Tensors yet.");const s=n.shape.length,i=t.shape.length;e==null&&(e=[s-1,i-2]);const r=e;return f(()=>{let o;if(s>i){o=s-i;const l=[];for(let u=0;u<o;++u)l.push(1);t=E(t,t.shape.concat(l))}else if(i>s){o=i-s;const l=[];for(let u=0;u<o;++u)l.push(1);n=E(n,n.shape.concat(l))}else o=0;let a;if(n.shape.length===2&&t.shape.length===2)r[0]===r[1]?a=nt(z(n,t),r[0]):a=nt(z(B(n,[1,0]),t),r[1]);else{const l=r[0]!==n.shape.length-1,u=r[1]===t.shape.length-1;a=qo(n,t,l,u)}if(o>0){let l;s>i?l=s+i-3:l=s-1;const u=[];for(let h=l;h<l+o;++h)u.push(h);a=Rs(a,u)}return a.shape.length===1&&(a=re(a,1)),a})}class Dr extends Gt{constructor(t){super(t),this.axes=t.axes,this.normalize=t.normalize==null?!1:t.normalize,this.supportsMasking=!0,this.reshapeRequired=!1}build(t){P(Array.isArray(t)&&t.length===2&&Array.isArray(t[0])&&Array.isArray(t[1]),()=>"A `Dot` layer should be called on a list of exactly 2 inputs.");const e=t[0],s=t[1];if(e.length>3||s.length>3)throw new L("Dot layer does not support tensors of 4D or higher rank yet.");const i=this.interpretAxes(e,s);if(e[i[0]]!==s[i[1]])throw new c(`Dimension incompatibility: ${e[i[0]]} !== ${s[i[1]]}`)}mergeFunction(t){if(t.length!==2)throw new c(`A \`Dot\` layer must be called on exactly 2 inputs, but received ${t.length} input(s).`);let e=t[0],s=t[1],i;return Array.isArray(this.axes)?i=this.axes.map((r,o)=>de(r,t[o].shape.length)):i=[de(this.axes,e.shape.length),de(this.axes,s.shape.length)],this.normalize&&(e=Pe(e,i[0]),s=Pe(s,i[1])),Bl(e,s,i)}interpretAxes(t,e){let s;return Array.isArray(this.axes)?s=this.axes:s=[de(this.axes,t.length),de(this.axes,e.length)],s}computeOutputShape(t){P(Array.isArray(t)&&t.length===2&&Array.isArray(t[0])&&Array.isArray(t[1]),()=>"A `Dot` layer should be called on a list of exactly 2 inputs.");const e=t[0].slice(),s=t[1].slice();if(e.length>3||s.length>3)throw new L("Dot layer does not support tensors of 4D or higher rank yet.");const i=this.interpretAxes(e,s);e.splice(i[0],1),s.splice(i[1],1),s.splice(0,1);const r=e.concat(s);return r.length===1&&r.push(1),r}computeMask(t,e){return null}getConfig(){const t={axes:this.axes,normalize:this.normalize},e=super.getConfig();return Object.assign(t,e),t}}Dr.className="Dot";w(Dr);/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */class xr extends O{constructor(t){super(t),this.supportsMasking=!0,this.stddev=t.stddev}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={stddev:this.stddev};return Object.assign(e,t),e}call(t,e){return f(()=>{this.invokeCallHook(t,e);const s=C(t);return Te(()=>D(Qe(s.shape,0,this.stddev),s),()=>s,e.training||!1)})}}xr.className="GaussianNoise";w(xr);class Lr extends O{constructor(t){super(t),this.supportsMasking=!0,this.rate=t.rate}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={rate:this.rate};return Object.assign(e,t),e}call(t,e){return f(()=>{this.invokeCallHook(t,e);const s=C(t);return this.rate>0&&this.rate<1?Te(()=>{const r=Math.sqrt(this.rate/(1-this.rate));return z(s,Qe(s.shape,1,r))},()=>s,e.training||!1):s})}}Lr.className="GaussianDropout";w(Lr);class Er extends O{constructor(t){super(t),this.supportsMasking=!0,this.rate=t.rate,this.noiseShape=t.noiseShape}_getNoiseShape(t){return this.noiseShape||C(t).shape}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={rate:this.rate};return Object.assign(e,t),e}call(t,e){return f(()=>{if(this.rate<1&&this.rate>0){const s=this._getNoiseShape(t);return Te(()=>{const r=C(t),o=1.6732632423543772,a=1.0507009873554805,l=-o*a;let u=Jn(Os(s),this.rate);u=St(u,"float32");const h=((1-this.rate)*(1+this.rate*l**2))**-.5,d=-h*l*this.rate,p=D(z(r,u),z(D(u,-1),l));return D(z(p,h),d)},()=>C(t),e.training||!1)}return t})}}Er.className="AlphaDropout";w(Er);/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function Ie(n,t,e,s,i,r=.001){let o;if(n.rank===2)o=Ko(n,t,e,s,i,r);else if(n.rank===3)o=Jo(n,t,e,s,i,r);else if(n.rank===4)o=Zo(n,t,e,s,i,r);else throw new L(`batchNormalization is not implemented for array of rank ${n.rank} yet`);return o}function Wl(n,t,e,s,i=.001){return f(()=>{const r=Fs(n,s),o=r.mean,a=r.variance;return[Ie(n,o,a,e,t,i),o,a]})}function Ul(n,t,e,s,i=.001){return f(()=>{const r=Fs(n,s),o=r.mean,a=r.variance,l=[];for(const b of yt(0,n.rank))s.indexOf(b)!==-1?l.push(1):l.push(n.shape[b]);const u=E(o,l),h=E(a,l),d=t==null?null:E(t,l),p=e==null?null:E(e,l);return[Ie(n,u,h,p,d,i),o,a]})}function Vl(n,t,e,s,i=.001){return Ct(s.slice().sort(),yt(0,n.rank-1))?Wl(n,t,e,s,i):Ul(n,t,e,s,i)}class Or extends O{constructor(t){t==null&&(t={}),super(t),this.supportsMasking=!0,this.axis=t.axis==null?-1:t.axis,this.momentum=t.momentum==null?.99:t.momentum,this.epsilon=t.epsilon==null?.001:t.epsilon,this.center=t.center==null?!0:t.center,this.scale=t.scale==null?!0:t.scale,this.betaInitializer=U(t.betaInitializer||"zeros"),this.gammaInitializer=U(t.gammaInitializer||"ones"),this.movingMeanInitializer=U(t.movingMeanInitializer||"zeros"),this.movingVarianceInitializer=U(t.movingVarianceInitializer||"ones"),this.betaConstraint=Z(t.betaConstraint),this.gammaConstraint=Z(t.gammaConstraint),this.betaRegularizer=V(t.betaRegularizer),this.gammaRegularizer=V(t.gammaRegularizer)}build(t){t=R(t);const e=this.axis>=0?this.axis:this.axis+t.length,s=t[e];if(s==null)throw new c(`Axis ${e} of input tensor should have a defined dimension but the layer received an input with shape ${JSON.stringify(t)}.`);this.inputSpec=[new K({ndim:t.length,axes:{[e]:s}})];const i=[s];this.scale&&(this.gamma=this.addWeight("gamma",i,null,this.gammaInitializer,this.gammaRegularizer,!0,this.gammaConstraint)),this.center&&(this.beta=this.addWeight("beta",i,null,this.betaInitializer,this.betaRegularizer,!0,this.betaConstraint)),this.movingMean=this.addWeight("moving_mean",i,null,this.movingMeanInitializer,null,!1),this.movingVariance=this.addWeight("moving_variance",i,null,this.movingVarianceInitializer,null,!1),this.built=!0}call(t,e){return f(()=>{const s=e.training==null?!1:e.training,i=C(t),r=i.shape,o=r.length,a=yt(0,o),l=this.axis>=0?this.axis:this.axis+o;a.splice(l,1);const u=Jt(1,o);u[l]=r[l];const h=a.slice();h.sort();const d=!Ct(h,yt(0,o).slice(0,o-1)),p=()=>{if(d){const m=E(this.movingMean.read(),u),k=E(this.movingVariance.read(),u),N=this.center?E(this.beta.read(),u):null,S=this.scale?E(this.gamma.read(),u):null;return Ie(i,m,k,N,S,this.epsilon)}else return Ie(i,this.movingMean.read(),this.movingVariance.read(),this.beta==null?null:this.beta.read(),this.gamma==null?null:this.gamma.read(),this.epsilon)};if(!s)return p();const[I,b,g]=Vl(i,this.gamma.read(),this.beta.read(),a,this.epsilon),y=(m,k,N)=>{f(()=>{const S=1-N,v=m.read(),M=z(tt(v,k),S);m.write(tt(v,M))})};return(()=>{y(this.movingMean,b,this.momentum),y(this.movingVariance,g,this.momentum)})(),I})}getConfig(){const t={axis:this.axis,momentum:this.momentum,epsilon:this.epsilon,center:this.center,scale:this.scale,betaInitializer:j(this.betaInitializer),gammaInitializer:j(this.gammaInitializer),movingMeanInitializer:j(this.movingMeanInitializer),movingVarianceInitializer:j(this.movingVarianceInitializer),betaRegularizer:F(this.betaRegularizer),gammaRegularizer:F(this.gammaRegularizer),betaConstraint:J(this.betaConstraint),gammaConstraint:J(this.gammaConstraint)},e=super.getConfig();return Object.assign(t,e),t}}Or.className="BatchNormalization";w(Or);class $r extends O{constructor(t){if(t==null&&(t={}),super(t),this.axis=t.axis==null?-1:t.axis,typeof this.axis=="number"){if(!Number.isInteger(this.axis))throw new Error(`Expected axis to be an integer, but received ${this.axis}`)}else if(Array.isArray(this.axis)){for(const e of this.axis)if(!Number.isInteger(e))throw new Error(`Expected axis to be an array of integers, but received ${JSON.stringify(this.axis)}`)}else throw new Error(`Expected axis to be an integer or an array of integers, but received ${JSON.stringify(this.axis)}`);this.epsilon=t.epsilon==null?.001:t.epsilon,this.center=t.center==null?!0:t.center,this.scale=t.scale==null?!0:t.scale,this.betaInitializer=U(t.betaInitializer||"zeros"),this.gammaInitializer=U(t.gammaInitializer||"ones"),this.betaRegularizer=V(t.betaRegularizer),this.gammaRegularizer=V(t.gammaRegularizer),this.supportsMasking=!0}build(t){t=R(t);const e=t.length;typeof this.axis=="number"&&(this.axis=[this.axis]);for(let r=0;r<this.axis.length;++r)this.axis[r]<0&&(this.axis[r]+=e);for(const r of this.axis)if(r<0||r>=e)throw new Error(`Invalid axis: ${r}`);if(this.axis.length!==$t(this.axis).length)throw new Error(`Found duplicate axes in: ${this.axis}`);const s=this.axis.map(r=>t[r]),i=!0;this.scale?this.gamma=this.addWeight("gamma",s,"float32",this.gammaInitializer,this.gammaRegularizer,i):this.gamma=null,this.center?this.beta=this.addWeight("beta",s,"float32",this.betaInitializer,this.betaRegularizer,i):this.beta=null,this.built=!0}call(t,e){const s=C(t),i=s.shape,r=i.length;return f(()=>{let{mean:a,variance:l}=Fs(s,this.axis,!0);const u=Jt(1,r);for(const g of this.axis)u[g]=i[g];const h=g=>g!=null&&g.shape.length!==r?E(g,u):g;let d=this.scale?h(this.gamma.read()):null,p=this.center?h(this.beta.read()):null;const I=[],b=[];for(let g=0;g<r;++g)this.axis.indexOf(g)!==-1?(I.push(i[g]),b.push(1)):(I.push(1),b.push(i[g]));return a=pe(a,I),l=pe(l,I),d!=null&&(d=pe(d,b)),p!=null&&(p=pe(p,b)),Ie(s,a,l,p,d,this.epsilon)})}getConfig(){const t={axis:this.axis,epsilon:this.epsilon,center:this.center,scale:this.scale,betaInitializer:j(this.betaInitializer),gammaInitializer:j(this.gammaInitializer),betaRegularizer:F(this.betaRegularizer),gammaRegularizer:F(this.gammaRegularizer)},e=super.getConfig();return Object.assign(t,e),t}}$r.className="LayerNormalization";w($r);/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function jl(n,t,e){return f(()=>{if(n.rank!==4)throw new c(`temporalPadding expects input tensor to be 4-D, but received a ${n.rank}-D tensor.`);if(t==null&&(t=[[1,1],[1,1]]),t.length!==2||t[0].length!==2||t[1].length!==2)throw new c("spatial2dPadding expects `padding` to be an Array of two Arrays, each of which is an Array of two integers.");if(e==null&&(e=bt()),e!=="channelsLast"&&e!=="channelsFirst")throw new c(`Unknown data format: ${e}. Supported data formats are 'channelsLast' and 'channelsFirst.`);let s;return e==="channelsFirst"?s=[[0,0],[0,0],t[0],t[1]]:s=[[0,0],t[0],t[1],[0,0]],Go(n,s)})}class Rr extends O{constructor(t){if(t==null&&(t={}),super(t),this.dataFormat=t.dataFormat==null?bt():t.dataFormat,t.padding==null)this.padding=[[1,1],[1,1]];else if(typeof t.padding=="number")this.padding=[[t.padding,t.padding],[t.padding,t.padding]];else{if(t.padding=t.padding,t.padding.length!==2)throw new c(`ZeroPadding2D expects padding to be a length-2 array, but received a length-${t.padding.length} array.`);let e,s;if(typeof t.padding[0]=="number")e=[t.padding[0],t.padding[0]],s=[t.padding[1],t.padding[1]];else{if(t.padding=t.padding,t.padding[0].length!==2)throw new c(`ZeroPadding2D expects height padding to be a length-2 array, but received a length-${t.padding[0].length} array.`);if(e=t.padding[0],t.padding[1].length!==2)throw new c(`ZeroPadding2D expects width padding to be a length-2 array, but received a length-${t.padding[1].length} array.`);s=t.padding[1]}this.padding=[e,s]}this.inputSpec=[new K({ndim:4})]}computeOutputShape(t){t=R(t);let e,s;return this.dataFormat==="channelsFirst"?(t[2]!=null&&t[2]>=0?e=t[2]+this.padding[0][0]+this.padding[0][1]:e=null,t[3]!=null&&t[3]>=0?s=t[3]+this.padding[1][0]+this.padding[1][1]:s=null,[t[0],t[1],e,s]):(t[1]!=null&&t[1]>=0?e=t[1]+this.padding[0][0]+this.padding[0][1]:e=null,t[2]!=null&&t[2]>=0?s=t[2]+this.padding[1][0]+this.padding[1][1]:s=null,[t[0],e,s,t[3]])}call(t,e){return f(()=>jl(C(t),this.padding,this.dataFormat))}getConfig(){const t={padding:this.padding,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}Rr.className="ZeroPadding2D";w(Rr);/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function as(n,t,e,s,i,r){return f(()=>{H(i),Qn(r),ot(s),e==null&&(e=[1,1]),s==null&&(s="valid"),i==null&&(i=bt()),r==null&&(r="max"),n=tn(n,i);let o;const a=s==="same"?"same":"valid";return r==="max"?o=Yo(n,t,e,a):o=Xo(n,t,e,a),i==="channelsFirst"&&(o=B(o,[0,3,1,2])),o})}function Mr(n,t,e,s,i,r){return f(()=>{H(i),Qn(r),ot(s),e==null&&(e=[1,1,1]),s==null&&(s="valid"),i==null&&(i=bt()),r==null&&(r="max"),n=Qi(n,i);let o;const a=s==="same"?"same":"valid";return r==="max"?o=Qo(n,t,e,a):o=ta(n,t,e,a),i==="channelsFirst"&&(o=B(o,[0,4,1,2,3])),o})}class Fr extends O{constructor(t){if(t.poolSize==null&&(t.poolSize=2),super(t),typeof t.poolSize=="number")this.poolSize=[t.poolSize];else if(Array.isArray(t.poolSize)&&t.poolSize.length===1&&typeof t.poolSize[0]=="number")this.poolSize=t.poolSize;else throw new c(`poolSize for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(t.poolSize)}`);if(G(this.poolSize,"poolSize"),t.strides==null)this.strides=this.poolSize;else if(typeof t.strides=="number")this.strides=[t.strides];else if(Array.isArray(t.strides)&&t.strides.length===1&&typeof t.strides[0]=="number")this.strides=t.strides;else throw new c(`strides for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(t.strides)}`);G(this.strides,"strides"),this.padding=t.padding==null?"valid":t.padding,ot(this.padding),this.inputSpec=[new K({ndim:3})]}computeOutputShape(t){t=R(t);const e=mt(t[1],this.poolSize[0],this.padding,this.strides[0]);return[t[0],e,t[2]]}call(t,e){return f(()=>{this.invokeCallHook(t,e),t=ve(C(t),2);const s=this.poolingFunction(C(t),[this.poolSize[0],1],[this.strides[0],1],this.padding,"channelsLast");return Rs(s,[2])})}getConfig(){const t={poolSize:this.poolSize,padding:this.padding,strides:this.strides},e=super.getConfig();return Object.assign(t,e),t}}class _r extends Fr{constructor(t){super(t)}poolingFunction(t,e,s,i,r){return H(r),ot(i),as(t,e,s,i,r,"max")}}_r.className="MaxPooling1D";w(_r);class Br extends Fr{constructor(t){super(t)}poolingFunction(t,e,s,i,r){return H(r),ot(i),as(t,e,s,i,r,"avg")}}Br.className="AveragePooling1D";w(Br);class Wr extends O{constructor(t){if(t.poolSize==null&&(t.poolSize=[2,2]),super(t),this.poolSize=Array.isArray(t.poolSize)?t.poolSize:[t.poolSize,t.poolSize],t.strides==null)this.strides=this.poolSize;else if(Array.isArray(t.strides)){if(t.strides.length!==2)throw new c(`If the strides property of a 2D pooling layer is an Array, it is expected to have a length of 2, but received length ${t.strides.length}.`);this.strides=t.strides}else this.strides=[t.strides,t.strides];G(this.poolSize,"poolSize"),G(this.strides,"strides"),this.padding=t.padding==null?"valid":t.padding,this.dataFormat=t.dataFormat==null?"channelsLast":t.dataFormat,H(this.dataFormat),ot(this.padding),this.inputSpec=[new K({ndim:4})]}computeOutputShape(t){t=R(t);let e=this.dataFormat==="channelsFirst"?t[2]:t[1],s=this.dataFormat==="channelsFirst"?t[3]:t[2];return e=mt(e,this.poolSize[0],this.padding,this.strides[0]),s=mt(s,this.poolSize[1],this.padding,this.strides[1]),this.dataFormat==="channelsFirst"?[t[0],t[1],e,s]:[t[0],e,s,t[3]]}call(t,e){return f(()=>(this.invokeCallHook(t,e),this.poolingFunction(C(t),this.poolSize,this.strides,this.padding,this.dataFormat)))}getConfig(){const t={poolSize:this.poolSize,padding:this.padding,strides:this.strides,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}class Ur extends Wr{constructor(t){super(t)}poolingFunction(t,e,s,i,r){return H(r),ot(i),as(t,e,s,i,r,"max")}}Ur.className="MaxPooling2D";w(Ur);class Vr extends Wr{constructor(t){super(t)}poolingFunction(t,e,s,i,r){return H(r),ot(i),as(t,e,s,i,r,"avg")}}Vr.className="AveragePooling2D";w(Vr);class jr extends O{constructor(t){if(t.poolSize==null&&(t.poolSize=[2,2,2]),super(t),this.poolSize=Array.isArray(t.poolSize)?t.poolSize:[t.poolSize,t.poolSize,t.poolSize],t.strides==null)this.strides=this.poolSize;else if(Array.isArray(t.strides)){if(t.strides.length!==3)throw new c(`If the strides property of a 3D pooling layer is an Array, it is expected to have a length of 3, but received length ${t.strides.length}.`);this.strides=t.strides}else this.strides=[t.strides,t.strides,t.strides];G(this.poolSize,"poolSize"),G(this.strides,"strides"),this.padding=t.padding==null?"valid":t.padding,this.dataFormat=t.dataFormat==null?"channelsLast":t.dataFormat,H(this.dataFormat),ot(this.padding),this.inputSpec=[new K({ndim:5})]}computeOutputShape(t){t=R(t);let e=this.dataFormat==="channelsFirst"?t[2]:t[1],s=this.dataFormat==="channelsFirst"?t[3]:t[2],i=this.dataFormat==="channelsFirst"?t[4]:t[3];return e=mt(e,this.poolSize[0],this.padding,this.strides[0]),s=mt(s,this.poolSize[1],this.padding,this.strides[1]),i=mt(i,this.poolSize[2],this.padding,this.strides[2]),this.dataFormat==="channelsFirst"?[t[0],t[1],e,s,i]:[t[0],e,s,i,t[4]]}call(t,e){return f(()=>(this.invokeCallHook(t,e),this.poolingFunction(C(t),this.poolSize,this.strides,this.padding,this.dataFormat)))}getConfig(){const t={poolSize:this.poolSize,padding:this.padding,strides:this.strides,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}class Pr extends jr{constructor(t){super(t)}poolingFunction(t,e,s,i,r){return H(r),ot(i),Mr(t,e,s,i,r,"max")}}Pr.className="MaxPooling3D";w(Pr);class Hr extends jr{constructor(t){super(t)}poolingFunction(t,e,s,i,r){return H(r),ot(i),Mr(t,e,s,i,r,"avg")}}Hr.className="AveragePooling3D";w(Hr);class qr extends O{constructor(t){super(t),this.inputSpec=[new K({ndim:3})]}computeOutputShape(t){return[t[0],t[2]]}call(t,e){throw new L}}class Kr extends qr{constructor(t){super(t||{})}call(t,e){return f(()=>{const s=C(t);return Y(s,1)})}}Kr.className="GlobalAveragePooling1D";w(Kr);class Jr extends qr{constructor(t){super(t||{})}call(t,e){return f(()=>{const s=C(t);return ge(s,1)})}}Jr.className="GlobalMaxPooling1D";w(Jr);class Zr extends O{constructor(t){super(t),this.dataFormat=t.dataFormat==null?"channelsLast":t.dataFormat,H(this.dataFormat),this.inputSpec=[new K({ndim:4})]}computeOutputShape(t){return t=t,this.dataFormat==="channelsLast"?[t[0],t[3]]:[t[0],t[1]]}call(t,e){throw new L}getConfig(){const t={dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}class Gr extends Zr{call(t,e){return f(()=>{const s=C(t);return this.dataFormat==="channelsLast"?Y(s,[1,2]):Y(s,[2,3])})}}Gr.className="GlobalAveragePooling2D";w(Gr);class Yr extends Zr{call(t,e){return f(()=>{const s=C(t);return this.dataFormat==="channelsLast"?ge(s,[1,2]):ge(s,[2,3])})}}Yr.className="GlobalMaxPooling2D";w(Yr);/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */class Xr extends O{constructor(t){super(t),this.layer=t.layer}build(t){this.built=!0}get trainable(){return this.layer!=null?this.layer.trainable:!1}set trainable(t){this.layer!=null&&(this.layer.trainable=t)}get trainableWeights(){return this.layer.trainableWeights}get nonTrainableWeights(){return this.layer.nonTrainableWeights}get updates(){return this.layer._updates}get losses(){return this.layer.losses}getWeights(){return this.layer.getWeights()}setWeights(t){this.layer.setWeights(t)}getConfig(){const t={layer:{className:this.layer.getClassName(),config:this.layer.getConfig()}},e=super.getConfig();return Object.assign(t,e),t}setFastWeightInitDuringBuild(t){super.setFastWeightInitDuringBuild(t),this.layer!=null&&this.layer.setFastWeightInitDuringBuild(t)}static fromConfig(t,e,s={}){const i=e.layer,r=vt(i,s);delete e.layer;const o={layer:r};return Object.assign(o,e),new t(o)}}class Qr extends Xr{constructor(t){super(t),this.supportsMasking=!0}build(t){if(t=R(t),t.length<3)throw new c(`TimeDistributed layer expects an input shape >= 3D, but received input shape ${JSON.stringify(t)}`);this.inputSpec=[{shape:t}];const e=[t[0]].concat(t.slice(2));this.layer.built||(this.layer.build(e),this.layer.built=!0),super.build(t)}computeOutputShape(t){t=R(t);const e=[t[0]].concat(t.slice(2)),s=this.layer.computeOutputShape(e),i=t[1];return[s[0],i].concat(s.slice(1))}call(t,e){return f(()=>(t=C(t),lr((o,a)=>[C(this.layer.call(o,e)),[]],t,[],!1,null,null,!1,!0)[1]))}}Qr.className="TimeDistributed";w(Qr);function Pl(n){Zt(da,"BidirectionalMergeMode",n)}const Hl="concat";class to extends Xr{constructor(t){super(t);const e=t.layer.getConfig(),s={};s.className=t.layer.getClassName(),s.config=e,this.forwardLayer=vt(s),e.goBackwards=e.goBackwards!==!0;const i={};if(i.className=t.layer.getClassName(),i.config=e,this.backwardLayer=vt(i),this.forwardLayer.name="forward_"+this.forwardLayer.name,this.backwardLayer.name="backward_"+this.backwardLayer.name,this.mergeMode=t.mergeMode===void 0?Hl:t.mergeMode,Pl(this.mergeMode),t.weights)throw new L("weights support is not implemented for Bidirectional layer yet.");this._stateful=t.layer.stateful,this.returnSequences=t.layer.returnSequences,this.returnState=t.layer.returnState,this.supportsMasking=!0,this._trainable=!0,this.inputSpec=t.layer.inputSpec,this.numConstants=null}get trainable(){return this._trainable}set trainable(t){this._trainable=t,this.forwardLayer!=null&&(this.forwardLayer.trainable=t),this.backwardLayer!=null&&(this.backwardLayer.trainable=t)}getWeights(){return this.forwardLayer.getWeights().concat(this.backwardLayer.getWeights())}setWeights(t){const e=t.length,s=Math.floor(e/2);this.forwardLayer.setWeights(t.slice(0,s)),this.backwardLayer.setWeights(t.slice(s))}computeOutputShape(t){let e=this.forwardLayer.computeOutputShape(t);Array.isArray(e)&&Array.isArray(e[0])||(e=[e]),e=e;let s,i,r;return this.returnState&&(r=e.slice(1)),s=e[0],s=s,this.mergeMode==="concat"?(s[s.length-1]*=2,i=[s]):this.mergeMode==null?i=[s,s.slice()]:i=[s],this.returnState?this.mergeMode==null?i.concat(r).concat(r.slice()):[s].concat(r).concat(r.slice()):et(i)}apply(t,e){let s=e==null?null:e.initialState,i=e==null?null:e.constants;e==null&&(e={});const r=ar(t,s,i,this.numConstants);if(t=r.inputs,s=r.initialState,i=r.constants,Array.isArray(t)&&(s=t.slice(1),t=t[0]),(s==null||s.length===0)&&i==null)return super.apply(t,e);const o=[],a=[];if(s!=null){const u=s.length;if(u%2>0)throw new c("When passing `initialState` to a Bidrectional RNN, the state should be an Array containing the states of the underlying RNNs.");e.initialState=s,o.push(...s);const h=s.map(d=>new K({shape:d.shape}));this.forwardLayer.stateSpec=h.slice(0,u/2),this.backwardLayer.stateSpec=h.slice(u/2),a.push(...h)}if(i!=null)throw new L("Support for constants in Bidirectional layers is not implemented yet.");const l=o[0]instanceof kt;for(const u of o)if(u instanceof kt!==l)throw new c("The initial state of a Bidirectional layer cannot be specified as a mix of symbolic and non-symbolic tensors");if(l){const u=[t].concat(o),h=this.inputSpec.concat(a),d=this.inputSpec;this.inputSpec=h;const p=super.apply(u,e);return this.inputSpec=d,p}else return super.apply(t,e)}call(t,e){return f(()=>{const s=e.initialState;let i,r;if(s==null)i=this.forwardLayer.call(t,e),r=this.backwardLayer.call(t,e);else{const l=s.slice(0,s.length/2),u=s.slice(s.length/2);i=this.forwardLayer.call(t,Object.assign(e,{initialState:l})),r=this.backwardLayer.call(t,Object.assign(e,{initialState:u}))}let o;this.returnState&&(Array.isArray(i)&&(o=i.slice(1).concat(r.slice(1))),i=i[0],r=r[0]),this.returnSequences&&(r=gs(r,1));let a;return this.mergeMode==="concat"?a=Us([i,r]):this.mergeMode==="sum"?a=D(i,r):this.mergeMode==="ave"?a=z(.5,D(i,r)):this.mergeMode==="mul"?a=z(i,r):this.mergeMode==null&&(a=[i,r]),this.returnState?this.mergeMode==null?a.concat(o):[a].concat(o):a})}resetStates(t){this.forwardLayer.resetStates(),this.backwardLayer.resetStates()}build(t){Ht(this.forwardLayer.name,()=>{this.forwardLayer.build(t)}),Ht(this.backwardLayer.name,()=>{this.backwardLayer.build(t)}),this.built=!0}computeMask(t,e){Array.isArray(e)&&(e=e[0]);let s;if(this.returnSequences?this.mergeMode==null?s=[e,e]:s=e:this.mergeMode==null?s=[null,null]:s=null,this.returnState){const r=this.forwardLayer.states.map(o=>null);return Array.isArray(s)?s.concat(r).concat(r):[s].concat(r).concat(r)}else return s}get trainableWeights(){return this.forwardLayer.trainableWeights.concat(this.backwardLayer.trainableWeights)}get nonTrainableWeights(){return this.forwardLayer.nonTrainableWeights.concat(this.backwardLayer.nonTrainableWeights)}setFastWeightInitDuringBuild(t){super.setFastWeightInitDuringBuild(t),this.forwardLayer!=null&&this.forwardLayer.setFastWeightInitDuringBuild(t),this.backwardLayer!=null&&this.backwardLayer.setFastWeightInitDuringBuild(t)}getConfig(){const t={mergeMode:this.mergeMode},e=super.getConfig();return Object.assign(t,e),t}static fromConfig(t,e){const s=vt(e.layer);if(delete e.layer,e.numConstants!=null)throw new L("Deserialization of a Bidirectional layer with numConstants present is not supported yet.");const i=e;return i.layer=s,new t(i)}}to.className="Bidirectional";w(to);/**
 * @license
 * Copyright 2022 CodeSmith LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */class eo extends O{constructor(t){super(t),this.scale=t.scale,t.offset?this.offset=t.offset:this.offset=0}getConfig(){const t={scale:this.scale,offset:this.offset},e=super.getConfig();return Object.assign(t,e),t}call(t,e){return f(()=>(t=C(t),t.dtype!=="float32"&&(t=St(t,"float32")),D(z(t,this.scale),this.offset)))}}eo.className="Rescaling";w(eo);/**
 * @license
 * Copyright 2022 CodeSmith LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */const{resizeBilinear:ql,cropAndResize:Kl}=jt;class so extends O{constructor(t){super(t),this.height=t.height,this.width=t.width}centerCrop(t,e,s,i,r,o,a,l){return f(()=>{let u,h=!1;const d=e/o,p=s/a,I=(i+e)/o,b=(r+s)/a,g=[d,p,I,b],y=[];t.rank===3?(h=!0,u=Kn([t])):u=t;for(let S=0;S<u.shape[0];S++)y.push(g);const A=ea(y,[y.length,4]),m=sa(0,y.length,1,"int32"),N=Kl(u,A,m,[i,r],"nearest");return St(h?C(ys(N)):N,l)})}upsize(t,e,s,i){return f(()=>{const r=ql(t,[e,s]);return St(r,i)})}call(t,e){return f(()=>{const s=C(t),i=s.dtype,r=s.shape,o=r[r.length-3],a=r[r.length-2];let l=0;o!==this.height&&(l=Math.floor((o-this.height)/2));let u=0;return a!==this.width&&(u=Math.floor((a-this.width)/2),u===0&&(u=1)),l>=0&&u>=0?this.centerCrop(s,l,u,this.height,this.width,o,a,i):this.upsize(t,this.height,this.width,i)})}getConfig(){const t={height:this.height,width:this.width},e=super.getConfig();return Object.assign(t,e),t}computeOutputShape(t){t=R(t);const e=t.length-3,s=t.length-2;return t[e]=this.height,t[s]=this.width,t}}so.className="CenterCrop";w(so);/**
 * @license
 * Copyright 2022 CodeSmith LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function Jl(n,t,e,s){let i=C(n);if(i.dtype!=="int32"&&(i=St(i,"int32")),t==="int")return i;const r=i.shape;if(i.rank===0&&(i=re(i,-1)),t==="oneHot"&&i.shape[i.shape.length-1]!==1&&(i=re(i,-1)),i.rank>2)throw new c(`When outputMode is not int, maximum output rank is 2 Received outputMode ${t} and input shape ${r} which would result in output rank ${i.rank}.`);const o=["multiHot","oneHot"].includes(t),a=i;let l;if(typeof s<"u"&&t==="count"?l=yn(a,s,e,o):l=yn(a,[],e,o),t!=="tfIdf")return l;if(s)return z(l,s);throw new c("When outputMode is 'tfIdf', weights must be provided.")}/**
 * @license
 * Copyright 2022 CodeSmith LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */class no extends O{constructor(t){super(t),this.numTokens=t.numTokens,t.outputMode?this.outputMode=t.outputMode:this.outputMode="multiHot"}getConfig(){const t={numTokens:this.numTokens,outputMode:this.outputMode},e=super.getConfig();return Object.assign(t,e),t}computeOutputShape(t){return t=R(t),t==null?[this.numTokens]:this.outputMode==="oneHot"&&t[t.length-1]!==1?(t.push(this.numTokens),t):(t[t.length-1]=this.numTokens,t)}call(t,e){return f(()=>{t=C(t),t.dtype!=="int32"&&(t=St(t,"int32"));let s;if(typeof e.countWeights<"u"){if(this.outputMode!=="count")throw new c(`countWeights is not used when outputMode !== count.
              Received countWeights=${e.countWeights}`);s=C(e.countWeights)}const i=ge(t),r=na(t),o=Ye(this.numTokens,i).bufferSync().get(0),a=Jn(r,0).bufferSync().get(0);if(!(o&&a))throw new c(`Input values must be between 0 < values <= numTokens with numTokens=${this.numTokens}`);return Jl(t,this.outputMode,this.numTokens,s)})}}no.className="CategoryEncoding";w(no);/**
 * @license
 * Copyright 2022 CodeSmith LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */const Zl=["bilinear","nearest"],_n=new Set(Zl);class io extends O{constructor(t){if(super(t),this.height=t.height,this.width=t.width,t.interpolation)if(_n.has(t.interpolation))this.interpolation=t.interpolation;else throw new c(`Invalid interpolation parameter: ${t.interpolation} is not implemented`);else this.interpolation="bilinear";this.cropToAspectRatio=Boolean(t.cropToAspectRatio)}computeOutputShape(t){t=R(t);const e=t[2];return[this.height,this.width,e]}getConfig(){const t={height:this.height,width:this.width,interpolation:this.interpolation,cropToAspectRatio:this.cropToAspectRatio},e=super.getConfig();return Object.assign(t,e),t}call(t,e){return f(()=>{const s=[this.height,this.width];if(this.interpolation==="bilinear")return jt.resizeBilinear(t,s,!this.cropToAspectRatio);if(this.interpolation==="nearest")return jt.resizeNearestNeighbor(t,s,!this.cropToAspectRatio);throw new Error(`Interpolation is ${this.interpolation} but only ${[..._n]} are supported`)})}}io.className="Resizing";w(io);export{Yl as l};
